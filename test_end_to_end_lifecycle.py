#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æµ‹è¯•: å®Œæ•´çš„æ¨¡å‹ç”Ÿå‘½å‘¨æœŸ

åœºæ™¯1: ä»åŸå§‹æ•°æ®åˆ°ç”Ÿäº§é¢„æµ‹çš„å®Œæ•´æµç¨‹
æµ‹è¯•ç›®æ ‡: éªŒè¯æ•´ä¸ªç³»ç»Ÿä»è¾“å…¥åˆ°è¾“å‡ºçš„å®Œæ•´é“¾è·¯

æµ‹è¯•æµç¨‹:
1. å‡†å¤‡é˜¶æ®µ - åˆ›å»ºæµ‹è¯•æ•°æ®å’Œç¯å¢ƒ
2. è®­ç»ƒé˜¶æ®µ - ä½¿ç”¨TrainingPipelineè®­ç»ƒæ¨¡å‹
3. æ³¨å†ŒéªŒè¯é˜¶æ®µ - éªŒè¯æ¨¡å‹æ­£ç¡®æ³¨å†Œå’ŒåŠ è½½
4. ç”Ÿäº§éƒ¨ç½²é˜¶æ®µ - ä½¿ç”¨ModelPredictoréƒ¨ç½²æ¨¡å‹
5. é¢„æµ‹é˜¶æ®µ - è¿›è¡Œå®é™…é¢„æµ‹
6. ç›‘æ§é˜¶æ®µ - éªŒè¯æ¨¡å‹ç›‘æ§åŠŸèƒ½
7. ç­–ç•¥é›†æˆé˜¶æ®µ - éªŒè¯ç­–ç•¥èƒ½æ­£ç¡®ä½¿ç”¨æ¨¡å‹

Usage:
    poetry run python test_end_to_end_lifecycle.py
"""

import logging
import sys
import tempfile
import shutil
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

import pandas as pd
import numpy as np

# Import the components we want to test
from trading_system.models.training.pipeline import TrainingPipeline
from trading_system.models.training.trainer import TrainingConfig
from trading_system.models.serving.predictor import ModelPredictor
from trading_system.models.base.model_factory import ModelFactory
from trading_system.strategies.core_ffml_strategy import CoreFFMLStrategy
from trading_system.data.yfinance_provider import YFinanceProvider
from trading_system.data.ff5_provider import FF5DataProvider
from trading_system.config.strategy import StrategyConfig
from trading_system.config.backtest import BacktestConfig

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EndToEndLifecycleTest:
    """ç«¯åˆ°ç«¯ç”Ÿå‘½å‘¨æœŸæµ‹è¯•ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        self.test_dir = Path(tempfile.mkdtemp(prefix="e2e_test_"))
        self.registry_path = self.test_dir / "model_registry"
        self.registry_path.mkdir(parents=True, exist_ok=True)

        self.test_symbols = ["AAPL", "MSFT", "GOOGL"]
        self.start_date = datetime(2023, 1, 1)
        self.end_date = datetime(2023, 12, 31)

        # æµ‹è¯•ç»“æœå­˜å‚¨
        self.test_results = {
            'setup': False,
            'training': False,
            'registration': False,
            'deployment': False,
            'prediction': False,
            'monitoring': False,
            'strategy_integration': False
        }

        logger.info(f"ğŸ§ª åˆå§‹åŒ–ç«¯åˆ°ç«¯æµ‹è¯•ç¯å¢ƒ: {self.test_dir}")

    def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.test_dir.exists():
            shutil.rmtree(self.test_dir)
        logger.info("ğŸ§¹ æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†")

    def create_synthetic_data(self) -> tuple[Dict[str, pd.DataFrame], pd.DataFrame]:
        """åˆ›å»ºåˆæˆæµ‹è¯•æ•°æ®"""
        logger.info("ğŸ“Š åˆ›å»ºåˆæˆæµ‹è¯•æ•°æ®...")

        # åˆ›å»ºä»·æ ¼æ•°æ®
        equity_data = {}
        np.random.seed(42)  # ç¡®ä¿å¯é‡ç°

        for i, symbol in enumerate(self.test_symbols):
            # ç”Ÿæˆæ—¥æœŸåºåˆ—
            dates = pd.date_range(start=self.start_date, end=self.end_date, freq='D')

            # ç”Ÿæˆåˆæˆä»·æ ¼æ•°æ®
            n_days = len(dates)

            # åŸºç¡€ä»·æ ¼è¶‹åŠ¿ + éšæœºæ¸¸èµ°
            base_price = 100 + i * 50  # AAPL: 100, MSFT: 150, GOOGL: 200

            # è¶‹åŠ¿ç»„ä»¶
            trend = np.linspace(0, 0.3, n_days)  # 30% å¹´åŒ–å¢é•¿

            # å­£èŠ‚æ€§ç»„ä»¶
            seasonal = 0.1 * np.sin(2 * np.pi * np.arange(n_days) / 60)  # å­£èŠ‚æ€§æ³¢åŠ¨

            # éšæœºæ¸¸èµ°
            random_walk = np.random.normal(0, 0.02, n_days).cumsum()

            # ç»„åˆä»·æ ¼
            price_multiplier = 1 + trend + seasonal + random_walk
            prices = base_price * price_multiplier

            # åˆ›å»ºOHLCVæ•°æ®
            df = pd.DataFrame({
                'date': dates,
                'close': prices,
                'open': prices * np.random.uniform(0.995, 1.005, n_days),
                'high': prices * np.random.uniform(1.0, 1.02, n_days),
                'low': prices * np.random.uniform(0.98, 1.0, n_days),
                'volume': np.random.randint(1_000_000, 10_000_000, n_days)
            })

            # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼æ¨¡æ‹ŸçœŸå®æ•°æ®
            missing_indices = np.random.choice(n_days, size=int(n_days * 0.02), replace=False)
            for idx in missing_indices:
                df.loc[idx, 'volume'] = np.nan

            equity_data[symbol] = df
            logger.info(f"âœ… ç”Ÿæˆ {symbol} æ•°æ®: {len(df)} è¡Œ")

        # åˆ›å»ºFF5å› å­æ•°æ®
        factor_dates = pd.date_range(start=self.start_date, end=self.end_date, freq='M')
        n_factors = len(factor_dates)

        # åˆæˆFF5å› å­ (åŸºäºå†å²ç»Ÿè®¡ç‰¹å¾)
        factor_data = pd.DataFrame({
            'date': factor_dates,
            'MKT': np.random.normal(0.006, 0.045, n_factors),  # å¸‚åœºå› å­
            'SMB': np.random.normal(0.002, 0.030, n_factors),  # è§„æ¨¡å› å­
            'HML': np.random.normal(0.001, 0.025, n_factors),  # ä»·å€¼å› å­
            'RMW': np.random.normal(0.003, 0.020, n_factors),  # ç›ˆåˆ©èƒ½åŠ›å› å­
            'CMA': np.random.normal(0.001, 0.015, n_factors)   # æŠ•èµ„å› å­
        })

        logger.info(f"âœ… ç”Ÿæˆå› å­æ•°æ®: {len(factor_data)} ä¸ªæœˆ")

        return equity_data, factor_data

    def test_setup_phase(self):
        """æµ‹è¯•é˜¶æ®µ1: å‡†å¤‡é˜¶æ®µ"""
        logger.info("\nğŸ”§ é˜¶æ®µ1: å‡†å¤‡æµ‹è¯•ç¯å¢ƒ")

        try:
            # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
            self.equity_data, self.factor_data = self.create_synthetic_data()

            # 2. éªŒè¯æ•°æ®è´¨é‡
            assert len(self.equity_data) == 3, "åº”è¯¥æœ‰3æ”¯è‚¡ç¥¨çš„æ•°æ®"
            assert len(self.factor_data) > 0, "å› å­æ•°æ®ä¸åº”ä¸ºç©º"

            for symbol, data in self.equity_data.items():
                assert len(data) > 200, f"{symbol} åº”è¯¥æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹"
                assert 'close' in data.columns, f"{symbol} åº”è¯¥æœ‰æ”¶ç›˜ä»·æ•°æ®"

            # 3. éªŒè¯æµ‹è¯•ç¯å¢ƒ
            assert self.test_dir.exists(), "æµ‹è¯•ç›®å½•åº”è¯¥å­˜åœ¨"
            assert self.registry_path.exists(), "æ¨¡å‹æ³¨å†Œç›®å½•åº”è¯¥å­˜åœ¨"

            self.test_results['setup'] = True
            logger.info("âœ… å‡†å¤‡é˜¶æ®µå®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ å‡†å¤‡é˜¶æ®µå¤±è´¥: {e}")
            raise

    def test_training_phase(self):
        """æµ‹è¯•é˜¶æ®µ2: è®­ç»ƒé˜¶æ®µ"""
        logger.info("\nğŸš€ é˜¶æ®µ2: æ¨¡å‹è®­ç»ƒ")

        try:
            # 1. åˆ›å»ºè®­ç»ƒé…ç½®
            config = TrainingConfig(
                use_cv=True,
                cv_folds=3,  # å‡å°‘æŠ˜æ•°ä»¥åŠ å¿«æµ‹è¯•
                test_size=0.2,
                random_state=42,
                early_stopping=True,
                validation_split=0.2
            )

            # 2. åˆ›å»ºè®­ç»ƒPipeline
            pipeline = TrainingPipeline(
                model_type="residual_predictor",
                config=config,
                registry_path=str(self.registry_path)
            )

            # 3. æ‰§è¡Œè®­ç»ƒ
            logger.info("å¼€å§‹è®­ç»ƒæ®‹å·®é¢„æµ‹æ¨¡å‹...")
            start_time = datetime.now()

            self.training_result = pipeline.run_pipeline(
                equity_data=self.equity_data,
                factor_data=self.factor_data,
                symbols=self.test_symbols,
                model_name="test_residual_predictor"
            )

            training_time = (datetime.now() - start_time).total_seconds()

            # 4. éªŒè¯è®­ç»ƒç»“æœ
            assert self.training_result is not None, "è®­ç»ƒç»“æœä¸åº”ä¸ºç©º"
            assert 'model_id' in self.training_result, "åº”è¯¥åŒ…å«æ¨¡å‹ID"
            assert 'metrics' in self.training_result, "åº”è¯¥åŒ…å«è®­ç»ƒæŒ‡æ ‡"

            self.model_id = self.training_result['model_id']

            # 5. éªŒè¯è®­ç»ƒæ—¶é—´åˆç† (ä¸è¶…è¿‡5åˆ†é’Ÿ)
            assert training_time < 300, f"è®­ç»ƒæ—¶é—´è¿‡é•¿: {training_time:.2f}ç§’"

            # 6. éªŒè¯æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜
            model_path = self.registry_path / self.model_id
            assert model_path.exists(), f"æ¨¡å‹ç›®å½•åº”è¯¥å­˜åœ¨: {model_path}"
            assert (model_path / "model.pkl").exists(), "æ¨¡å‹æ–‡ä»¶åº”è¯¥å­˜åœ¨"
            assert (model_path / "metadata.json").exists(), "å…ƒæ•°æ®æ–‡ä»¶åº”è¯¥å­˜åœ¨"

            # 7. éªŒè¯å…ƒæ•°æ®å†…å®¹
            with open(model_path / "metadata.json", 'r') as f:
                metadata = json.load(f)

            assert metadata['model_type'] == "residual_predictor", "æ¨¡å‹ç±»å‹åº”è¯¥æ­£ç¡®"
            assert 'trained_at' in metadata, "åº”è¯¥åŒ…å«è®­ç»ƒæ—¶é—´"
            assert metadata['training_samples'] > 0, "åº”è¯¥æœ‰è®­ç»ƒæ ·æœ¬æ•°"

            logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ID: {self.model_id}")
            logger.info(f"   è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
            logger.info(f"   è®­ç»ƒæ ·æœ¬: {metadata['training_samples']}")

            self.test_results['training'] = True

        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒé˜¶æ®µå¤±è´¥: {e}")
            raise

    def test_registration_phase(self):
        """æµ‹è¯•é˜¶æ®µ3: æ³¨å†ŒéªŒè¯é˜¶æ®µ"""
        logger.info("\nğŸ“ é˜¶æ®µ3: æ¨¡å‹æ³¨å†ŒéªŒè¯")

        try:
            # 1. é€šè¿‡ModelFactoryéªŒè¯æ¨¡å‹æ³¨å†Œ
            available_models = ModelFactory._registry
            assert "residual_predictor" in available_models, "æ®‹å·®é¢„æµ‹å™¨åº”è¯¥å·²æ³¨å†Œ"

            # 2. å°è¯•åŠ è½½æ¨¡å‹
            from trading_system.models.base.base_model import BaseModel

            loaded_model = BaseModel.load(self.registry_path / self.model_id)

            # 3. éªŒè¯åŠ è½½çš„æ¨¡å‹
            assert loaded_model is not None, "åŠ è½½çš„æ¨¡å‹ä¸åº”ä¸ºç©º"
            assert hasattr(loaded_model, 'predict'), "æ¨¡å‹åº”è¯¥æœ‰é¢„æµ‹æ–¹æ³•"
            assert hasattr(loaded_model, 'model_type'), "æ¨¡å‹åº”è¯¥æœ‰ç±»å‹å±æ€§"
            assert loaded_model.model_type == "residual_predictor", "æ¨¡å‹ç±»å‹åº”è¯¥æ­£ç¡®"

            # 4. éªŒè¯æ¨¡å‹çŠ¶æ€
            assert hasattr(loaded_model, 'status'), "æ¨¡å‹åº”è¯¥æœ‰çŠ¶æ€å±æ€§"
            assert loaded_model.status in ["trained", "deployed"], f"æ¨¡å‹çŠ¶æ€åº”è¯¥æ­£å¸¸: {loaded_model.status}"

            # 5. éªŒè¯æ¨¡å‹å…ƒæ•°æ®
            assert hasattr(loaded_model, 'metadata'), "æ¨¡å‹åº”è¯¥æœ‰å…ƒæ•°æ®"
            assert loaded_model.metadata.model_type == "residual_predictor", "å…ƒæ•°æ®ç±»å‹åº”è¯¥æ­£ç¡®"
            assert loaded_model.metadata.training_samples > 0, "å…ƒæ•°æ®åº”è¯¥åŒ…å«è®­ç»ƒæ ·æœ¬æ•°"

            logger.info("âœ… æ¨¡å‹æ³¨å†ŒéªŒè¯å®Œæˆ")
            logger.info(f"   æ¨¡å‹ç±»å‹: {loaded_model.model_type}")
            logger.info(f"   æ¨¡å‹çŠ¶æ€: {loaded_model.status}")
            logger.info(f"   è®­ç»ƒæ ·æœ¬: {loaded_model.metadata.training_samples}")

            self.test_results['registration'] = True

        except Exception as e:
            logger.error(f"âŒ æ³¨å†ŒéªŒè¯é˜¶æ®µå¤±è´¥: {e}")
            raise

    def test_deployment_phase(self):
        """æµ‹è¯•é˜¶æ®µ4: ç”Ÿäº§éƒ¨ç½²é˜¶æ®µ"""
        logger.info("\nğŸš€ é˜¶æ®µ4: ç”Ÿäº§éƒ¨ç½²")

        try:
            # 1. åˆ›å»ºModelPredictor
            self.predictor = ModelPredictor(
                model_registry_path=str(self.registry_path),
                enable_monitoring=True,
                cache_predictions=True
            )

            # 2. åŠ è½½æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒ
            deployed_model_id = self.predictor.load_model(
                model_name="residual_predictor",
                model_path=str(self.registry_path / self.model_id)
            )

            # 3. éªŒè¯éƒ¨ç½²ç»“æœ
            assert deployed_model_id is not None, "éƒ¨ç½²çš„æ¨¡å‹IDä¸åº”ä¸ºç©º"
            assert self.predictor.get_current_model() is not None, "å½“å‰åŠ è½½çš„æ¨¡å‹ä¸åº”ä¸ºç©º"
            assert self.predictor.get_current_model_id() == deployed_model_id, "æ¨¡å‹IDåº”è¯¥åŒ¹é…"

            # 4. éªŒè¯Monitoråˆå§‹åŒ–
            health = self.predictor.get_model_health()
            # æ³¨æ„: æ–°æ¨¡å‹å¯èƒ½è¿˜æ²¡æœ‰ç›‘æ§æ•°æ®ï¼Œæ‰€ä»¥healthå¯èƒ½ä¸ºNone
            logger.info(f"æ¨¡å‹å¥åº·çŠ¶æ€: {health.status if health else 'æš‚æ— æ•°æ®'}")

            # 5. éªŒè¯å¯ä»¥è·å–æ¨¡å‹ä¿¡æ¯
            available_models = self.predictor.list_available_models()
            assert "residual_predictor" in available_models, "åº”è¯¥å¯ä»¥åˆ—å‡ºå¯ç”¨æ¨¡å‹"

            model_info = self.predictor.get_model_info("residual_predictor")
            assert model_info is not None, "åº”è¯¥å¯ä»¥è·å–æ¨¡å‹ä¿¡æ¯"
            assert 'description' in model_info, "æ¨¡å‹ä¿¡æ¯åº”è¯¥åŒ…å«æè¿°"

            logger.info("âœ… ç”Ÿäº§éƒ¨ç½²å®Œæˆ")
            logger.info(f"   éƒ¨ç½²æ¨¡å‹ID: {deployed_model_id}")
            logger.info(f"   å¯ç”¨æ¨¡å‹: {available_models}")

            self.test_results['deployment'] = True

        except Exception as e:
            logger.error(f"âŒ éƒ¨ç½²é˜¶æ®µå¤±è´¥: {e}")
            raise

    def test_prediction_phase(self):
        """æµ‹è¯•é˜¶æ®µ5: é¢„æµ‹é˜¶æ®µ"""
        logger.info("\nğŸ”® é˜¶æ®µ5: é¢„æµ‹æµ‹è¯•")

        try:
            # 1. å‡†å¤‡é¢„æµ‹æ•°æ® (ä½¿ç”¨æœ€æ–°çš„æ•°æ®)
            symbol = self.test_symbols[0]  # ä½¿ç”¨AAPL
            latest_data = self.equity_data[symbol].tail(30)  # æœ€è¿‘30å¤©æ•°æ®

            # 2. æ‰§è¡Œé¢„æµ‹
            prediction_result = self.predictor.predict(
                market_data=latest_data,
                symbol=symbol,
                prediction_date=self.end_date
            )

            # 3. éªŒè¯é¢„æµ‹ç»“æœ
            assert prediction_result is not None, "é¢„æµ‹ç»“æœä¸åº”ä¸ºç©º"
            assert 'prediction' in prediction_result, "åº”è¯¥åŒ…å«é¢„æµ‹å€¼"
            assert 'symbol' in prediction_result, "åº”è¯¥åŒ…å«è‚¡ç¥¨ä»£ç "
            assert 'prediction_date' in prediction_result, "åº”è¯¥åŒ…å«é¢„æµ‹æ—¥æœŸ"
            assert 'model_id' in prediction_result, "åº”è¯¥åŒ…å«æ¨¡å‹ID"
            assert 'timestamp' in prediction_result, "åº”è¯¥åŒ…å«æ—¶é—´æˆ³"

            # 4. éªŒè¯é¢„æµ‹å€¼åˆç†æ€§
            prediction_value = prediction_result['prediction']
            assert isinstance(prediction_value, (int, float, np.floating)), "é¢„æµ‹å€¼åº”è¯¥æ˜¯æ•°å€¼"
            assert not np.isnan(prediction_value), "é¢„æµ‹å€¼ä¸åº”è¯¥æ˜¯NaN"
            assert not np.isinf(prediction_value), "é¢„æµ‹å€¼ä¸åº”è¯¥æ˜¯æ— ç©·å¤§"
            assert abs(prediction_value) < 1.0, f"é¢„æµ‹å€¼åº”è¯¥åœ¨åˆç†èŒƒå›´å†…: {prediction_value}"

            # 5. æµ‹è¯•æ‰¹é‡é¢„æµ‹
            batch_results = self.predictor.predict_batch(
                market_data=pd.concat([df.tail(30) for df in self.equity_data.values()],
                                    keys=self.test_symbols),
                symbols=self.test_symbols,
                prediction_date=self.end_date
            )

            # 6. éªŒè¯æ‰¹é‡é¢„æµ‹ç»“æœ
            assert isinstance(batch_results, dict), "æ‰¹é‡é¢„æµ‹ç»“æœåº”è¯¥æ˜¯å­—å…¸"
            assert len(batch_results) <= len(self.test_symbols), "é¢„æµ‹ç»“æœæ•°é‡ä¸åº”è¶…è¿‡è‚¡ç¥¨æ•°é‡"

            for symbol, result in batch_results.items():
                assert 'prediction' in result, f"{symbol} é¢„æµ‹ç»“æœåº”è¯¥åŒ…å«é¢„æµ‹å€¼"
                assert not np.isnan(result['prediction']), f"{symbol} é¢„æµ‹å€¼ä¸åº”è¯¥æ˜¯NaN"

            # 7. éªŒè¯Monitorè®°å½•äº†é¢„æµ‹
            # ç”±äºæˆ‘ä»¬å¯ç”¨äº†ç›‘æ§ï¼Œé¢„æµ‹åº”è¯¥è¢«è®°å½•
            logger.info("âœ… é¢„æµ‹æµ‹è¯•å®Œæˆ")
            logger.info(f"   AAPLé¢„æµ‹å€¼: {prediction_value:.6f}")
            logger.info(f"   æ‰¹é‡é¢„æµ‹: {len(batch_results)} ä¸ªè‚¡ç¥¨")

            self.prediction_results = {
                'single': prediction_result,
                'batch': batch_results
            }

            self.test_results['prediction'] = True

        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹é˜¶æ®µå¤±è´¥: {e}")
            raise

    def test_monitoring_phase(self):
        """æµ‹è¯•é˜¶æ®µ6: ç›‘æ§é˜¶æ®µ"""
        logger.info("\nğŸ“Š é˜¶æ®µ6: ç›‘æ§æµ‹è¯•")

        try:
            # 1. è·å–å½“å‰æ¨¡å‹å¥åº·çŠ¶æ€
            health = self.predictor.get_model_health()

            # 2. æ£€æŸ¥ç›‘æ§åŠŸèƒ½æ˜¯å¦æ­£å¸¸
            # æ³¨æ„: å¯¹äºæ–°æ¨¡å‹ï¼Œå¯èƒ½è¿˜æ²¡æœ‰è¶³å¤Ÿçš„ç›‘æ§æ•°æ®
            if health:
                logger.info(f"æ¨¡å‹å¥åº·çŠ¶æ€: {health.status}")
                logger.info(f"é—®é¢˜åˆ—è¡¨: {health.issues}")
                logger.info(f"å¥åº·æŒ‡æ ‡: {health.metrics}")

                # 3. éªŒè¯å¥åº·çŠ¶æ€åˆç†æ€§
                assert health.status in ['healthy', 'warning', 'critical', 'degraded', 'unknown'], \
                    f"å¥åº·çŠ¶æ€åº”è¯¥æœ‰æ•ˆ: {health.status}"

                # 4. éªŒè¯ç›‘æ§æŒ‡æ ‡
                if health.metrics:
                    for metric_name, metric_value in health.metrics.items():
                        assert isinstance(metric_value, (int, float)), \
                            f"æŒ‡æ ‡å€¼åº”è¯¥æ˜¯æ•°å€¼: {metric_name}={metric_value}"

            else:
                logger.info("æ–°æ¨¡å‹æš‚æ— ç›‘æ§æ•°æ®ï¼Œè¿™æ˜¯æ­£å¸¸çš„")

            # 5. æµ‹è¯•é¢„æµ‹ç¼“å­˜åŠŸèƒ½
            cached_prediction = self.predictor.get_cached_prediction(
                symbol=self.test_symbols[0],
                prediction_date=self.end_date
            )

            # åº”è¯¥èƒ½æ‰¾åˆ°ç¼“å­˜çš„é¢„æµ‹
            if cached_prediction:
                assert 'prediction' in cached_prediction, "ç¼“å­˜çš„é¢„æµ‹åº”è¯¥åŒ…å«é¢„æµ‹å€¼"
                logger.info(f"æ‰¾åˆ°ç¼“å­˜çš„é¢„æµ‹: {cached_prediction['prediction']:.6f}")

            # 6. éªŒè¯ç›‘æ§æ²¡æœ‰æŠ›å‡ºå¼‚å¸¸
            # è¿™å·²ç»é€šè¿‡å‰é¢çš„æ­¥éª¤éªŒè¯äº†

            logger.info("âœ… ç›‘æ§æµ‹è¯•å®Œæˆ")
            self.test_results['monitoring'] = True

        except Exception as e:
            logger.error(f"âŒ ç›‘æ§é˜¶æ®µå¤±è´¥: {e}")
            raise

    def test_strategy_integration_phase(self):
        """æµ‹è¯•é˜¶æ®µ7: ç­–ç•¥é›†æˆé˜¶æ®µ"""
        logger.info("\nğŸ¯ é˜¶æ®µ7: ç­–ç•¥é›†æˆæµ‹è¯•")

        try:
            # 1. åˆ›å»ºç­–ç•¥é…ç½®
            strategy_config = StrategyConfig(
                name="E2E_Test_Strategy",
                parameters={
                    'min_signal_strength': 0.05,
                    'max_position_size': 0.2,
                    'target_positions': len(self.test_symbols)
                },
                lookback_period=252,
                universe=self.test_symbols
            )

            # 2. åˆ›å»ºå›æµ‹é…ç½®
            backtest_config = BacktestConfig(
                start_date=self.start_date,
                end_date=self.end_date,
                initial_capital=1000000,
                symbols=self.test_symbols
            )

            # 3. åˆ›å»ºç­–ç•¥å®ä¾‹
            strategy = CoreFFMLStrategy(
                config=strategy_config,
                backtest_config=backtest_config
            )

            # 4. æ‰‹åŠ¨è®¾ç½®æ¨¡å‹çš„equity_data (ç®€åŒ–æµ‹è¯•)
            strategy.equity_data = self.equity_data
            strategy.factor_data = self.factor_data

            # 5. éªŒè¯ç­–ç•¥å¯ä»¥ç”Ÿæˆä¿¡å·
            # æ³¨æ„: ç”±äºæˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹å¯èƒ½ä¸å‡†ç¡®ï¼Œè¿™é‡Œä¸»è¦æµ‹è¯•æµç¨‹æ˜¯å¦æ­£å¸¸
            try:
                signals = strategy.generate_signals(self.end_date)

                # 6. éªŒè¯ä¿¡å·ç»“æœ
                if signals:
                    logger.info(f"ç­–ç•¥ç”Ÿæˆäº† {len(signals)} ä¸ªä¿¡å·")

                    # éªŒè¯ä¿¡å·æ ¼å¼
                    for signal in signals[:3]:  # åªæ£€æŸ¥å‰3ä¸ªä¿¡å·
                        assert hasattr(signal, 'symbol'), "ä¿¡å·åº”è¯¥æœ‰è‚¡ç¥¨ä»£ç "
                        assert hasattr(signal, 'strength'), "ä¿¡å·åº”è¯¥æœ‰å¼ºåº¦"
                        assert signal.symbol in self.test_symbols, "ä¿¡å·è‚¡ç¥¨åº”è¯¥åœ¨æµ‹è¯•é›†ä¸­"

                    logger.info(f"ç¤ºä¾‹ä¿¡å·: {signals[0].symbol} = {signals[0].strength:.6f}")
                else:
                    logger.info("ç­–ç•¥æœªç”Ÿæˆä¿¡å· (å¯èƒ½æ˜¯é¢„æµ‹å€¼ä¸æ»¡è¶³é˜ˆå€¼)")

            except Exception as e:
                # å¦‚æœä¿¡å·ç”Ÿæˆå¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºæ¨¡å‹é¢„æµ‹é—®é¢˜
                if "No model available" in str(e):
                    logger.warning("ç­–ç•¥æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¿™å¯èƒ½æ˜¯é…ç½®é—®é¢˜")
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œè®°å½•ä½†ç»§ç»­æµ‹è¯•
                    logger.warning(f"ç­–ç•¥ç”Ÿæˆä¿¡å·æ—¶å‡ºç°é—®é¢˜: {e}")

            # 7. éªŒè¯ç­–ç•¥çŠ¶æ€
            strategy_info = strategy.get_strategy_summary()
            assert strategy_info is not None, "ç­–ç•¥ä¿¡æ¯ä¸åº”ä¸ºç©º"
            assert 'strategy_name' in strategy_info, "ç­–ç•¥ä¿¡æ¯åº”è¯¥åŒ…å«åç§°"

            logger.info("âœ… ç­–ç•¥é›†æˆæµ‹è¯•å®Œæˆ")
            logger.info(f"   ç­–ç•¥åç§°: {strategy_info.get('strategy_name')}")
            logger.info(f"   ç­–ç•¥ç±»å‹: {strategy_info.get('strategy_type')}")

            self.test_results['strategy_integration'] = True

        except Exception as e:
            logger.error(f"âŒ ç­–ç•¥é›†æˆé˜¶æ®µå¤±è´¥: {e}")
            # è¿™ä¸ªé˜¶æ®µä¸æ˜¯å…³é”®ï¼Œè®°å½•å¤±è´¥ä½†ä¸ä¸­æ–­æµ‹è¯•
            logger.warning("ç­–ç•¥é›†æˆå¤±è´¥ï¼Œä½†è¿™ä¸å½±å“æ ¸å¿ƒæ¨¡å‹åŠŸèƒ½")

    def run_complete_test(self):
        """è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•"""
        logger.info("ğŸ¯ å¼€å§‹ç«¯åˆ°ç«¯ç”Ÿå‘½å‘¨æœŸæµ‹è¯•")
        logger.info("=" * 60)

        try:
            # æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æµ‹è¯•é˜¶æ®µ
            self.test_setup_phase()
            self.test_training_phase()
            self.test_registration_phase()
            self.test_deployment_phase()
            self.test_prediction_phase()
            self.test_monitoring_phase()
            self.test_strategy_integration_phase()

            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            self.generate_test_report()

        except Exception as e:
            logger.error(f"âŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥: {e}")
            raise
        finally:
            self.cleanup()

    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š ç«¯åˆ°ç«¯æµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 60)

        total_tests = len(self.test_results)
        passed_tests = sum(self.test_results.values())

        for phase, result in self.test_results.items():
            status = "âœ… PASSED" if result else "âŒ FAILED"
            phase_name = {
                'setup': 'å‡†å¤‡é˜¶æ®µ',
                'training': 'è®­ç»ƒé˜¶æ®µ',
                'registration': 'æ³¨å†ŒéªŒè¯',
                'deployment': 'ç”Ÿäº§éƒ¨ç½²',
                'prediction': 'é¢„æµ‹æµ‹è¯•',
                'monitoring': 'ç›‘æ§æµ‹è¯•',
                'strategy_integration': 'ç­–ç•¥é›†æˆ'
            }.get(phase, phase)

            logger.info(f"{phase_name:.<20} {status}")

        logger.info("-" * 60)
        logger.info(f"æ€»è®¡: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")

        if passed_tests == total_tests:
            logger.info("ğŸ‰ æ‰€æœ‰ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿæ¶æ„é‡æ„æˆåŠŸï¼")
            logger.info("\nğŸ’¡ å…³é”®æˆå°±:")
            logger.info("   âœ… æ–°æ¨¡å‹æ¶æ„å·¥ä½œæ­£å¸¸")
            logger.info("   âœ… è®­ç»ƒåˆ°é¢„æµ‹æµç¨‹å®Œæ•´")
            logger.info("   âœ… æ¨¡å‹æ³¨å†Œå’ŒåŠ è½½åŠŸèƒ½æ­£å¸¸")
            logger.info("   âœ… ç”Ÿäº§éƒ¨ç½²å’Œç›‘æ§åŠŸèƒ½æ­£å¸¸")
            logger.info("   âœ… ç­–ç•¥é›†æˆåŸºæœ¬æ­£å¸¸")
            logger.info("\nğŸš€ ç³»ç»Ÿå¯ä»¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨ï¼")
        else:
            failed_count = total_tests - passed_tests
            logger.warning(f"âš ï¸  æœ‰ {failed_count} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")

        logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºå¹¶è¿è¡Œæµ‹è¯•
        test = EndToEndLifecycleTest()
        test.run_complete_test()

        return 0

    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)