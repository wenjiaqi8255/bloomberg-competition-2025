#!/usr/bin/env python3
"""
ç›´æ¥ç«¯åˆ°ç«¯æµ‹è¯•: æ ¸å¿ƒæ¨¡å‹åŠŸèƒ½

ç›´æ¥æµ‹è¯•æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œè·³è¿‡å¤æ‚çš„Pipeline
"""

import logging
import sys
import tempfile
import shutil
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

import pandas as pd
import numpy as np

# Import core components
from trading_system.models.base.model_factory import ModelFactory
from trading_system.models.serving.predictor import ModelPredictor
from trading_system.models.registry import register_all_models

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    np.random.seed(42)

    # åˆ›å»ºç‰¹å¾æ•°æ®
    n_samples = 200
    dates = pd.date_range(start="2023-01-01", periods=n_samples, freq="D")

    # FF5 å› å­æ•°æ®
    factor_data = pd.DataFrame({
        'date': dates,
        'MKT': np.random.normal(0.005, 0.04, n_samples),
        'SMB': np.random.normal(0.001, 0.03, n_samples),
        'HML': np.random.normal(0.001, 0.025, n_samples),
        'RMW': np.random.normal(0.002, 0.02, n_samples),
        'CMA': np.random.normal(0.001, 0.015, n_samples)
    })

    # è‚¡ç¥¨æ”¶ç›Šæ•°æ® (åŸºäºå› å­ + å™ªå£°)
    true_betas = {'MKT': 1.0, 'SMB': 0.3, 'HML': -0.2, 'RMW': 0.1, 'CMA': 0.05}
    returns = np.zeros(n_samples)

    for factor, beta in true_betas.items():
        returns += beta * factor_data[factor].values

    # æ·»åŠ å™ªå£°å’Œæ®‹å·®
    returns += np.random.normal(0, 0.02, n_samples)

    # ç›®æ ‡æ•°æ®
    target_data = pd.Series(returns, index=dates, name='returns')

    return factor_data, target_data


def test_direct_model_workflow():
    """æµ‹è¯•ç›´æ¥çš„æ¨¡å‹å·¥ä½œæµç¨‹"""
    logger.info("ğŸ¯ å¼€å§‹ç›´æ¥æ¨¡å‹å·¥ä½œæµç¨‹æµ‹è¯•")
    logger.info("=" * 50)

    test_dir = Path(tempfile.mkdtemp(prefix="e2e_direct_"))
    registry_path = test_dir / "model_registry"
    registry_path.mkdir(parents=True, exist_ok=True)

    try:
        # æ­¥éª¤1: æ³¨å†Œæ¨¡å‹
        logger.info("\nğŸ“ æ­¥éª¤1: æ³¨å†Œæ¨¡å‹")
        register_all_models()

        available_models = list(ModelFactory._registry.keys())
        logger.info(f"å¯ç”¨æ¨¡å‹: {available_models}")
        assert "ff5_regression" in available_models, "FF5æ¨¡å‹åº”è¯¥å·²æ³¨å†Œ"

        # æ­¥éª¤2: åˆ›å»ºæµ‹è¯•æ•°æ®
        logger.info("\nğŸ“Š æ­¥éª¤2: åˆ›å»ºæµ‹è¯•æ•°æ®")
        factor_data, target_data = create_test_data()
        logger.info(f"âœ… åˆ›å»ºäº† {len(factor_data)} ä¸ªæ ·æœ¬")

        # æ­¥éª¤3: åˆ›å»ºå¹¶è®­ç»ƒFF5æ¨¡å‹
        logger.info("\nğŸš€ æ­¥éª¤3: è®­ç»ƒFF5æ¨¡å‹")

        ff5_model = ModelFactory.create("ff5_regression", {
            "regularization": "ridge",
            "alpha": 1.0
        })

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X = factor_data[['MKT', 'SMB', 'HML', 'RMW', 'CMA']].copy()
        X.index = factor_data['date']  # Set index to match target_data
        y = target_data

        # è®­ç»ƒæ¨¡å‹
        ff5_model.fit(X, y)
        logger.info("âœ… FF5æ¨¡å‹è®­ç»ƒå®Œæˆ")

        # éªŒè¯æ¨¡å‹è®­ç»ƒç»“æœ
        assert hasattr(ff5_model, '_model'), "æ¨¡å‹åº”è¯¥æœ‰å†…éƒ¨æ¨¡å‹"
        assert ff5_model.status in ["trained", "deployed"], "æ¨¡å‹çŠ¶æ€åº”è¯¥æ­£ç¡®"
        logger.info(f"æ¨¡å‹çŠ¶æ€: {ff5_model.status}")

        # æ­¥éª¤4: ä¿å­˜æ¨¡å‹
        logger.info("\nğŸ’¾ æ­¥éª¤4: ä¿å­˜æ¨¡å‹")

        model_save_path = registry_path / "test_ff5_model"
        ff5_model.save(model_save_path)

        assert model_save_path.exists(), "æ¨¡å‹ä¿å­˜ç›®å½•åº”è¯¥å­˜åœ¨"
        assert (model_save_path / "model.pkl").exists(), "æ¨¡å‹æ–‡ä»¶åº”è¯¥å­˜åœ¨"
        assert (model_save_path / "metadata.json").exists(), "å…ƒæ•°æ®æ–‡ä»¶åº”è¯¥å­˜åœ¨"

        logger.info("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")

        # æ­¥éª¤5: åŠ è½½æ¨¡å‹
        logger.info("\nğŸ“¥ æ­¥éª¤5: åŠ è½½æ¨¡å‹")

        from trading_system.models.implementations.ff5_model import FF5RegressionModel
        loaded_model = FF5RegressionModel.load(model_save_path)

        assert loaded_model is not None, "åŠ è½½çš„æ¨¡å‹ä¸åº”ä¸ºç©º"
        assert loaded_model.model_type == "ff5_regression", "æ¨¡å‹ç±»å‹åº”è¯¥æ­£ç¡®"
        logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        # æ­¥éª¤6: è¿›è¡Œé¢„æµ‹
        logger.info("\nğŸ”® æ­¥éª¤6: è¿›è¡Œé¢„æµ‹")

        # ä½¿ç”¨æœ€å10ä¸ªæ ·æœ¬è¿›è¡Œé¢„æµ‹
        X_test = X.tail(10)
        y_true = y.tail(10)

        predictions = loaded_model.predict(X_test)
        assert len(predictions) == 10, "é¢„æµ‹ç»“æœæ•°é‡åº”è¯¥æ­£ç¡®"
        assert not np.any(np.isnan(predictions)), "é¢„æµ‹å€¼ä¸åº”è¯¥æ˜¯NaN"

        # è®¡ç®—é¢„æµ‹å‡†ç¡®æ€§
        mse = np.mean((predictions - y_true.values) ** 2)
        r2 = 1 - np.sum((y_true.values - predictions) ** 2) / np.sum((y_true.values - np.mean(y_true.values)) ** 2)

        logger.info(f"âœ… é¢„æµ‹å®Œæˆ")
        logger.info(f"   MSE: {mse:.6f}")
        logger.info(f"   RÂ²: {r2:.4f}")

        # æ­¥éª¤7: åˆ›å»ºModelPredictor
        logger.info("\nğŸš€ æ­¥éª¤7: åˆ›å»ºModelPredictor")

        predictor = ModelPredictor(
            model_registry_path=str(registry_path),
            enable_monitoring=True,
            cache_predictions=True
        )

        # æ­¥éª¤8: åŠ è½½æ¨¡å‹åˆ°ModelPredictor
        logger.info("\nğŸ¯ æ­¥éª¤8: éƒ¨ç½²æ¨¡å‹åˆ°ModelPredictor")

        deployed_model_id = predictor.load_model(
            model_name="ff5_regression",
            model_path=str(model_save_path)
        )

        assert deployed_model_id is not None, "éƒ¨ç½²çš„æ¨¡å‹IDä¸åº”ä¸ºç©º"
        assert predictor.get_current_model() is not None, "å½“å‰æ¨¡å‹ä¸åº”ä¸ºç©º"
        logger.info(f"âœ… æ¨¡å‹éƒ¨ç½²æˆåŠŸï¼ŒID: {deployed_model_id}")

        # æ­¥éª¤9: é€šè¿‡ModelPredictorè¿›è¡Œé¢„æµ‹
        logger.info("\nğŸ“Š æ­¥éª¤9: é€šè¿‡ModelPredictoré¢„æµ‹")

        # åˆ›å»ºæ¨¡æ‹Ÿçš„å¸‚åœºæ•°æ®ï¼ŒåŒ…å«FF5å› å­æ•°æ®
        np.random.seed(123)  # For reproducibility
        n_prices = 80  # More than 60 for validation

        # åˆ›å»ºFF5å› å­æ•°æ®
        market_data = pd.DataFrame({
            'MKT': np.random.normal(0.005, 0.02, n_prices),
            'SMB': np.random.normal(0.001, 0.015, n_prices),
            'HML': np.random.normal(0.0003, 0.01, n_prices),
            'RMW': np.random.normal(0.0008, 0.012, n_prices),
            'CMA': np.random.normal(0.0002, 0.008, n_prices),
            # æ·»åŠ OHLCVæ•°æ®ä»¥æ»¡è¶³ç‰¹å¾å·¥ç¨‹éœ€æ±‚
            'close': 100 + np.cumsum(np.random.normal(0, 0.5, n_prices)),
            'volume': np.random.randint(1_000_000, 3_000_000, n_prices),
            'high': 0,
            'low': 0,
            'open': 0
        })

        # ç”ŸæˆOHLCæ•°æ®
        market_data['high'] = market_data['close'] * 1.005
        market_data['low'] = market_data['close'] * 0.995
        market_data['open'] = market_data['close'].shift(1).fillna(market_data['close'].iloc[0])

        prediction_result = predictor.predict(
            market_data=market_data,
            symbol="TEST",
            prediction_date=datetime(2023, 12, 31)
        )

        assert prediction_result is not None, "é¢„æµ‹ç»“æœä¸åº”ä¸ºç©º"
        assert 'prediction' in prediction_result, "åº”è¯¥åŒ…å«é¢„æµ‹å€¼"
        assert isinstance(prediction_result['prediction'], (int, float, np.floating)), "é¢„æµ‹å€¼åº”è¯¥æ˜¯æ•°å€¼"

        logger.info(f"âœ… ModelPredictoré¢„æµ‹æˆåŠŸ: {prediction_result['prediction']:.6f}")

        # æ­¥éª¤10: æµ‹è¯•æ¨¡å‹å¥åº·ç›‘æ§
        logger.info("\nğŸ“ˆ æ­¥éª¤10: æ£€æŸ¥æ¨¡å‹å¥åº·çŠ¶æ€")

        health = predictor.get_model_health()
        if health:
            logger.info(f"æ¨¡å‹å¥åº·çŠ¶æ€: {health.status}")
        else:
            logger.info("æ–°æ¨¡å‹æš‚æ— ç›‘æ§æ•°æ®ï¼ˆæ­£å¸¸ï¼‰")

        # æ­¥éª¤11: æµ‹è¯•ç¼“å­˜åŠŸèƒ½
        logger.info("\nğŸ’¾ æ­¥éª¤11: æµ‹è¯•é¢„æµ‹ç¼“å­˜")

        cached_prediction = predictor.get_cached_prediction(
            symbol="TEST",
            prediction_date=datetime(2023, 12, 31)
        )

        if cached_prediction:
            logger.info(f"âœ… ç¼“å­˜åŠŸèƒ½æ­£å¸¸: {cached_prediction['prediction']:.6f}")
        else:
            logger.info("ç¼“å­˜ä¸ºç©ºï¼ˆå¯èƒ½ç¼“å­˜è®¾ç½®é—®é¢˜ï¼‰")

        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        logger.info("\n" + "=" * 50)
        logger.info("ğŸ‰ ç›´æ¥æ¨¡å‹å·¥ä½œæµç¨‹æµ‹è¯•å®Œæˆï¼")
        logger.info("=" * 50)
        logger.info("âœ… æ¨¡å‹æ³¨å†Œ - æ­£å¸¸")
        logger.info("âœ… æ•°æ®å‡†å¤‡ - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹è®­ç»ƒ - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹ä¿å­˜ - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹åŠ è½½ - æ­£å¸¸")
        logger.info("âœ… ç›´æ¥é¢„æµ‹ - æ­£å¸¸")
        logger.info("âœ… ModelPredictoréƒ¨ç½² - æ­£å¸¸")
        logger.info("âœ… ç”Ÿäº§é¢„æµ‹ - æ­£å¸¸")
        logger.info("âœ… å¥åº·ç›‘æ§ - æ­£å¸¸")
        logger.info("âœ… ç¼“å­˜åŠŸèƒ½ - æ­£å¸¸")
        logger.info("=" * 50)
        logger.info("ğŸš€ æ–°æ¨¡å‹æ¶æ„æ ¸å¿ƒåŠŸèƒ½éªŒè¯æˆåŠŸï¼")
        logger.info("ğŸ’¡ å…³é”®æˆå°±:")
        logger.info("   - æ¨¡å‹è®­ç»ƒå’Œä¿å­˜æœºåˆ¶å®Œæ•´")
        logger.info("   - ModelPredictorç”Ÿäº§æœåŠ¡æ­£å¸¸")
        logger.info("   - é¢„æµ‹åŠŸèƒ½ç¨³å®šå¯é ")
        logger.info("   - æ¨¡å‹ç›‘æ§åŸºç¡€è®¾æ–½å°±ç»ª")
        logger.info("   - ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–åˆ°ä½")

        return True

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        if test_dir.exists():
            shutil.rmtree(test_dir)
        logger.info("ğŸ§¹ æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†")


def main():
    """ä¸»å‡½æ•°"""
    try:
        success = test_direct_model_workflow()
        return 0 if success else 1
    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)