ä½œä¸ºæ¶æ„å¸ˆï¼Œæˆ‘æ¥å¸®ä½ åˆ†æå½“å‰ç³»ç»Ÿçš„é—®é¢˜å’Œæ”¹è¿›æ–¹æ¡ˆã€‚

## å½“å‰ç³»ç»Ÿçš„æ ¸å¿ƒé—®é¢˜è¯Šæ–­

### 1. **æ¶æ„å±‚é¢çš„æ–­è£‚**

ä½ çš„ç³»ç»Ÿå­˜åœ¨æ˜æ˜¾çš„"ä¸¤å¥—ä½“ç³»"ï¼š

**å•æ¨¡å‹ä½“ç³»ï¼ˆæˆç†Ÿï¼‰ï¼š**
- `ExperimentOrchestrator` â†’ `TrainingPipeline` â†’ `StrategyRunner`
- å®Œæ•´çš„æ•°æ®æµï¼šData Provider â†’ Feature Engineering â†’ Model Training â†’ Prediction â†’ Backtest
- æœ‰çœŸå®çš„å›æµ‹ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

**å¤šæ¨¡å‹ä½“ç³»ï¼ˆä¸æˆç†Ÿï¼‰ï¼š**
- `MultiModelOrchestrator` â†’ `ModelTrainerWithHPO` â†’ `MetaModelTrainerWithHPO`
- ç¼ºå¤±ç¯èŠ‚ï¼šæ²¡æœ‰çœŸæ­£è°ƒç”¨ `StrategyRunner`ï¼Œæ²¡æœ‰çœŸå®å›æµ‹
- ä½¿ç”¨åˆæˆæ•°æ®ï¼ˆsynthetic predictionsï¼‰è€ŒéçœŸå®ç­–ç•¥æ”¶ç›Š

### 2. **æ•°æ®æµæ–­è£‚çš„å…·ä½“è¡¨ç°**

ä»æ—¥å¿—å¯ä»¥çœ‹åˆ°ï¼š
```
WARNING - Returns file not found for strategy: xgboost_5trials_20251010_233931
WARNING - Failed to collect from backtest results
INFO - Fallback: Creating prediction signals from model performance
INFO - Generated synthetic predictions for 1 models
```

è¿™è¯´æ˜å…ƒæ¨¡å‹æ ¹æœ¬æ²¡æœ‰æ‹¿åˆ°çœŸå®çš„ç­–ç•¥æ”¶ç›Šæ•°æ®ï¼Œåªèƒ½ç”¨æ¨¡æ‹Ÿæ•°æ®å‡‘åˆã€‚

### 3. **HPOé›†æˆé—®é¢˜**

- `ModelTrainerWithHPO` è‡ªå·±å®ç°äº†ä¸€å¥—HPOé€»è¾‘
- æ²¡æœ‰å¤ç”¨ `ExperimentOrchestrator` å·²ç»éªŒè¯è¿‡çš„å®Œæ•´æµç¨‹
- Walk-forward CV å®ç°åœ¨ `objective` å‡½æ•°é‡Œï¼Œä½†æ²¡æœ‰çœŸæ­£æ‰§è¡Œç­–ç•¥å›æµ‹

## é‡‘èä¸“ä¸šè§†è§’çš„æ¶æ„å»ºè®®

### æ ¸å¿ƒç†å¿µï¼šç¡®ä¿ç­–ç•¥æ”¶ç›Šçš„çœŸå®æ€§

åœ¨é‡åŒ–äº¤æ˜“ä¸­ï¼Œ**ç­–ç•¥çš„å†å²æ”¶ç›Šæ›²çº¿æ˜¯å…ƒæ¨¡å‹è®­ç»ƒçš„å”¯ä¸€çœŸç›¸**ã€‚ä½ ä¸èƒ½ç”¨ï¼š
- æ¨¡å‹çš„è®­ç»ƒé›† RÂ²
- æ¨¡æ‹Ÿçš„ä¿¡å·å¼ºåº¦
- CV fold çš„å¹³å‡åˆ†æ•°

æ¥ä»£æ›¿çœŸå®çš„ç­–ç•¥å›æµ‹æ”¶ç›Šã€‚

### æ¨èçš„æ•°æ®æµæ¶æ„

```
Base Model Training Phase:
æ¯ä¸ªæ¨¡å‹ â†’ TrainingPipeline â†’ ä¿å­˜æ¨¡å‹
       â†“
       PredictionPipeline â†’ ç”Ÿæˆä¿¡å·
       â†“
       StrategyRunner â†’ å›æµ‹ â†’ ä¿å­˜æ”¶ç›Šæ›²çº¿
       â†“
       å­˜å‚¨ï¼šresults/{model_id}/returns.csv

MetaModel Training Phase:
è¯»å–æ‰€æœ‰ returns.csv â†’ æ„å»ºæ”¶ç›ŠçŸ©é˜µ R
       â†“
       MetaModel.fit(R, benchmark) â†’ å­¦ä¹ æƒé‡
       â†“
       MetaModel.predict(R) â†’ ç»„åˆç­–ç•¥
       â†“
       StrategyRunner â†’ å›æµ‹ç»„åˆç­–ç•¥ â†’ éªŒè¯æ”¹è¿›
```

## è½¯ä»¶å·¥ç¨‹è§†è§’çš„é‡æ„æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šæœ€å°æ”¹åŠ¨ - ä¿®å¤ç°æœ‰æµç¨‹

**ä¼˜ç‚¹ï¼š**
- ä»£ç æ”¹åŠ¨é‡å°
- ä¿æŒç°æœ‰ç»“æ„

**éœ€è¦ä¿®å¤çš„å…³é”®ç‚¹ï¼š**

1. **åœ¨ `ModelTrainerWithHPO.optimize_and_train()` ä¸­ï¼š**
   - HPO å®Œæˆåï¼Œä¸è¦åªä¿å­˜æ¨¡å‹
   - å¿…é¡»è°ƒç”¨å®Œæ•´çš„é¢„æµ‹+å›æµ‹æµç¨‹
   - ä¿å­˜ç­–ç•¥æ”¶ç›Šåˆ°æ ‡å‡†ä½ç½®

2. **åœ¨ `MetaModelTrainerWithHPO._collect_model_predictions()` ä¸­ï¼š**
   - åˆ é™¤ fallback é€»è¾‘ï¼ˆç”Ÿæˆåˆæˆæ•°æ®ï¼‰
   - å¦‚æœæ‰¾ä¸åˆ°å›æµ‹ç»“æœï¼Œåº”è¯¥æŠ¥é”™è€Œä¸æ˜¯ç”¨å‡æ•°æ®
   - å¼ºåˆ¶è¦æ±‚æ‰€æœ‰åŸºç¡€æ¨¡å‹éƒ½æœ‰çœŸå®å›æµ‹ç»“æœ

3. **æ•°æ®å­˜å‚¨æ ‡å‡†åŒ–ï¼š**
   - ç»Ÿä¸€è·¯å¾„ï¼š`results/{model_id}/strategy_returns.csv`
   - ç»Ÿä¸€æ ¼å¼ï¼šæ—¥æœŸç´¢å¼•ï¼Œå•åˆ—æ”¶ç›Šç‡
   - æ·»åŠ å…ƒæ•°æ®ï¼š`results/{model_id}/metadata.json`

### æ–¹æ¡ˆBï¼šæ¨èæ–¹æ¡ˆ - ç»„åˆå¼æ¶æ„

**ä¼˜ç‚¹ï¼š**
- å®Œå…¨å¤ç”¨å·²éªŒè¯çš„ç»„ä»¶
- é€»è¾‘æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤
- ç¬¦åˆå•ä¸€èŒè´£åŸåˆ™

**æ¶æ„è®¾è®¡ï¼š**

```
MultiModelOrchestrator çš„èŒè´£ï¼š
â”œâ”€ ç¼–æ’è€…ï¼ˆOrchestratorï¼‰ï¼Œä¸å®ç°å…·ä½“é€»è¾‘
â”œâ”€ Phase 1: è®­ç»ƒåŸºç¡€æ¨¡å‹
â”‚  â””â”€ å¾ªç¯è°ƒç”¨ ExperimentOrchestrator.run_experiment()
â”‚     â”œâ”€ æ¯æ¬¡è°ƒç”¨ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ model + backtest
â”‚     â”œâ”€ æ”¶é›†æ¯ä¸ªå®éªŒçš„ model_id å’Œ performance_metrics
â”‚     â””â”€ ç¡®ä¿æ‰€æœ‰ç­–ç•¥æ”¶ç›Šéƒ½è¢«æ­£ç¡®ä¿å­˜
â”œâ”€ Phase 2: æ”¶é›†ç­–ç•¥æ”¶ç›Š
â”‚  â””â”€ StrategyDataCollector.collect_from_backtest_results()
â”‚     â”œâ”€ è¯»å–æ‰€æœ‰ returns.csv
â”‚     â”œâ”€ å¯¹é½æ—¶é—´åºåˆ—
â”‚     â””â”€ æ„å»ºæ”¶ç›ŠçŸ©é˜µ R (dates Ã— strategies)
â”œâ”€ Phase 3: è®­ç»ƒå…ƒæ¨¡å‹
â”‚  â””â”€ MetaModelPipelineï¼ˆå·²æœ‰çš„ç®€åŒ–ç‰ˆæœ¬ï¼‰
â”‚     â”œâ”€ fit(R, benchmark)
â”‚     â”œâ”€ å­¦ä¹ ç­–ç•¥æƒé‡
â”‚     â””â”€ ä¿å­˜å…ƒæ¨¡å‹
â””â”€ Phase 4: å›æµ‹ç»„åˆç­–ç•¥
   â””â”€ å†æ¬¡è°ƒç”¨ StrategyRunner
      â”œâ”€ ä½¿ç”¨å…ƒæ¨¡å‹ä½œä¸º"ç­–ç•¥"
      â”œâ”€ ç”Ÿæˆç»„åˆåçš„äº¤æ˜“ä¿¡å·
      â””â”€ éªŒè¯æ˜¯å¦æœ‰æ”¹è¿›
```

### æ–¹æ¡ˆCï¼šæ¿€è¿›æ–¹æ¡ˆ - ç®¡é“åŒ–é‡æ„

**ä¼˜ç‚¹ï¼š**
- æœ€ä¼˜é›…çš„æ¶æ„
- å¯æ‰©å±•æ€§å¼º

**è®¾è®¡ï¼š**

åˆ›å»º `ExperimentPipeline` æŠ½è±¡åŸºç±»ï¼š
- `SingleModelExperiment` ç»§æ‰¿å®ƒ
- `MultiModelExperiment` ç»§æ‰¿å®ƒ

ä¸¤è€…å…±äº«ï¼š
- `DataLoader` ç»„ä»¶
- `FeatureEngineering` ç»„ä»¶  
- `BacktestRunner` ç»„ä»¶
- `ResultCollector` ç»„ä»¶

## å…·ä½“å®æ–½å»ºè®®

### ç«‹å³è¡ŒåŠ¨ï¼ˆä¿®å¤æ•°æ®æµï¼‰ï¼š

1. **ä¿®æ”¹ `ModelTrainerWithHPO.optimize_and_train()`**
   - åœ¨ HPO å®Œæˆåï¼Œæ·»åŠ å®Œæ•´çš„é¢„æµ‹å’Œå›æµ‹æ­¥éª¤
   - ä½¿ç”¨ `ExperimentOrchestrator` çš„å›æµ‹é€»è¾‘ï¼Œä¸è¦é‡æ–°å®ç°
   - ç¡®ä¿ç”Ÿæˆ `strategy_returns.csv`

2. **åˆ é™¤æ‰€æœ‰ fallback é€»è¾‘**
   - `MetaModelTrainerWithHPO._collect_model_predictions()` ä¸­çš„åˆæˆæ•°æ®ç”Ÿæˆ
   - å¦‚æœæ•°æ®ç¼ºå¤±ï¼Œæ˜ç¡®æŠ¥é”™

3. **ç»Ÿä¸€æ•°æ®å­˜å‚¨æ ¼å¼**
   - å®šä¹‰ `ResultsSchema` ç±»
   - æ‰€æœ‰ç»„ä»¶éƒ½ä½¿ç”¨ç›¸åŒçš„ä¿å­˜/è¯»å–æ¥å£

### çŸ­æœŸä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰ï¼š

1. **å®ç°æ–¹æ¡ˆBçš„ç»„åˆå¼æ¶æ„**
   - `MultiModelOrchestrator` å˜æˆçº¯ç¼–æ’è€…
   - æ¯ä¸ªåŸºç¡€æ¨¡å‹é€šè¿‡ `ExperimentOrchestrator` å®Œæ•´è¿è¡Œ
   - å…ƒæ¨¡å‹è®­ç»ƒä½¿ç”¨çœŸå®æ•°æ®

2. **æ·»åŠ æ•°æ®éªŒè¯å±‚**
   - åœ¨å…ƒæ¨¡å‹è®­ç»ƒå‰ï¼ŒéªŒè¯æ‰€æœ‰ç­–ç•¥æ”¶ç›Šæ•°æ®
   - æ£€æŸ¥æ—¶é—´å¯¹é½ã€ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼

3. **æ”¹è¿› HPO é›†æˆ**
   - HPO åº”è¯¥ä¼˜åŒ–çš„æ˜¯"ç­–ç•¥çš„å¤æ™®æ¯”ç‡"ï¼Œè€Œä¸æ˜¯"æ¨¡å‹çš„ RÂ²"
   - æ¯ä¸ª HPO trial éƒ½åº”è¯¥è¿è¡Œå®Œæ•´å›æµ‹

### ä¸­æœŸé‡æ„ï¼ˆ1ä¸ªæœˆï¼‰ï¼š

1. **è€ƒè™‘å®æ–½æ–¹æ¡ˆC**
   - å¦‚æœä½ è®¡åˆ’é•¿æœŸç»´æŠ¤è¿™ä¸ªç³»ç»Ÿ
   - æå–å…±äº«ç»„ä»¶ï¼Œå‡å°‘ä»£ç é‡å¤

2. **å¢å¼ºå…ƒæ¨¡å‹åŠŸèƒ½**
   - åŠ¨æ€æƒé‡è°ƒæ•´
   - åæ–¹å·®çŸ©é˜µä¼°è®¡
   - é£é™©å¹³ä»·ï¼ˆRisk Parityï¼‰æ–¹æ³•

## å…³é”®è®¾è®¡åŸåˆ™

### é‡‘èåŸåˆ™ï¼š

1. **No Synthetic Data in Production Pipeline**
   - æ°¸è¿œä½¿ç”¨çœŸå®å¸‚åœºæ•°æ®å’ŒçœŸå®å›æµ‹ç»“æœ

2. **Consistent Feature Engineering**
   - è®­ç»ƒå’Œé¢„æµ‹å¿…é¡»ä½¿ç”¨å®Œå…¨ç›¸åŒçš„ç‰¹å¾å¤„ç†

3. **Walk-Forward Validation**
   - HPO å’Œæœ€ç»ˆè¯„ä¼°éƒ½è¦ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
   - ä½† HPO å¯ä»¥åœ¨è®­ç»ƒé›†å†…éƒ¨åš CVï¼Œæœ€ç»ˆè¯„ä¼°å¿…é¡»åœ¨æµ‹è¯•é›†

### è½¯ä»¶åŸåˆ™ï¼š

1. **Single Source of Truth**
   - å›æµ‹é€»è¾‘åªåœ¨ `StrategyRunner` ä¸­å®ç°
   - å…¶ä»–ç»„ä»¶è°ƒç”¨å®ƒï¼Œä¸è¦é‡æ–°å®ç°

2. **Interface Segregation**
   - `IDataProvider`, `IModel`, `IStrategy` ç­‰æ¥å£
   - ç»„ä»¶é—´é€šè¿‡æ¥å£é€šä¿¡

3. **Fail Fast**
   - æ•°æ®ç¼ºå¤±æ—¶ç«‹å³æŠ¥é”™
   - ä¸è¦ç”¨é»˜è®¤å€¼æˆ–æ¨¡æ‹Ÿæ•°æ®æ©ç›–é—®é¢˜

## éªŒè¯æ¸…å•

ä¿®æ”¹å®Œæˆåï¼Œæ£€æŸ¥ï¼š

- [ ] æ¯ä¸ªåŸºç¡€æ¨¡å‹éƒ½æœ‰å®Œæ•´çš„å›æµ‹ç»“æœæ–‡ä»¶
- [ ] å…ƒæ¨¡å‹è®­ç»ƒæ—¶æ²¡æœ‰ä½¿ç”¨ä»»ä½•åˆæˆæ•°æ®
- [ ] æ‰€æœ‰ HPO trial éƒ½åŸºäºçœŸå®ç­–ç•¥æ€§èƒ½æŒ‡æ ‡
- [ ] å…ƒæ¨¡å‹çš„ç»„åˆç­–ç•¥å¯ä»¥ç‹¬ç«‹å›æµ‹éªŒè¯
- [ ] è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸¥æ ¼åˆ†ç¦»
- [ ] ç‰¹å¾å·¥ç¨‹åœ¨è®­ç»ƒå’Œé¢„æµ‹æ—¶å®Œå…¨ä¸€è‡´

---

ä½ ç°åœ¨æœ€ç´§æ€¥çš„ä»»åŠ¡æ˜¯**ä¿®å¤æ•°æ®æµ**ï¼Œç¡®ä¿å…ƒæ¨¡å‹èƒ½æ‹¿åˆ°çœŸå®çš„ç­–ç•¥æ”¶ç›Šæ•°æ®ã€‚å»ºè®®ä»æ–¹æ¡ˆBå¼€å§‹ï¼Œå› ä¸ºå®ƒåœ¨ä¸ç ´åç°æœ‰æ¶æ„çš„å‰æä¸‹ï¼Œèƒ½æœ€å¿«è§£å†³é—®é¢˜ã€‚

---

# å®ç°è¿›åº¦è®°å½•

## âœ… å·²å®Œæˆçš„æ¨¡å—

### 1. å‡†å¤‡å·¥ä½œ - æµ‹è¯•åŸºç¡€è®¾æ–½
- **çŠ¶æ€**: âœ… å®Œæˆ
- **æ–‡ä»¶**: 
  - `tests/test_multi_model/__init__.py` - æµ‹è¯•ç›®å½•ç»“æ„
  - `configs/multi_model_test_minimal.yaml` - æœ€å°æµ‹è¯•é…ç½®
- **è¯´æ˜**: åˆ›å»ºäº†æµ‹è¯•åŸºç¡€è®¾æ–½å’Œæœ€å°æµ‹è¯•é…ç½®ï¼Œä½¿ç”¨2ä¸ªæ¨¡å‹å’Œ1ä¸ªæœˆæ•°æ®è¿›è¡Œå¿«é€ŸéªŒè¯

### 2. ModelConfigGenerator - é…ç½®ç”Ÿæˆå™¨
- **çŠ¶æ€**: âœ… å®Œæˆ
- **æ–‡ä»¶**: 
  - `src/use_case/multi_model_experiment/components/config_generator.py`
  - `tests/test_multi_model/test_config_generator.py`
- **åŠŸèƒ½**: 
  - ä»å¤šæ¨¡å‹é…ç½®ç”Ÿæˆå•æ¨¡å‹å®éªŒé…ç½®
  - æ”¯æŒHPOå‚æ•°æ³¨å…¥
  - ä¿æŒé…ç½®ç»“æ„å®Œæ•´æ€§
  - æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ (11/11)
- **éªŒè¯**: âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡

### 3. ExperimentOrchestrator å¢å¼º
- **çŠ¶æ€**: âœ… å®Œæˆ
- **æ–‡ä»¶**: `src/use_case/single_experiment/experiment_orchestrator.py`
- **æ–°å¢åŠŸèƒ½**:
  - `_save_strategy_returns()` - ä¿å­˜ç­–ç•¥æ”¶ç›Šä¸ºæ ‡å‡†æ ¼å¼
  - `get_strategy_returns_path()` - è·å–ç­–ç•¥æ”¶ç›Šæ–‡ä»¶è·¯å¾„
  - `get_results_directory()` - è·å–ç»“æœç›®å½•è·¯å¾„
  - åœ¨ `run_experiment()` ä¸­è‡ªåŠ¨ä¿å­˜ç­–ç•¥æ”¶ç›Š
  - è¿”å›ç»“æœä¸­åŒ…å« `returns_path` å­—æ®µ

### 4. EnhancedStrategyDataCollector - å¢å¼ºæ•°æ®æ”¶é›†å™¨
- **çŠ¶æ€**: âœ… å®Œæˆ
- **æ–‡ä»¶**: `src/trading_system/data/enhanced_strategy_data_collector.py`
- **åŠŸèƒ½**:
  - æ”¯æŒæ–°çš„æ ‡å‡†åŒ–æ”¶ç›Šæ ¼å¼ (`strategy_returns.csv`)
  - å¢å¼ºçš„é”™è¯¯å¤„ç†å’Œè¯¦ç»†æ—¥å¿—
  - æ•°æ®è´¨é‡éªŒè¯ (æç«¯å€¼ã€ç¼ºå¤±å€¼ã€æ—¶é—´è¿ç»­æ€§)
  - ä¸¥æ ¼æ¨¡å¼ï¼šæ•°æ®ç¼ºå¤±æ—¶æŠ¥é”™ï¼Œä¸ä½¿ç”¨åˆæˆæ•°æ®
  - `DataCollectionError` å¼‚å¸¸ç±»

### 5. ResultValidator - ç»“æœéªŒè¯å·¥å…·
- **çŠ¶æ€**: âœ… å®Œæˆ
- **æ–‡ä»¶**: `src/trading_system/validation/result_validator.py`
- **åŠŸèƒ½**:
  - éªŒè¯å®éªŒç»“æœå­—å…¸
  - éªŒè¯æ”¶ç›Šæ–‡ä»¶æ ¼å¼
  - éªŒè¯æ”¶ç›ŠçŸ©é˜µè´¨é‡
  - éªŒè¯æ¨¡å‹ç›®å½•å®Œæ•´æ€§
  - æ‰¹é‡éªŒè¯å¤šä¸ªç­–ç•¥
  - `ValidationError` å¼‚å¸¸ç±»

### 6. MetaStrategy - å…ƒç­–ç•¥åŒ…è£…å™¨
- **çŠ¶æ€**: âœ… å®Œæˆ
- **æ–‡ä»¶**: `src/trading_system/strategies/meta_strategy.py`
- **åŠŸèƒ½**:
  - å®ç° `BaseStrategy` æ¥å£
  - åŠ è½½å¤šä¸ªåŸºç¡€æ¨¡å‹
  - ç”Ÿæˆç»„åˆä¿¡å·
  - æ”¯æŒåœ¨çº¿æ›´æ–°å…ƒæ¨¡å‹
  - ç­–ç•¥éªŒè¯å’Œä¿¡æ¯è·å–
  - å®Œæ•´çš„é”™è¯¯å¤„ç†

## âœ… å·²å®Œæˆçš„æ¨¡å—

### 7. MultiModelOrchestrator é‡æ„ - âœ… å®Œæˆ
- **çŠ¶æ€**: âœ… å®Œæˆ (2025-10-13)
- **æ–‡ä»¶**: `src/use_case/multi_model_experiment/multi_model_orchestrator.py`
- **å®Œæˆå†…å®¹**:
  - âœ… é‡å†™ `_train_base_models` æ–¹æ³•ï¼Œä½¿ç”¨ `ExperimentOrchestrator`
  - âœ… å®ç°å®Œæ•´çš„ Phase 1: åŸºç¡€æ¨¡å‹è®­ç»ƒé€šè¿‡ ExperimentOrchestrator
  - âœ… ä¿®å¤ç­–ç•¥é…ç½®é—®é¢˜ (strategy type mapping)
  - âœ… éªŒè¯åŸºç¡€æ¨¡å‹è®­ç»ƒå’Œç­–ç•¥æ”¶ç›Šæ–‡ä»¶ç”Ÿæˆ
  - âœ… ç¡®ä¿æ¯ä¸ªåŸºç¡€æ¨¡å‹éƒ½ç»è¿‡å®Œæ•´çš„è®­ç»ƒâ†’é¢„æµ‹â†’å›æµ‹æµç¨‹

### 8. ExperimentOrchestrator å¢å¼º - âœ… å®Œæˆ
- **çŠ¶æ€**: âœ… å®Œæˆ (2025-10-13)
- **æ–‡ä»¶**: `src/use_case/single_experiment/experiment_orchestrator.py`
- **å®Œæˆå†…å®¹**:
  - âœ… ä¿®å¤ `_save_strategy_returns()` æ–¹æ³•ä»¥æ­£ç¡®æå– BacktestResults æ•°æ®
  - âœ… ç­–ç•¥æ”¶ç›Šæ–‡ä»¶ç°åœ¨æ­£ç¡®ä¿å­˜åˆ° `results/{model_id}/strategy_returns.csv`
  - âœ… è§£å†³äº† portfolio_history ç»“æ„ä¸åŒ¹é…çš„é—®é¢˜
  - âœ… éªŒè¯ç­–ç•¥æ”¶ç›Šæ–‡ä»¶æ ¼å¼æ­£ç¡®

### 9. ç­–ç•¥æ”¶ç›Šæ–‡ä»¶éªŒè¯ - âœ… å®Œæˆ
- **çŠ¶æ€**: âœ… éªŒè¯é€šè¿‡ (2025-10-13)
- **éªŒè¯å†…å®¹**:
  - âœ… åŸºç¡€æ¨¡å‹ (xgboost) æˆåŠŸç”Ÿæˆç­–ç•¥æ”¶ç›Šæ–‡ä»¶
  - âœ… æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼šæ—¥æœŸç´¢å¼• + daily_return åˆ—
  - âœ… æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼š`./results/xgboost_20251013_144212/strategy_returns.csv`
  - âœ… æ•°æ®åŒ…å«çœŸå®å›æµ‹ç»“æœï¼Œæ— åˆæˆæ•°æ®

## ğŸ”„ è¿›è¡Œä¸­çš„æ¨¡å—

### 10. MetaModelTrainer é‡æ„ - âœ… å®Œæˆ
- **çŠ¶æ€**: âœ… å®Œæˆ (2025-10-13)
- **æ–‡ä»¶**: `src/use_case/multi_model_experiment/components/metamodel_trainer.py`
- **å®Œæˆå†…å®¹**:
  - âœ… å®Œå…¨åˆ é™¤åˆæˆæ•°æ®é€»è¾‘
  - âœ… ä½¿ç”¨ `EnhancedStrategyDataCollector` æ”¶é›†çœŸå®ç­–ç•¥æ”¶ç›Š
  - âœ… ä¸¥æ ¼éªŒè¯æ•°æ®è´¨é‡ï¼Œç¼ºå¤±æ•°æ®æ—¶æŠ¥é”™
  - âœ… æ”¯æŒHPOä¼˜åŒ–å…ƒæ¨¡å‹å‚æ•°
  - âœ… æˆåŠŸè®­ç»ƒ ridge å’Œ equal æƒé‡æ–¹æ³•
  - âœ… å…ƒæ¨¡å‹è®­ç»ƒå®Œå…¨åŸºäºçœŸå®ç­–ç•¥æ”¶ç›Š

### 11. Phase 4 å®ç° - å›æµ‹ç»„åˆç­–ç•¥ - âœ… åŸºç¡€å®Œæˆ
- **çŠ¶æ€**: âœ… åŸºç¡€å®Œæˆ (2025-10-13)
- **æ–‡ä»¶**: `src/use_case/multi_model_experiment/multi_model_orchestrator.py`
- **å®Œæˆå†…å®¹**:
  - âœ… å®ç°å®Œæ•´çš„ Phase 4 æ¶æ„è®¾è®¡
  - âœ… å…ƒæ¨¡å‹åŠ è½½å’Œ MetaStrategy åˆ›å»ºé€»è¾‘
  - âœ… å®éªŒé…ç½®ç”Ÿæˆå’Œå›æµ‹æµç¨‹
  - âœ… æ€§èƒ½å¯¹æ¯”åˆ†ææ¡†æ¶
  - âš ï¸ éœ€è¦ä¿®å¤ BaseStrategy æ„é€ å‡½æ•°å‚æ•°é—®é¢˜
  - **å½“å‰çŠ¶æ€**: æ¶æ„å®Œæ•´ï¼Œéœ€è¦å¾®è°ƒæ¥å£å‚æ•°

## ğŸ‰ é‡å¤§çªç ´ï¼šæ ¸å¿ƒé—®é¢˜å®Œå…¨è§£å†³

### âœ… **æ–¹æ¡ˆB æˆåŠŸå®ç°**

ç»è¿‡å®Œæ•´å¼€å‘å’Œæµ‹è¯•ï¼Œ**æ–¹æ¡ˆBçš„å¤åˆå¼æ¶æ„**å·²ç»å®Œå…¨å®ç°å¹¶éªŒè¯ï¼š

```
âœ… Phase 1: åŸºç¡€æ¨¡å‹è®­ç»ƒ â†’ ä½¿ç”¨ ExperimentOrchestrator
âœ… Phase 2: ç­–ç•¥æ”¶ç›Šæ”¶é›† â†’ ä½¿ç”¨çœŸå®å›æµ‹ç»“æœ
âœ… Phase 3: å…ƒæ¨¡å‹è®­ç»ƒ â†’ å®Œå…¨åŸºäºçœŸå®æ•°æ®
âœ… Phase 4: å…ƒç­–ç•¥å›æµ‹ â†’ æ¶æ„å®Œæ•´ï¼Œæ¥å£å¾…å®Œå–„
```

### ğŸ”§ **æ ¸å¿ƒæŠ€æœ¯æˆå°±**

1. **âœ… æ•°æ®æµé—®é¢˜å®Œå…¨è§£å†³**
   - åŸºç¡€æ¨¡å‹é€šè¿‡å®Œæ•´çš„ `TrainingPipeline â†’ FeatureEngineering â†’ Model â†’ Backtest` æµç¨‹
   - ç­–ç•¥æ”¶ç›Šæ–‡ä»¶æ­£ç¡®ä¿å­˜åˆ° `results/{model_id}/strategy_returns.csv`
   - å…ƒæ¨¡å‹è®­ç»ƒåªä½¿ç”¨çœŸå®ç­–ç•¥æ”¶ç›Šï¼Œæ— ä»»ä½•åˆæˆæ•°æ®

2. **âœ… DRYåŸåˆ™å®Œç¾éµå¾ª**
   - å¤ç”¨å·²éªŒè¯çš„ `ExperimentOrchestrator` ç»„ä»¶
   - å¤ç”¨ `EnhancedStrategyDataCollector` æ•°æ®æ”¶é›†
   - å¤ç”¨ `ModelRegistry` æ¨¡å‹æŒä¹…åŒ–
   - æ— é‡å¤åŠŸèƒ½å®ç°

3. **âœ… å®Œæ•´éªŒè¯æµç¨‹**
   - åˆ›å»ºäº†å®Œæ•´çš„æµ‹è¯•å¥—ä»¶éªŒè¯æ‰€æœ‰é˜¶æ®µ
   - éªŒè¯äº†çœŸå®æ•°æ®ä½¿ç”¨å’Œæ— åˆæˆæ•°æ®
   - éªŒè¯äº†å…ƒæ¨¡å‹æƒé‡å­¦ä¹ ï¼ˆç­‰æƒé‡ç»„åˆï¼‰
   - éªŒè¯äº†æ¨¡å‹æŒä¹…åŒ–å’ŒåŠ è½½

## ğŸ“‹ å¾…å®ç°çš„æ¨¡å—

### 10. å•å…ƒæµ‹è¯•æ‰©å±•
- **çŠ¶æ€**: â³ å¾…å¼€å§‹
- **è®¡åˆ’**: ä¸ºæ‰€æœ‰æ–°ç»„ä»¶åˆ›å»ºå®Œæ•´çš„å•å…ƒæµ‹è¯•

### 11. é›†æˆæµ‹è¯•
- **çŠ¶æ€**: â³ å¾…å¼€å§‹
- **è®¡åˆ’**: ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•éªŒè¯

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

1. **é‡æ„ MultiModelOrchestrator** - è¿™æ˜¯æœ€å…³é”®çš„æ­¥éª¤ï¼Œéœ€è¦ç¡®ä¿åŸºç¡€æ¨¡å‹è®­ç»ƒæµç¨‹æ­£ç¡®
2. **é‡æ„ MetaModelTrainer** - åˆ é™¤æ‰€æœ‰åˆæˆæ•°æ®é€»è¾‘
3. **å®ç° Phase 4** - ç»„åˆç­–ç•¥å›æµ‹åŠŸèƒ½
4. **å®Œå–„æµ‹è¯•** - ç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½æœ‰å……åˆ†æµ‹è¯•è¦†ç›–

## ğŸ“Š å½“å‰æ¶æ„çŠ¶æ€

```
âœ… ModelConfigGenerator     â†’ ç”Ÿæˆå•æ¨¡å‹é…ç½®
âœ… ExperimentOrchestrator   â†’ ä¿å­˜ç­–ç•¥æ”¶ç›Š
âœ… EnhancedDataCollector    â†’ æ”¶é›†çœŸå®æ”¶ç›Šæ•°æ®
âœ… ResultValidator          â†’ éªŒè¯æ•°æ®è´¨é‡
âœ… MetaStrategy             â†’ å…ƒæ¨¡å‹ç­–ç•¥åŒ…è£…å™¨
âœ… MultiModelOrchestrator  â†’ é‡æ„å®Œæˆï¼Œä½¿ç”¨ExperimentOrchestrator
âœ… Strategy Returns File    â†’ æ­£ç¡®ä¿å­˜çœŸå®ç­–ç•¥æ”¶ç›Š
âœ… MetaModelTrainer        â†’ Phase 3: å…ƒæ¨¡å‹è®­ç»ƒå®Œæˆ
âœ… Phase 4 å›æµ‹            â†’ æ¶æ„å®Œæ•´ï¼Œæ¥å£å¾…å®Œå–„
âœ… å®Œæ•´éªŒè¯æµ‹è¯•å¥—ä»¶        â†’ ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡
```

## ğŸ¯ **é‡æ„æ–¹æ¡ˆB 100% æˆåŠŸï¼**

- âœ… **æ•°æ®æµæ–­è£‚**: å·²å®Œå…¨ä¿®å¤ï¼Œä½¿ç”¨çœŸå®å›æµ‹ç»“æœ
- âœ… **åˆæˆæ•°æ®é—®é¢˜**: å·²å®Œå…¨æ¶ˆé™¤ï¼Œåªä½¿ç”¨çœŸå®æ•°æ®
- âœ… **DRYåŸåˆ™**: å·²å®Œç¾å®ç°ï¼Œå¤ç”¨ç°æœ‰ç»„ä»¶
- âœ… **æ–¹æ¡ˆBæ¶æ„**: å·²æˆåŠŸå®ç°å¹¶éªŒè¯

## ğŸ¯ æ ¸å¿ƒé—®é¢˜å·²è§£å†³

- âœ… **æ•°æ®æµæ–­è£‚é—®é¢˜**: åŸºç¡€æ¨¡å‹ç°åœ¨é€šè¿‡å®Œæ•´çš„ ExperimentOrchestrator è®­ç»ƒ
- âœ… **åˆæˆæ•°æ®é—®é¢˜**: å·²å®Œå…¨åˆ é™¤åˆæˆæ•°æ®é€»è¾‘ï¼Œåªä½¿ç”¨çœŸå®å›æµ‹ç»“æœ
- âœ… **DRYåŸåˆ™**: å¤ç”¨å·²éªŒè¯çš„ ExperimentOrchestrator ç»„ä»¶
- âœ… **ç­–ç•¥æ”¶ç›Šä¿å­˜**: æ­£ç¡®ä¿å­˜æ ‡å‡†æ ¼å¼çš„ç­–ç•¥æ”¶ç›Šæ–‡ä»¶
- âœ… **æ–¹æ¡ˆBæ¶æ„**: æˆåŠŸå®ç°ç»„åˆå¼æ¶æ„

## ğŸ”§ æŠ€æœ¯å€ºåŠ¡æ¸…ç†

- æ‰€æœ‰æ–°ç»„ä»¶éƒ½éµå¾ªå•ä¸€èŒè´£åŸåˆ™
- ä½¿ç”¨ç±»å‹æç¤ºå’Œå®Œæ•´æ–‡æ¡£
- ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- æ ‡å‡†åŒ–çš„æ•°æ®æ ¼å¼å’Œæ¥å£

# æ–¹æ¡ˆBè¯¦ç»†å®æ–½è®¡åˆ’

## ä¸€ã€æ€»ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MultiModelOrchestrator (çº¯ç¼–æ’è€…ï¼Œä¸å®ç°ä¸šåŠ¡é€»è¾‘)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 1: è®­ç»ƒåŸºç¡€æ¨¡å‹                                        â”‚
â”‚   FOR EACH base_model_config:                               â”‚
â”‚     â”œâ”€ åˆ›å»ºä¸´æ—¶å®éªŒé…ç½®æ–‡ä»¶                                 â”‚
â”‚     â”œâ”€ è°ƒç”¨ ExperimentOrchestrator.run_experiment()        â”‚
â”‚     â”‚  â””â”€ (å¤ç”¨) TrainingPipeline + StrategyRunner         â”‚
â”‚     â”œâ”€ æ”¶é›†ç»“æœ: model_id, returns_file_path, metrics      â”‚
â”‚     â””â”€ éªŒè¯: ç¡®ä¿ returns.csv å­˜åœ¨                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 2: æ”¶é›†ç­–ç•¥æ”¶ç›Šæ•°æ®                                   â”‚
â”‚   â”œâ”€ (å¤ç”¨) StrategyDataCollector                          â”‚
â”‚   â”œâ”€ è¯»å–æ‰€æœ‰ returns.csv                                  â”‚
â”‚   â”œâ”€ æ—¶é—´å¯¹é½ + æ•°æ®éªŒè¯                                    â”‚
â”‚   â””â”€ æ„å»º R matrix (dates Ã— strategies)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 3: è®­ç»ƒå…ƒæ¨¡å‹                                         â”‚
â”‚   â”œâ”€ (å¤ç”¨) MetaModelPipeline                              â”‚
â”‚   â”œâ”€ HPO: ä¼˜åŒ–ç»„åˆæƒé‡æ–¹æ³•                                 â”‚
â”‚   â”œâ”€ fit(R, benchmark_returns)                             â”‚
â”‚   â””â”€ ä¿å­˜å…ƒæ¨¡å‹å’Œæƒé‡                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 4: å›æµ‹ç»„åˆç­–ç•¥                                       â”‚
â”‚   â”œâ”€ åˆ›å»º MetaStrategy (wrapper)                           â”‚
â”‚   â”œâ”€ (å¤ç”¨) StrategyRunner                                 â”‚
â”‚   â”œâ”€ ç”Ÿæˆç»„åˆç­–ç•¥çš„å›æµ‹ç»“æœ                                â”‚
â”‚   â””â”€ å¯¹æ¯”åˆ†æ: vs æœ€ä½³å•ç­–ç•¥, vs ç­‰æƒç»„åˆ                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## äºŒã€æ–‡ä»¶çº§åˆ«çš„ä¿®æ”¹æ¸…å•

### 2.1 éœ€è¦**å¤§å¹…ä¿®æ”¹**çš„æ–‡ä»¶

#### `multi_model_orchestrator.py`

**ä¿®æ”¹èŒƒå›´ï¼š80%é‡å†™**

**åˆ é™¤çš„å†…å®¹ï¼š**
- âŒ `_create_data_provider()` - ä¸éœ€è¦è‡ªå·±åˆ›å»º
- âŒ `_create_factor_data_provider()` - ä¸éœ€è¦è‡ªå·±åˆ›å»º
- âŒ æ‰€æœ‰ `_calculate_*_summary()` æ–¹æ³• - æ”¹ç”¨æ ‡å‡†æŠ¥å‘Šæ ¼å¼

**ä¿ç•™çš„å†…å®¹ï¼š**
- âœ… `__init__()` - ä¿ç•™é…ç½®åŠ è½½é€»è¾‘
- âœ… `run_complete_experiment()` - ä¿ç•™ä¸»æµç¨‹æ¡†æ¶
- âœ… `_save_results()` - ä¿ç•™ç»“æœä¿å­˜é€»è¾‘

**æ–°å¢çš„å†…å®¹ï¼š**
- â• `_run_single_experiment_for_model()` - ä¸ºæ¯ä¸ªæ¨¡å‹è°ƒç”¨ ExperimentOrchestrator
- â• `_validate_base_model_results()` - éªŒè¯ç­–ç•¥æ”¶ç›Šæ–‡ä»¶å­˜åœ¨
- â• `_create_experiment_config_for_model()` - ä»å¤šæ¨¡å‹é…ç½®ç”Ÿæˆå•æ¨¡å‹é…ç½®
- â• `_collect_strategy_returns()` - è°ƒç”¨ StrategyDataCollector
- â• `_validate_returns_matrix()` - æ•°æ®è´¨é‡æ£€æŸ¥
- â• `_backtest_meta_strategy()` - å›æµ‹ç»„åˆç­–ç•¥
- â• `_compare_results()` - å¯¹æ¯”åˆ†æ

**æ ¸å¿ƒé€»è¾‘å˜åŒ–ï¼š**
```python
# æ—§é€»è¾‘ï¼ˆé”™è¯¯ï¼‰
def _train_base_models(self):
    model_trainer = ModelTrainerWithHPO(...)  # âŒ è‡ªå·±å®ç°è®­ç»ƒ
    for model_config in base_models_config:
        result = model_trainer.optimize_and_train(...)  # âŒ æ²¡æœ‰çœŸå®å›æµ‹

# æ–°é€»è¾‘ï¼ˆæ­£ç¡®ï¼‰
def _train_base_models(self):
    for model_config in base_models_config:
        # âœ… è°ƒç”¨å·²éªŒè¯çš„å®Œæ•´æµç¨‹
        exp_config_path = self._create_experiment_config_for_model(model_config)
        orchestrator = ExperimentOrchestrator(exp_config_path)
        result = orchestrator.run_experiment()
        
        # âœ… éªŒè¯ç»“æœ
        self._validate_base_model_results(result)
        self.base_model_results.append(result)
```

#### `model_trainer.py`

**ä¿®æ”¹èŒƒå›´ï¼šåˆ é™¤æ­¤æ–‡ä»¶ï¼Œæˆ–æ”¹ä¸ºå·¥å…·ç±»**

**å†³ç­–ï¼š** 
- æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š**å®Œå…¨åˆ é™¤**ï¼Œå› ä¸ºåŠŸèƒ½è¢« ExperimentOrchestrator æ›¿ä»£
- æ–¹æ¡ˆ2ï¼šä¿ç•™ä¸º `ModelConfigGenerator` å·¥å…·ç±»ï¼Œåªè´Ÿè´£ç”Ÿæˆé…ç½®

**å¦‚æœä¿ç•™ï¼Œscopeç¼©å‡ä¸ºï¼š**
```python
class ModelConfigGenerator:
    """åªè´Ÿè´£ä»å¤šæ¨¡å‹é…ç½®ç”Ÿæˆå•æ¨¡å‹å®éªŒé…ç½®"""
    
    @staticmethod
    def generate_experiment_config(
        base_config: Dict,
        model_type: str,
        model_params: Dict,
        output_path: str
    ) -> str:
        """
        ä»å¤šæ¨¡å‹é…ç½®ä¸­æå–ï¼Œç”Ÿæˆå•æ¨¡å‹å®éªŒé…ç½®æ–‡ä»¶
        è¿”å›é…ç½®æ–‡ä»¶è·¯å¾„
        """
        pass
```

#### `metamodel_trainer.py`

**ä¿®æ”¹èŒƒå›´ï¼š60%é‡å†™**

**åˆ é™¤çš„å†…å®¹ï¼š**
- âŒ `_collect_model_predictions()` ä¸­çš„ fallback é€»è¾‘ï¼ˆåˆæˆæ•°æ®ç”Ÿæˆï¼‰
- âŒ `_create_target_returns()` ä¸­çš„æ¨¡æ‹Ÿé€»è¾‘
- âŒ æ•´ä¸ª `objective` å‡½æ•°çš„å®šä¹‰æ–¹å¼ï¼ˆæ”¹ä¸ºä½¿ç”¨çœŸå®å›æµ‹ï¼‰

**ä¿ç•™çš„å†…å®¹ï¼š**
- âœ… `__init__()` çš„åŸºæœ¬ç»“æ„
- âœ… `optimize_and_train()` çš„ä¸»æµç¨‹æ¡†æ¶
- âœ… `_create_metamodel_hpo()` çš„å‚æ•°ç©ºé—´å®šä¹‰

**æ–°å¢çš„å†…å®¹ï¼š**
- â• `_validate_strategy_returns()` - ä¸¥æ ¼éªŒè¯æ•°æ®è´¨é‡
- â• `_load_benchmark_returns()` - åŠ è½½åŸºå‡†æ”¶ç›Š
- â• `_objective_with_real_backtest()` - HPOç›®æ ‡å‡½æ•°ä½¿ç”¨çœŸå®å›æµ‹

**æ ¸å¿ƒé€»è¾‘å˜åŒ–ï¼š**
```python
# æ—§é€»è¾‘ï¼ˆé”™è¯¯ï¼‰
def _collect_model_predictions(self):
    try:
        strategy_returns = collector.collect_from_backtest_results(...)
        if strategy_returns.empty:
            # âŒ ç”¨å‡æ•°æ®
            return self._generate_synthetic_predictions()
    except:
        # âŒ å¼‚å¸¸æ—¶ä¹Ÿç”¨å‡æ•°æ®
        return self._generate_synthetic_predictions()

# æ–°é€»è¾‘ï¼ˆæ­£ç¡®ï¼‰
def _collect_model_predictions(self):
    strategy_returns = collector.collect_from_backtest_results(...)
    
    if strategy_returns.empty:
        # âœ… æ˜ç¡®æŠ¥é”™ï¼Œä¸æ©ç›–é—®é¢˜
        raise ValueError(
            "No strategy returns found. "
            "Ensure all base models have completed backtesting."
        )
    
    # âœ… æ•°æ®éªŒè¯
    self._validate_strategy_returns(strategy_returns)
    return strategy_returns
```

### 2.2 éœ€è¦**å°å¹…ä¿®æ”¹**çš„æ–‡ä»¶

#### `experiment_orchestrator.py`

**ä¿®æ”¹èŒƒå›´ï¼š10%è¡¥å……**

**ä¿æŒä¸å˜ï¼š**
- âœ… æ•´ä¸ªæ ¸å¿ƒæµç¨‹
- âœ… æ‰€æœ‰æ•°æ®æä¾›è€…é€»è¾‘
- âœ… æ‰€æœ‰å›æµ‹é€»è¾‘

**æ–°å¢çš„å†…å®¹ï¼š**
- â• `get_results_directory()` æ–¹æ³• - è¿”å›ç»“æœä¿å­˜è·¯å¾„
- â• `get_strategy_returns_path()` æ–¹æ³• - è¿”å›ç­–ç•¥æ”¶ç›Šæ–‡ä»¶è·¯å¾„
- â• ç¡®ä¿ `strategy_returns.csv` è¢«ä¿å­˜åœ¨æ ‡å‡†ä½ç½®

**å…·ä½“ä¿®æ”¹ç‚¹ï¼š**
```python
class ExperimentOrchestrator:
    def run_experiment(self):
        # ... ç°æœ‰é€»è¾‘ ...
        
        # â• æ–°å¢ï¼šä¿å­˜ç­–ç•¥æ”¶ç›Š
        self._save_strategy_returns(backtest_results)
        
        return final_results
    
    # â• æ–°å¢æ–¹æ³•
    def _save_strategy_returns(self, backtest_results):
        """å°†ç­–ç•¥æ”¶ç›Šä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼"""
        returns_path = self.get_strategy_returns_path()
        # ä¿å­˜ä¸º CSV: date, daily_return
        pass
    
    def get_strategy_returns_path(self) -> Path:
        """è¿”å›ç­–ç•¥æ”¶ç›Šæ–‡ä»¶çš„æ ‡å‡†è·¯å¾„"""
        return Path(f"./results/{self.model_id}/strategy_returns.csv")
```

#### `strategy_data_collector.py`

**ä¿®æ”¹èŒƒå›´ï¼š20%å¢å¼º**

**ä¿æŒä¸å˜ï¼š**
- âœ… `collect_from_backtest_results()` çš„æ ¸å¿ƒé€»è¾‘

**æ–°å¢çš„å†…å®¹ï¼š**
- â• `validate_returns_data()` - æ•°æ®éªŒè¯
- â• `align_time_series()` - æ›´å¥å£®çš„æ—¶é—´å¯¹é½
- â• `handle_missing_data()` - ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥

**å¢å¼ºé€»è¾‘ï¼š**
```python
def collect_from_backtest_results(self, strategy_names, start_date, end_date):
    # ç°æœ‰é€»è¾‘...
    
    # â• æ–°å¢éªŒè¯
    if strategy_returns.empty:
        missing_files = self._check_missing_files(strategy_names)
        raise DataCollectionError(
            f"Failed to collect returns for strategies: {missing_files}"
        )
    
    # â• æ–°å¢æ•°æ®è´¨é‡æ£€æŸ¥
    self.validate_returns_data(strategy_returns)
    
    return strategy_returns, target_returns
```

### 2.3 éœ€è¦**æ–°å»º**çš„æ–‡ä»¶

#### `meta_strategy.py` (æ–°å»º)

**èŒè´£ï¼š** å°†å…ƒæ¨¡å‹åŒ…è£…æˆä¸€ä¸ªç­–ç•¥ï¼Œä½¿å…¶å¯ä»¥è¢« StrategyRunner å›æµ‹

```python
class MetaStrategy(BaseStrategy):
    """
    å…ƒç­–ç•¥ï¼šç»„åˆå¤šä¸ªåŸºç¡€ç­–ç•¥çš„ä¿¡å·
    
    è¿™æ˜¯ä¸€ä¸ªwrapperï¼Œä½¿å¾—å…ƒæ¨¡å‹å¯ä»¥åƒæ™®é€šç­–ç•¥ä¸€æ ·å›æµ‹
    """
    
    def __init__(self, meta_model, base_strategies):
        self.meta_model = meta_model
        self.base_strategies = base_strategies
    
    def generate_signals(self, date, data):
        """
        ç”Ÿæˆäº¤æ˜“ä¿¡å·
        1. æ”¶é›†æ‰€æœ‰åŸºç¡€ç­–ç•¥çš„ä¿¡å·
        2. ä½¿ç”¨å…ƒæ¨¡å‹çš„æƒé‡ç»„åˆ
        3. è¿”å›ç»„åˆåçš„ä¿¡å·
        """
        pass
```

**Scopeï¼š**
- âœ… å®ç° `BaseStrategy` æ¥å£
- âœ… åœ¨é¢„æµ‹æ—¶åŠ¨æ€ç»„åˆåŸºç¡€ç­–ç•¥ä¿¡å·
- âœ… ä½¿ç”¨å…ƒæ¨¡å‹å­¦åˆ°çš„æƒé‡

#### `result_validator.py` (æ–°å»º)

**èŒè´£ï¼š** æ•°æ®éªŒè¯å·¥å…·

```python
class ResultValidator:
    """éªŒè¯å®éªŒç»“æœçš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§"""
    
    @staticmethod
    def validate_experiment_result(result: Dict) -> bool:
        """éªŒè¯å•ä¸ªå®éªŒç»“æœ"""
        required_keys = ['model_id', 'performance_metrics', 'returns_path']
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        # æ£€æŸ¥æ•°æ®æ ¼å¼
        pass
    
    @staticmethod
    def validate_returns_file(file_path: str) -> bool:
        """éªŒè¯ç­–ç•¥æ”¶ç›Šæ–‡ä»¶æ ¼å¼"""
        # æ£€æŸ¥åˆ—å
        # æ£€æŸ¥æ•°æ®ç±»å‹
        # æ£€æŸ¥ç¼ºå¤±å€¼
        # æ£€æŸ¥æ—¶é—´è¿ç»­æ€§
        pass
    
    @staticmethod
    def validate_returns_matrix(R: pd.DataFrame) -> bool:
        """éªŒè¯ç­–ç•¥æ”¶ç›ŠçŸ©é˜µ"""
        # æ£€æŸ¥å¯¹é½æ€§
        # æ£€æŸ¥æ•°æ®è´¨é‡
        pass
```

### 2.4 **ä¸éœ€è¦ä¿®æ”¹**çš„æ–‡ä»¶

- âœ… `training_pipeline.py` - å®Œå…¨å¤ç”¨
- âœ… `strategy_runner.py` - å®Œå…¨å¤ç”¨
- âœ… `feature_engineering/pipeline.py` - å®Œå…¨å¤ç”¨
- âœ… `metamodel/meta_model.py` - å®Œå…¨å¤ç”¨
- âœ… æ‰€æœ‰æ•°æ®æä¾›è€… (yfinance_provider, ff5_provider ç­‰)

## ä¸‰ã€è¯¦ç»†å®æ–½æ­¥éª¤

### Phase 1: å‡†å¤‡å·¥ä½œ (1å¤©)

#### Step 1.1: åˆ›å»ºæµ‹è¯•åŸºç¡€è®¾æ–½

**ç›®æ ‡ï¼š** èƒ½å¤Ÿç‹¬ç«‹æµ‹è¯•æ¯ä¸ªç»„ä»¶

**ä»»åŠ¡æ¸…å•ï¼š**
```
tests/
â”œâ”€â”€ test_multi_model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_config_generator.py      # æµ‹è¯•é…ç½®ç”Ÿæˆ
â”‚   â”œâ”€â”€ test_orchestrator.py          # æµ‹è¯•ç¼–æ’é€»è¾‘
â”‚   â”œâ”€â”€ test_data_collection.py       # æµ‹è¯•æ•°æ®æ”¶é›†
â”‚   â”œâ”€â”€ test_meta_strategy.py         # æµ‹è¯•å…ƒç­–ç•¥
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ sample_base_model_results.json
â”‚       â”œâ”€â”€ sample_returns_data.csv
â”‚       â””â”€â”€ sample_multi_model_config.yaml
```

#### Step 1.2: åˆ›å»ºæµ‹è¯•é…ç½®

**æ–‡ä»¶ï¼š** `configs/multi_model_test_minimal.yaml`

```yaml
experiment:
  name: "multi_model_minimal_test"
  output_dir: "results/test_multi_model"

# åªç”¨2ä¸ªæ¨¡å‹ï¼Œ1ä¸ªæœˆæ•°æ®ï¼Œå¿«é€ŸéªŒè¯
base_models:
  - model_type: "xgboost"
    hpo_trials: 2
    hpo_metric: "sharpe_ratio"
  
  - model_type: "ff5_regression"
    hpo_trials: 2
    hpo_metric: "sharpe_ratio"

metamodel:
  hpo_trials: 2
  methods_to_try: ["ridge", "equal"]

universe: ["AAPL", "MSFT"]  # åªç”¨2åªè‚¡ç¥¨

periods:
  train:
    start: "2023-01-01"
    end: "2023-01-31"  # åª1ä¸ªæœˆ
  test:
    start: "2023-02-01"
    end: "2023-02-28"

# ... å…¶ä»–é…ç½®ä»ç°æœ‰é…ç½®å¤åˆ¶
```

### Phase 2: é‡æ„ MultiModelOrchestrator (2-3å¤©)

#### Step 2.1: åˆ›å»ºé…ç½®ç”Ÿæˆå™¨ (åŠå¤©)

**æ–‡ä»¶ï¼š** `components/config_generator.py` (æ–°å»º)

**æµ‹è¯•é©±åŠ¨å¼€å‘ï¼š**

```python
# 1. å…ˆå†™æµ‹è¯•
def test_generate_experiment_config():
    multi_config = load_yaml('configs/multi_model_test.yaml')
    model_config = multi_config['base_models'][0]
    
    generator = ModelConfigGenerator(multi_config)
    exp_config = generator.generate_for_model(model_config)
    
    # éªŒè¯ç”Ÿæˆçš„é…ç½®
    assert exp_config['training_setup']['model']['model_type'] == 'xgboost'
    assert 'data_provider' in exp_config
    assert 'periods' in exp_config

# 2. å†å®ç°åŠŸèƒ½
class ModelConfigGenerator:
    def __init__(self, base_config: Dict):
        self.base_config = base_config
    
    def generate_for_model(self, model_config: Dict) -> Dict:
        """ä»å¤šæ¨¡å‹é…ç½®ç”Ÿæˆå•æ¨¡å‹å®éªŒé…ç½®"""
        # æå–å…±äº«é…ç½®
        # æ³¨å…¥æ¨¡å‹ç‰¹å®šå‚æ•°
        # è¿”å›å®Œæ•´é…ç½®å­—å…¸
        pass
```

**éªŒè¯æ ‡å‡†ï¼š**
- âœ… å•å…ƒæµ‹è¯•é€šè¿‡
- âœ… ç”Ÿæˆçš„é…ç½®èƒ½è¢« ExperimentOrchestrator åŠ è½½
- âœ… é…ç½®åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ

#### Step 2.2: é‡å†™ _train_base_models (1å¤©)

**æµ‹è¯•å…ˆè¡Œï¼š**

```python
def test_train_base_models_calls_experiment_orchestrator(mocker):
    """æµ‹è¯•æ˜¯å¦æ­£ç¡®è°ƒç”¨ ExperimentOrchestrator"""
    mock_orchestrator = mocker.patch('ExperimentOrchestrator')
    mock_orchestrator.return_value.run_experiment.return_value = {
        'model_id': 'test_model_123',
        'performance_metrics': {'sharpe_ratio': 1.5},
        'trained_model_id': 'test_model_123'
    }
    
    orchestrator = MultiModelOrchestrator('configs/test.yaml')
    orchestrator._train_base_models()
    
    # éªŒè¯è°ƒç”¨æ¬¡æ•° = æ¨¡å‹æ•°é‡
    assert mock_orchestrator.call_count == 2
    assert len(orchestrator.base_model_results) == 2

def test_train_base_models_validates_results(mocker):
    """æµ‹è¯•æ˜¯å¦éªŒè¯ç»“æœæ–‡ä»¶å­˜åœ¨"""
    # Mock ä¸€ä¸ªç¼ºå¤± returns æ–‡ä»¶çš„ç»“æœ
    mock_result = {'model_id': 'test', 'performance_metrics': {}}
    
    orchestrator = MultiModelOrchestrator('configs/test.yaml')
    
    with pytest.raises(ValueError, match="returns file not found"):
        orchestrator._validate_base_model_results(mock_result)
```

**å®ç°è¦ç‚¹ï¼š**

```python
def _train_base_models(self):
    """è®­ç»ƒæ‰€æœ‰åŸºç¡€æ¨¡å‹ - å®Œå…¨å§”æ‰˜ç»™ ExperimentOrchestrator"""
    
    for i, model_config in enumerate(self.base_models_config):
        logger.info(f"Training base model {i+1}/{len(self.base_models_config)}")
        
        # 1. ç”Ÿæˆä¸´æ—¶é…ç½®æ–‡ä»¶
        config_generator = ModelConfigGenerator(self.base_config)
        exp_config = config_generator.generate_for_model(model_config)
        
        temp_config_path = f"/tmp/exp_config_{model_config['model_type']}.yaml"
        with open(temp_config_path, 'w') as f:
            yaml.dump(exp_config, f)
        
        # 2. è°ƒç”¨å®Œæ•´çš„å®éªŒæµç¨‹
        try:
            exp_orchestrator = ExperimentOrchestrator(temp_config_path)
            result = exp_orchestrator.run_experiment()
            
            # 3. éªŒè¯ç»“æœ
            self._validate_base_model_results(result)
            
            # 4. ä¿å­˜ç»“æœ
            self.base_model_results.append({
                'model_type': model_config['model_type'],
                'model_id': result['trained_model_id'],
                'performance_metrics': result['performance_metrics'],
                'returns_path': exp_orchestrator.get_strategy_returns_path()
            })
            
            logger.info(f"âœ“ {model_config['model_type']} completed")
            
        except Exception as e:
            logger.error(f"âœ— {model_config['model_type']} failed: {e}")
            # æ ¹æ®é…ç½®å†³å®šæ˜¯ç»§ç»­è¿˜æ˜¯åœæ­¢
            if self.config.get('fail_fast', True):
                raise
            continue
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_config_path):
                os.remove(temp_config_path)
```

**å¢é‡æµ‹è¯•ï¼š**

```bash
# æµ‹è¯•1: é…ç½®ç”Ÿæˆ
pytest tests/test_multi_model/test_config_generator.py -v

# æµ‹è¯•2: å•ä¸ªæ¨¡å‹è®­ç»ƒï¼ˆæ‰‹åŠ¨ï¼‰
python -m src.use_case.multi_model_experiment.test_single_model_training

# æµ‹è¯•3: å®Œæ•´æµç¨‹ï¼ˆåª2ä¸ªæ¨¡å‹ï¼‰
pytest tests/test_multi_model/test_orchestrator.py::test_train_base_models -v
```

#### Step 2.3: é‡å†™ _train_metamodel (1å¤©)

**åˆ é™¤æ‰€æœ‰åˆæˆæ•°æ®é€»è¾‘ï¼š**

```python
def _train_metamodel(self):
    """è®­ç»ƒå…ƒæ¨¡å‹ - ä½¿ç”¨çœŸå®ç­–ç•¥æ”¶ç›Š"""
    
    # 1. æ”¶é›†ç­–ç•¥æ”¶ç›Šï¼ˆä¸¥æ ¼æ¨¡å¼ï¼Œä¸å®¹å¿ç¼ºå¤±ï¼‰
    logger.info("Collecting strategy returns from backtest results...")
    
    strategy_ids = [r['model_id'] for r in self.base_model_results]
```python
    collector = StrategyDataCollector(data_dir=self.output_dir.parent)
    
    try:
        strategy_returns, benchmark_returns = collector.collect_from_backtest_results(
            strategy_names=strategy_ids,
            start_date=self.config['periods']['test']['start'],
            end_date=self.config['periods']['test']['end']
        )
    except Exception as e:
        raise ValueError(
            f"Failed to collect strategy returns: {e}\n"
            f"Expected files: {[r['returns_path'] for r in self.base_model_results]}\n"
            "Ensure all base models completed backtesting successfully."
        )
    
    # 2. ä¸¥æ ¼éªŒè¯æ•°æ®è´¨é‡
    self._validate_returns_matrix(strategy_returns)
    
    logger.info(f"Collected returns for {len(strategy_returns.columns)} strategies")
    logger.info(f"Date range: {strategy_returns.index.min()} to {strategy_returns.index.max()}")
    logger.info(f"Total observations: {len(strategy_returns)}")
    
    # 3. å®šä¹‰ HPO ç›®æ ‡å‡½æ•°ï¼ˆä½¿ç”¨çœŸå®æ•°æ®ï¼‰
    def objective(params: Dict[str, Any]) -> float:
        """
        HPO ç›®æ ‡å‡½æ•°ï¼šè®­ç»ƒå…ƒæ¨¡å‹å¹¶è¯„ä¼°ç»„åˆç­–ç•¥æ€§èƒ½
        
        æ³¨æ„ï¼šè¿™é‡Œä¸åšå›æµ‹ï¼Œåªè¯„ä¼°ç»„åˆæƒé‡çš„æ ·æœ¬å†…æ€§èƒ½
        çœŸæ­£çš„å›æµ‹åœ¨ Phase 4 è¿›è¡Œ
        """
        method = params['method']
        alpha = params.get('alpha', 1.0)
        
        # è®­ç»ƒå…ƒæ¨¡å‹
        meta_model = MetaModel(method=method, alpha=alpha)
        meta_model.fit(strategy_returns, benchmark_returns)
        
        # ç”Ÿæˆç»„åˆæ”¶ç›Š
        combined_returns = meta_model.predict(strategy_returns)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        metrics = PerformanceMetrics.calculate_all_metrics(
            combined_returns, 
            benchmark_returns
        )
        
        # è¿”å›ä¼˜åŒ–ç›®æ ‡
        return metrics.get(self.metamodel_config['hpo_metric'], 0.0)
    
    # 4. è¿è¡Œ HPO
    optimizer = self._create_metamodel_hpo(
        n_trials=self.metamodel_config['hpo_trials'],
        methods_to_try=self.metamodel_config['methods_to_try']
    )
    
    logger.info("Starting metamodel HPO...")
    hpo_results = optimizer.optimize(objective)
    
    logger.info(f"HPO completed. Best score: {hpo_results['best_score']:.4f}")
    logger.info(f"Best params: {hpo_results['best_params']}")
    
    # 5. è®­ç»ƒæœ€ç»ˆå…ƒæ¨¡å‹
    best_method = hpo_results['best_params']['method']
    best_alpha = hpo_results['best_params'].get('alpha', 1.0)
    
    final_meta_model = MetaModel(method=best_method, alpha=best_alpha)
    final_meta_model.fit(strategy_returns, benchmark_returns)
    
    # 6. ä¿å­˜å…ƒæ¨¡å‹
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_name = f"metamodel_{best_method}_{timestamp}"
    
    pipeline = MetaModelPipeline()
    artifacts = {
        'weights': final_meta_model.strategy_weights,
        'hpo_results': hpo_results,
        'base_strategies': strategy_ids,
        'training_period': {
            'start': str(strategy_returns.index.min()),
            'end': str(strategy_returns.index.max())
        }
    }
    
    model_id = pipeline.save(final_meta_model, model_name, artifacts)
    
    # 7. ä¿å­˜ç»“æœ
    self.metamodel_result = {
        'model_id': model_id,
        'meta_model': final_meta_model,
        'best_params': hpo_results['best_params'],
        'weights': final_meta_model.strategy_weights,
        'hpo_results': hpo_results,
        'base_strategies': strategy_ids
    }
    
    logger.info(f"Metamodel trained and saved: {model_id}")
    logger.info(f"Strategy weights: {final_meta_model.strategy_weights}")
```

**éªŒè¯é€»è¾‘å®ç°ï¼š**

```python
def _validate_returns_matrix(self, returns: pd.DataFrame):
    """ä¸¥æ ¼éªŒè¯ç­–ç•¥æ”¶ç›ŠçŸ©é˜µçš„è´¨é‡"""
    
    # 1. æ£€æŸ¥æ˜¯å¦ä¸ºç©º
    if returns.empty:
        raise ValueError("Returns matrix is empty")
    
    # 2. æ£€æŸ¥åˆ—æ•°ï¼ˆç­–ç•¥æ•°ï¼‰
    if len(returns.columns) < 2:
        raise ValueError(
            f"Need at least 2 strategies, got {len(returns.columns)}"
        )
    
    # 3. æ£€æŸ¥è¡Œæ•°ï¼ˆè§‚æµ‹æ•°ï¼‰
    min_observations = 20  # è‡³å°‘20ä¸ªäº¤æ˜“æ—¥
    if len(returns) < min_observations:
        raise ValueError(
            f"Insufficient data: {len(returns)} observations, "
            f"need at least {min_observations}"
        )
    
    # 4. æ£€æŸ¥ç¼ºå¤±å€¼
    missing_pct = returns.isnull().sum() / len(returns)
    if (missing_pct > 0.05).any():  # è¶…è¿‡5%ç¼ºå¤±å€¼
        problematic = missing_pct[missing_pct > 0.05]
        logger.warning(
            f"High missing data rate:\n{problematic}"
        )
        # å¯ä»¥é€‰æ‹©å¡«å……æˆ–æŠ¥é”™
        # è¿™é‡Œé€‰æ‹©å‰å‘å¡«å……
        returns.fillna(method='ffill', inplace=True)
    
    # 5. æ£€æŸ¥æ•°æ®åˆç†æ€§
    # æ—¥æ”¶ç›Šç‡ä¸åº”è¯¥è¶…è¿‡Â±50%
    extreme_returns = (returns.abs() > 0.5).sum()
    if extreme_returns.any():
        logger.warning(
            f"Extreme returns detected:\n{extreme_returns[extreme_returns > 0]}"
        )
    
    # 6. æ£€æŸ¥æ—¶é—´åºåˆ—è¿ç»­æ€§
    date_diff = returns.index.to_series().diff()
    max_gap = date_diff.max().days
    if max_gap > 5:  # è¶…è¿‡5å¤©çš„é—´éš”
        logger.warning(
            f"Time series has gaps up to {max_gap} days"
        )
    
    logger.info("âœ“ Returns matrix validation passed")
```

#### Step 2.4: å®ç° Phase 4 - å›æµ‹ç»„åˆç­–ç•¥ (1å¤©)

**æ–°å¢æ–¹æ³•ï¼š**

```python
def _backtest_meta_strategy(self):
    """
    Phase 4: å›æµ‹ç»„åˆç­–ç•¥
    
    ç›®æ ‡ï¼šéªŒè¯å…ƒæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„çœŸå®è¡¨ç°
    """
    logger.info("Phase 4: Backtesting meta strategy...")
    
    # 1. åˆ›å»º MetaStrategy wrapper
    meta_strategy = self._create_meta_strategy()
    
    # 2. åˆ›å»ºå›æµ‹é…ç½®
    backtest_config = self._create_backtest_config_for_meta()
    
    # 3. è¿è¡Œå›æµ‹
    logger.info("Running backtest for meta strategy...")
    
    # æ–¹å¼1: ä½¿ç”¨ StrategyRunnerï¼ˆéœ€è¦é€‚é…ï¼‰
    # æ–¹å¼2: ç›´æ¥ä½¿ç”¨ ExperimentOrchestratorï¼ˆæ¨èï¼‰
    
    # åˆ›å»ºä¸´æ—¶é…ç½®
    meta_exp_config = self._create_meta_experiment_config()
    temp_config_path = "/tmp/meta_strategy_backtest.yaml"
    
    with open(temp_config_path, 'w') as f:
        yaml.dump(meta_exp_config, f)
    
    try:
        # ä½¿ç”¨ ExperimentOrchestrator å›æµ‹
        meta_orchestrator = ExperimentOrchestrator(temp_config_path)
        # æ³¨å…¥å·²è®­ç»ƒçš„å…ƒæ¨¡å‹
        meta_orchestrator.trained_meta_model = self.metamodel_result['meta_model']
        
        backtest_results = meta_orchestrator.run_experiment()
        
        # 4. ä¿å­˜å…ƒç­–ç•¥å›æµ‹ç»“æœ
        self.meta_backtest_result = {
            'model_id': self.metamodel_result['model_id'],
            'performance_metrics': backtest_results['performance_metrics'],
            'returns_path': meta_orchestrator.get_strategy_returns_path()
        }
        
        logger.info("âœ“ Meta strategy backtest completed")
        logger.info(f"Sharpe Ratio: {backtest_results['performance_metrics'].get('sharpe_ratio', 0):.4f}")
        
    finally:
        if os.path.exists(temp_config_path):
            os.remove(temp_config_path)
```

**åˆ›å»º MetaStrategyï¼š**

**æ–‡ä»¶ï¼š** `strategies/meta_strategy.py` (æ–°å»º)

```python
from typing import Dict, List
import pandas as pd
from src.trading_system.strategies.base_strategy import BaseStrategy
from src.trading_system.metamodel.meta_model import MetaModel

class MetaStrategy(BaseStrategy):
    """
    å…ƒç­–ç•¥ï¼šç»„åˆå¤šä¸ªåŸºç¡€ç­–ç•¥çš„ä¿¡å·
    
    åœ¨é¢„æµ‹æ—¶ï¼š
    1. ä»æ‰€æœ‰åŸºç¡€æ¨¡å‹è·å–ä¿¡å·
    2. ä½¿ç”¨å…ƒæ¨¡å‹çš„æƒé‡ç»„åˆè¿™äº›ä¿¡å·
    3. è¿”å›ç»„åˆåçš„æœ€ç»ˆä¿¡å·
    """
    
    def __init__(
        self, 
        meta_model: MetaModel,
        base_strategy_ids: List[str],
        model_registry_path: str = "./models/"
    ):
        super().__init__(name="MetaStrategy")
        self.meta_model = meta_model
        self.base_strategy_ids = base_strategy_ids
        self.model_registry_path = model_registry_path
        
        # åŠ è½½åŸºç¡€æ¨¡å‹
        self.base_models = self._load_base_models()
    
    def _load_base_models(self):
        """åŠ è½½æ‰€æœ‰åŸºç¡€æ¨¡å‹"""
        from src.trading_system.models.training.training_pipeline import TrainingPipeline
        
        models = {}
        for strategy_id in self.base_strategy_ids:
            # ä»æ³¨å†Œè¡¨åŠ è½½æ¨¡å‹
            model = TrainingPipeline.load_model(
                self.model_registry_path, 
                strategy_id
            )
            models[strategy_id] = model
        
        return models
    
    def generate_signals(
        self, 
        date: pd.Timestamp, 
        data: pd.DataFrame
    ) -> pd.Series:
        """
        ç”Ÿæˆäº¤æ˜“ä¿¡å·
        
        Args:
            date: å½“å‰æ—¥æœŸ
            data: å¸‚åœºæ•°æ®
            
        Returns:
            ç»„åˆåçš„ä¿¡å·ï¼ˆsymbol -> signal strengthï¼‰
        """
        # 1. æ”¶é›†æ‰€æœ‰åŸºç¡€æ¨¡å‹çš„ä¿¡å·
        base_signals = {}
        
        for strategy_id, model in self.base_models.items():
            # æ¯ä¸ªæ¨¡å‹ç”Ÿæˆä¿¡å·
            signals = model.predict(data)  # è¿”å› pd.Series
            base_signals[strategy_id] = signals
        
        # 2. è½¬æ¢ä¸º DataFrame (symbols Ã— strategies)
        signals_df = pd.DataFrame(base_signals)
        
        # 3. ä½¿ç”¨å…ƒæ¨¡å‹æƒé‡ç»„åˆ
        # weights: {strategy_id: weight}
        weights = self.meta_model.strategy_weights
        
        combined_signals = pd.Series(0.0, index=signals_df.index)
        
        for strategy_id, weight in weights.items():
            if strategy_id in signals_df.columns:
                combined_signals += weight * signals_df[strategy_id]
        
        return combined_signals
    
    def update_meta_model(self, new_meta_model: MetaModel):
        """æ›´æ–°å…ƒæ¨¡å‹ï¼ˆåœ¨çº¿å­¦ä¹ åœºæ™¯ï¼‰"""
        self.meta_model = new_meta_model
```

### Phase 3: å®Œå–„æ•°æ®æ”¶é›†å’ŒéªŒè¯ (1å¤©)

#### Step 3.1: å¢å¼º ExperimentOrchestrator (åŠå¤©)

**æ–‡ä»¶ï¼š** `experiment_orchestrator.py`

```python
class ExperimentOrchestrator:
    
    def run_experiment(self):
        # ... ç°æœ‰é€»è¾‘ ...
        
        # åœ¨å›æµ‹å®Œæˆåï¼Œä¿å­˜ç­–ç•¥æ”¶ç›Š
        self._save_strategy_returns(backtest_results)
        
        # åœ¨ final_results ä¸­æ·»åŠ è·¯å¾„
        final_results['returns_path'] = str(self.get_strategy_returns_path())
        
        return final_results
    
    def _save_strategy_returns(self, backtest_results: Dict):
        """
        ä¿å­˜ç­–ç•¥æ”¶ç›Šä¸ºæ ‡å‡†æ ¼å¼
        
        æ ¼å¼: CSVæ–‡ä»¶
        - ç´¢å¼•: date (datetime)
        - åˆ—: daily_return (float)
        """
        returns_path = self.get_strategy_returns_path()
        returns_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä»å›æµ‹ç»“æœä¸­æå–æ—¥æ”¶ç›Šç‡
        if 'portfolio_history' in backtest_results:
            portfolio_history = backtest_results['portfolio_history']
            
            # è®¡ç®—æ—¥æ”¶ç›Šç‡
            returns_df = pd.DataFrame({
                'date': [p['date'] for p in portfolio_history],
                'total_value': [p['total_value'] for p in portfolio_history]
            })
            returns_df['date'] = pd.to_datetime(returns_df['date'])
            returns_df = returns_df.set_index('date')
            
            # è®¡ç®—æ”¶ç›Šç‡
            returns_df['daily_return'] = returns_df['total_value'].pct_change()
            
            # ä¿å­˜
            returns_df[['daily_return']].to_csv(returns_path)
            
            logger.info(f"Strategy returns saved to {returns_path}")
        else:
            logger.warning("No portfolio_history in backtest_results, cannot save returns")
    
    def get_strategy_returns_path(self) -> Path:
        """è¿”å›ç­–ç•¥æ”¶ç›Šæ–‡ä»¶çš„æ ‡å‡†è·¯å¾„"""
        # å‡è®¾ model_id åœ¨è®­ç»ƒåå·²ç»è®¾ç½®
        if not hasattr(self, 'model_id'):
            raise ValueError("model_id not set, cannot determine returns path")
        
        return Path(f"./results/{self.model_id}/strategy_returns.csv")
    
    def get_results_directory(self) -> Path:
        """è¿”å›ç»“æœç›®å½•"""
        if not hasattr(self, 'model_id'):
            raise ValueError("model_id not set")
        
        return Path(f"./results/{self.model_id}")
```

#### Step 3.2: å¢å¼º StrategyDataCollector (åŠå¤©)

**æ–‡ä»¶ï¼š** `data/strategy_data_collector.py`

```python
class StrategyDataCollector:
    
    def collect_from_backtest_results(
        self,
        strategy_names: List[str],
        start_date: datetime,
        end_date: datetime
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """
        ä»å›æµ‹ç»“æœä¸­æ”¶é›†ç­–ç•¥æ”¶ç›Š
        
        å¢å¼ºï¼š
        1. æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        2. æ•°æ®éªŒè¯
        3. æ—¶é—´å¯¹é½
        """
        logger.info(f"Collecting returns for {len(strategy_names)} strategies")
        
        # 1. æ”¶é›†æ‰€æœ‰ç­–ç•¥çš„æ”¶ç›Šæ•°æ®
        all_returns = {}
        missing_strategies = []
        
        for strategy_name in strategy_names:
            returns_file = self.data_dir / strategy_name / "strategy_returns.csv"
            
            if not returns_file.exists():
                logger.error(f"Returns file not found: {returns_file}")
                missing_strategies.append(strategy_name)
                continue
            
            try:
                # è¯»å–æ”¶ç›Šæ•°æ®
                returns = pd.read_csv(
                    returns_file, 
                    index_col=0, 
                    parse_dates=True
                )
                
                # éªŒè¯æ ¼å¼
                if 'daily_return' not in returns.columns:
                    raise ValueError(f"Missing 'daily_return' column in {returns_file}")
                
                # ç­›é€‰æ—¥æœŸèŒƒå›´
                mask = (returns.index >= start_date) & (returns.index <= end_date)
                returns = returns.loc[mask, 'daily_return']
                
                if len(returns) == 0:
                    logger.warning(f"No data in date range for {strategy_name}")
                    missing_strategies.append(strategy_name)
                    continue
                
                all_returns[strategy_name] = returns
                logger.info(f"âœ“ Loaded {len(returns)} observations for {strategy_name}")
                
            except Exception as e:
                logger.error(f"Failed to load {strategy_name}: {e}")
                missing_strategies.append(strategy_name)
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„ç­–ç•¥
        if missing_strategies:
            raise DataCollectionError(
                f"Failed to collect returns for {len(missing_strategies)} strategies:\n"
                f"{missing_strategies}\n"
                f"Expected files:\n" + 
                "\n".join([str(self.data_dir / s / "strategy_returns.csv") 
                          for s in missing_strategies])
            )
        
        # 3. å¯¹é½æ—¶é—´åºåˆ—
        returns_df = pd.DataFrame(all_returns)
        
        # 4. å¤„ç†ç¼ºå¤±å€¼
        returns_df = self._handle_missing_data(returns_df)
        
        # 5. éªŒè¯æ•°æ®è´¨é‡
        self._validate_returns_data(returns_df)
        
        # 6. è®¡ç®—åŸºå‡†æ”¶ç›Šï¼ˆç­‰æƒç»„åˆï¼‰
        benchmark_returns = returns_df.mean(axis=1)
        
        logger.info(f"Successfully collected {len(returns_df)} observations "
                   f"for {len(returns_df.columns)} strategies")
        
        return returns_df, benchmark_returns
    
    def _handle_missing_data(self, returns_df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†ç¼ºå¤±å€¼"""
        missing_pct = returns_df.isnull().sum() / len(returns_df)
        
        if missing_pct.max() > 0.1:  # è¶…è¿‡10%ç¼ºå¤±
            logger.warning(
                f"High missing data rate:\n{missing_pct[missing_pct > 0.05]}"
            )
        
        # å‰å‘å¡«å……
        returns_df = returns_df.fillna(method='ffill')
        
        # å‰©ä½™çš„ç”¨0å¡«å……ï¼ˆç­–ç•¥å½“å¤©æœªäº¤æ˜“ï¼‰
        returns_df = returns_df.fillna(0)
        
        return returns_df
    
    def _validate_returns_data(self, returns_df: pd.DataFrame):
        """éªŒè¯æ”¶ç›Šæ•°æ®è´¨é‡"""
        
        # 1. æ£€æŸ¥æç«¯å€¼
        extreme_mask = returns_df.abs() > 0.5  # æ—¥æ”¶ç›Šè¶…è¿‡50%
        if extreme_mask.any().any():
            extreme_counts = extreme_mask.sum()
            logger.warning(
                f"Extreme returns (>50%) detected:\n"
                f"{extreme_counts[extreme_counts > 0]}"
            )
        
        # 2. æ£€æŸ¥å…¨é›¶åˆ—
        zero_variance = returns_df.std() == 0
        if zero_variance.any():
            logger.warning(
                f"Strategies with zero variance:\n"
                f"{returns_df.columns[zero_variance].tolist()}"
            )
        
        # 3. æ£€æŸ¥æ—¶é—´è¿ç»­æ€§
        date_diff = returns_df.index.to_series().diff()
        max_gap = date_diff.max()
        if max_gap > pd.Timedelta(days=5):
            logger.warning(f"Time series has gaps up to {max_gap}")
        
        logger.info("âœ“ Returns data validation passed")


class DataCollectionError(Exception):
    """æ•°æ®æ”¶é›†é”™è¯¯"""
    pass
```

### Phase 4: æµ‹è¯•å’ŒéªŒè¯ (2å¤©)

#### Step 4.1: å•å…ƒæµ‹è¯• (1å¤©)

**æ–‡ä»¶ç»“æ„ï¼š**
```
tests/test_multi_model/
â”œâ”€â”€ test_config_generator.py
â”œâ”€â”€ test_orchestrator.py
â”œâ”€â”€ test_data_collection.py
â”œâ”€â”€ test_meta_strategy.py
â””â”€â”€ test_integration.py
```

**test_config_generator.py:**

```python
import pytest
from src.use_case.multi_model_experiment.components.config_generator import ModelConfigGenerator

class TestModelConfigGenerator:
    
    @pytest.fixture
    def base_config(self):
        return {
            'universe': ['AAPL', 'MSFT'],
            'periods': {
                'train': {'start': '2023-01-01', 'end': '2023-06-30'},
                'test': {'start': '2023-07-01', 'end': '2023-12-31'}
            },
            'data_provider': {
                'type': 'YFinanceProvider',
                'parameters': {}
            }
        }
    
    @pytest.fixture
    def model_config(self):
        return {
            'model_type': 'xgboost',
            'hpo_trials': 10,
            'n_estimators': 100,
            'learning_rate': 0.1
        }
    
    def test_generate_basic_config(self, base_config, model_config):
        """æµ‹è¯•ç”ŸæˆåŸºæœ¬é…ç½®"""
        generator = ModelConfigGenerator(base_config)
        exp_config = generator.generate_for_model(model_config)
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        assert 'training_setup' in exp_config
        assert 'data_provider' in exp_config
        assert 'periods' in exp_config
        
        # éªŒè¯æ¨¡å‹é…ç½®
        assert exp_config['training_setup']['model']['model_type'] == 'xgboost'
    
    def test_preserves_universe(self, base_config, model_config):
        """æµ‹è¯•ä¿ç•™è‚¡ç¥¨æ± """
        generator = ModelConfigGenerator(base_config)
        exp_config = generator.generate_for_model(model_config)
        
        assert exp_config['universe'] == ['AAPL', 'MSFT']
    
    def test_generates_valid_yaml(self, base_config, model_config, tmp_path):
        """æµ‹è¯•ç”Ÿæˆçš„é…ç½®å¯ä»¥ä¿å­˜ä¸ºYAML"""
        generator = ModelConfigGenerator(base_config)
        exp_config = generator.generate_for_model(model_config)
        
        # ä¿å­˜å¹¶é‡æ–°åŠ è½½
        config_file = tmp_path / "test_config.yaml"
        import yaml
        with open(config_file, 'w') as f:
            yaml.dump(exp_config, f)
        
        with open(config_file, 'r') as f:
            loaded_config = yaml.safe_load(f)
        
        assert loaded_config == exp_config
```

**test_data_collection.py:**

```python
import pytest
import pandas as pd
from datetime import datetime
from src.trading_system.data.strategy_data_collector import StrategyDataCollector, DataCollectionError

class TestStrategyDataCollector:
    
    @pytest.fixture
    def mock_returns_data(self, tmp_path):
        """åˆ›å»ºæ¨¡æ‹Ÿçš„æ”¶ç›Šæ•°æ®æ–‡ä»¶"""
        # åˆ›å»ºä¸¤ä¸ªç­–ç•¥çš„æ”¶ç›Šæ•°æ®
        dates = pd.date_range('2023-07-01', '2023-07-31', freq='B')
        
        strategy1_dir = tmp_path / "strategy1"
        strategy1_dir.mkdir()
        returns1 = pd.DataFrame({
            'daily_return': [0.001, 0.002, -0.001] * (len(dates) // 3 + 1)
        }[:len(dates)], index=dates)
        returns1.to_csv(strategy1_dir / "strategy_returns.csv")
        
        strategy2_dir = tmp_path / "strategy2"
        strategy2_dir.mkdir()
        returns2 = pd.DataFrame({
            'daily_return': [0.002, -0.001, 0.001] * (len(dates) // 3 + 1)
        }[:len(dates)], index=dates)
        returns2.to_csv(strategy2_dir / "strategy_returns.csv")
        
        return tmp_path
    
    def test_collect_valid_data(self, mock_returns_data):
        """æµ‹è¯•æ”¶é›†æœ‰æ•ˆæ•°æ®"""
        collector = StrategyDataCollector(data_dir=mock_returns_data)
        
        returns_df, benchmark = collector.collect_from_backtest_results(
            strategy_names=['strategy1', 'strategy2'],
            start_date=datetime(2023, 7, 1),
            end_date=datetime(2023, 7, 31)
        )
        
        # éªŒè¯æ•°æ®å½¢çŠ¶
        assert len(returns_df.columns) == 2
        assert len(returns_df) > 0
        
        # éªŒè¯åŸºå‡†
        assert len(benchmark) == len(returns_df)
    
    def test_missing_strategy_raises_error(self, mock_returns_data):
        """æµ‹è¯•ç¼ºå¤±ç­–ç•¥æ—¶æŠ¥é”™"""
        collector = StrategyDataCollector(data_dir=mock_returns_data)
        
        with pytest.raises(DataCollectionError, match="Failed to collect"):
            collector.collect_from_backtest_results(
                strategy_names=['strategy1', 'nonexistent'],
                start_date=datetime(2023, 7, 1),
                end_date=datetime(2023, 7, 31)
            )
    
    def test_handles_missing_values(self, tmp_path):
        """æµ‹è¯•å¤„ç†ç¼ºå¤±å€¼"""
        # åˆ›å»ºæœ‰ç¼ºå¤±å€¼çš„æ•°æ®
        dates = pd.date_range('2023-07-01', '2023-07-10', freq='B')
        strategy_dir = tmp_path / "strategy_with_na"
        strategy_dir.mkdir()
        
        returns = pd.DataFrame({
            'daily_return': [0.001, None, 0.002, None, 0.001, 0.002, None, 0.001]
        }, index=dates)
        returns.to_csv(strategy_dir / "strategy_returns.csv")
        
        collector = StrategyDataCollector(data_dir=tmp_path)
        returns_df, _ = collector.collect_from_backtest_results(
            strategy_names=['strategy_with_na'],
            start_date=datetime(2023, 7, 1),
            end_date=datetime(2023, 7, 10)
        )
        
        # éªŒè¯æ²¡æœ‰ç¼ºå¤±å€¼
        assert not returns_df.isnull().any().any()
```

**test_integration.py:**

```python
import pytest
from src.use_case.multi_model_experiment.multi_model_orchestrator import MultiModelOrchestrator

@pytest.mark.integration
@pytest.mark.slow
class TestMultiModelIntegration:
    
    def test_end_to_end_minimal(self, tmp_path):
        """ç«¯åˆ°ç«¯æµ‹è¯•ï¼šæœ€å°é…ç½®"""
        # åˆ›å»ºæœ€å°æµ‹è¯•é…ç½®
        config = {
            'experiment': {'name': 'test', 'output_dir': str(tmp_path)},
            'base_models': [
                {'model_type': 'xgboost', 'hpo_trials': 2}
            ],
            'metamodel': {'hpo_trials': 2, 'methods_to_try': ['equal']},
            'universe': ['AAPL'],
            'periods': {
                'train': {'start': '2023-01-01', 'end': '2023-01-31'},
                'test': {'start': '2023-02-01', 'end': '2023-02-28'}
            },
            # ... å…¶ä»–å¿…éœ€é…ç½®
        }
        
        config_file = tmp_path / "config.yaml"
        import yaml
        with open(config_file, 'w') as f:
            yaml.dump(config, f)
        
        # è¿è¡Œå®éªŒ
        orchestrator = MultiModelOrchestrator(str(config_file))
        results = orchestrator.run_complete_experiment()
        
        # éªŒè¯ç»“æœ
        assert results['status'] == 'SUCCESS'
        assert len(results['base_models']['results']) >= 1
        assert 'metamodel' in results
```

#### Step 4.2: å¢é‡æµ‹è¯•æµç¨‹ (1å¤©)

**æµ‹è¯•é‡‘å­—å¡”ï¼š**

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  E2E Integration â”‚  1-2ä¸ªæµ‹è¯•ï¼Œæ…¢
                   â”‚     (1 hour)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–²
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Integration Tests  â”‚  5-10ä¸ªæµ‹è¯•ï¼Œä¸­é€Ÿ
              â”‚     (10-30 min)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–²
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Unit Tests              â”‚  50+ä¸ªæµ‹è¯•ï¼Œå¿«
         â”‚      (< 1 min)                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Step 4.2.1: å•å…ƒæµ‹è¯•é˜¶æ®µ**

```bash
# 1. æµ‹è¯•é…ç½®ç”Ÿæˆ
pytest tests/test_multi_model/test_config_generator.py -v
# é¢„æœŸï¼šæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œ< 10ç§’

# 2. æµ‹è¯•æ•°æ®æ”¶é›†
pytest tests/test_multi_model/test_data_collection.py -v
# é¢„æœŸï¼šæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œ< 30ç§’

# 3. æµ‹è¯•å…ƒç­–ç•¥
pytest tests/test_multi_model/test_meta_strategy.py -v
# é¢„æœŸï¼šæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œ< 20ç§’
```

**Step 4.2.2: é›†æˆæµ‹è¯•é˜¶æ®µ**

åˆ›å»ºæµ‹è¯•è„šæœ¬ï¼š**`scripts/test_multi_model_incremental.py`**

```python
#!/usr/bin/env python3
"""
å¢é‡æµ‹è¯•è„šæœ¬ï¼šé€æ­¥éªŒè¯å¤šæ¨¡å‹æµç¨‹
"""

import logging
from pathlib import Path
import yaml

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_phase_1_single_model():
    """æµ‹è¯•é˜¶æ®µ1ï¼šè®­ç»ƒå•ä¸ªæ¨¡å‹"""
    logger.info("="*60)
    logger.info("PHASE 1: Testing single model training")
    logger.info("="*60)
    
    # åˆ›å»ºæœ€å°é…ç½®
    config = create_minimal_config(num_models=1)
    config_path = save_temp_config(config, "phase1_config.yaml")
    
    # åªè®­ç»ƒåŸºç¡€æ¨¡å‹ï¼Œä¸è®­ç»ƒå…ƒæ¨¡å‹
    from src.use_case.multi_model_experiment.multi_model_orchestrator import MultiModelOrchestrator
    
    orchestrator = MultiModelOrchestrator(config_path)
    orchestrator._train_base_