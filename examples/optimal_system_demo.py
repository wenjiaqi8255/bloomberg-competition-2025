#!/usr/bin/env python3
"""
Optimal System Demo - ä¸€è¡Œä»£ç æœ€ä¼˜ç³»ç»Ÿæ¼”ç¤º
==============================================

ä¸€è¡Œä»£ç ç»Ÿä¸€æœ€ä½³æ¨¡å‹+å…ƒæ¨¡å‹ç»„åˆç³»ç»Ÿçš„å®Œæ•´æ¼”ç¤ºã€‚

Examples:
    >>> python optimal_system_demo.py --config configs/optimal_system_config.yaml
    >>> python optimal_system_demo.py --quick-test
    >>> python optimal_system_demo.py --custom-config
"""

import argparse
import logging
import sys
from pathlib import Path
import yaml
import pandas as pd
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / "src"))

from trading_system.orchestration.optimal_system_orchestrator import (
    OptimalSystemOrchestrator, OptimalSystemConfig,
    create_optimal_system_orchestrator, quick_optimal_system
)
from trading_system.orchestration.components.optimal_model_selector import (
    create_model_selector, quick_best_model_selection
)
from trading_system.orchestration.components.optimal_metamodel_selector import (
    create_metamodel_selector, quick_optimal_metamodel
)
from trading_system.orchestration.components.system_performance_evaluator import (
    create_system_evaluator, quick_system_evaluation
)

logger = logging.getLogger(__name__)


def setup_logging(log_level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—."""
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶."""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def generate_mock_data(config: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º."""
    import numpy as np

    data_config = config.get('data', {})
    universe = data_config.get('universe', ['AAPL', 'GOOGL', 'MSFT'])

    # ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®
    train_period = data_config.get('train_period', {})
    test_period = data_config.get('test_period', {})

    # ç®€åŒ–çš„æ•°æ®ç”Ÿæˆï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨çœŸå®æ•°æ®ï¼‰
    dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')

    # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼æ•°æ®
    price_data = {}
    for symbol in universe:
        np.random.seed(hash(symbol) % 2**32)  # ç¡®ä¿å¯é‡å¤æ€§
        returns = np.random.normal(0.001, 0.02, len(dates))  # æ—¥æ”¶ç›Šç‡
        prices = 100 * np.exp(np.cumsum(returns))
        price_data[symbol] = pd.Series(prices, index=dates)

    # ç”Ÿæˆä¿¡å·æ•°æ®
    signals_data = {}
    for symbol in universe:
        signals = np.random.normal(0, 0.1, len(dates))  # ç®€åŒ–çš„ä¿¡å·
        signals_data[symbol] = pd.Series(signals, index=dates)

    return {
        'train_data': {
            'prices': pd.DataFrame(price_data),
            'signals': pd.DataFrame(signals_data),
            'returns': pd.DataFrame({symbol: prices.pct_change()
                                   for symbol, prices in price_data.items()})
        },
        'test_data': {
            'prices': pd.DataFrame(price_data),
            'signals': pd.DataFrame(signals_data),
            'returns': pd.DataFrame({symbol: prices.pct_change()
                                   for symbol, prices in price_data.items()})
        },
        'strategy_data': {
            'returns': pd.DataFrame(signals_data),
            'performance': {symbol: {'sharpe_ratio': np.random.uniform(0.5, 1.5),
                                   'total_return': np.random.uniform(0.1, 0.3),
                                   'volatility': np.random.uniform(0.1, 0.2)}
                          for symbol in universe}
        },
        'benchmark_data': {
            'returns': pd.Series(np.random.normal(0.0008, 0.015, len(dates)),
                               index=dates, name='SPY')
        }
    }


def demo_basic_one_line_usage():
    """æ¼”ç¤ºåŸºç¡€ä¸€è¡Œä»£ç ç”¨æ³•."""
    print("ğŸš€ æ¼”ç¤ºåŸºç¡€ä¸€è¡Œä»£ç ç”¨æ³•")
    print("=" * 50)

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    config = load_config('configs/quick_test_config.yaml')
    data = generate_mock_data(config)

    # ä¸€è¡Œä»£ç åˆ›å»ºåè°ƒå™¨
    orchestrator = create_optimal_system_orchestrator(n_trials=5, save_results=True)

    # ä¸€è¡Œä»£ç è¿è¡Œå®Œæ•´ç³»ç»Ÿ
    model_types = ['xgboost', 'lstm']
    result = orchestrator.find_and_run_optimal_system(
        model_types, data['train_data'], data['test_data'],
        data['strategy_data'], data['benchmark_data']
    )

    # ä¸€è¡Œä»£ç æ‰“å°ç»“æœ
    print(f"âœ… ç³»ç»ŸæˆåŠŸè¿è¡Œï¼æœ€ä½³Sharpe: {result['report']['key_metrics']['sharpe_ratio']:.3f}")
    print(f"âœ… æ€»æ”¶ç›Š: {result['report']['key_metrics']['total_return']:.2%}")
    print(f"âœ… æœ€å¤§å›æ’¤: {result['report']['key_metrics']['max_drawdown']:.2%}")

    return result


def demo_quick_optimal_system():
    """æ¼”ç¤ºå¿«é€Ÿæœ€ä¼˜ç³»ç»Ÿä¸€è¡Œä»£ç ."""
    print("\nğŸš€ æ¼”ç¤ºå¿«é€Ÿæœ€ä¼˜ç³»ç»Ÿä¸€è¡Œä»£ç ")
    print("=" * 50)

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    config = load_config('configs/quick_test_config.yaml')
    data = generate_mock_data(config)

    # ä¸€è¡Œä»£ç å®Œæˆæ•´ä¸ªæœ€ä¼˜ç³»ç»Ÿæµç¨‹
    model_types = ['xgboost', 'lstm']
    result = quick_optimal_system(
        model_types, data['train_data'], data['test_data'],
        data['strategy_data'], data['benchmark_data'], n_trials=3
    )

    # ä¸€è¡Œä»£ç æ˜¾ç¤ºç»“æœ
    print(f"âœ… å¿«é€Ÿç³»ç»Ÿå®Œæˆï¼ç³»ç»ŸéªŒè¯: {result['success']}")
    print(f"âœ… æœ€ä½³æ¨¡å‹æ•°é‡: {len(result['best_models'])}")
    print(f"âœ… å…ƒæ¨¡å‹RÂ²: {result['best_metamodel'].get('performance', {}).get('r2', 0):.3f}")

    return result


def demo_component_level_usage():
    """æ¼”ç¤ºç»„ä»¶çº§åˆ«ä¸€è¡Œä»£ç ç”¨æ³•."""
    print("\nğŸš€ æ¼”ç¤ºç»„ä»¶çº§åˆ«ä¸€è¡Œä»£ç ç”¨æ³•")
    print("=" * 50)

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    config = load_config('configs/quick_test_config.yaml')
    data = generate_mock_data(config)

    # ä¸€è¡Œä»£ç åˆ›å»ºæ¨¡å‹é€‰æ‹©å™¨
    model_selector = create_model_selector(n_trials=3, primary_metric='sharpe_ratio')

    # ä¸€è¡Œä»£ç æ‰¾åˆ°æœ€ä½³æ¨¡å‹
    model_types = ['xgboost', 'lstm']
    best_models = model_selector.find_best_models(
        model_types, data['train_data'], data['test_data'], data['benchmark_data']
    )
    print(f"âœ… æ‰¾åˆ° {len(best_models)} ä¸ªä¼˜åŒ–æ¨¡å‹")

    # ä¸€è¡Œä»£ç åˆ›å»ºå…ƒæ¨¡å‹é€‰æ‹©å™¨
    metamodel_selector = create_metamodel_selector(n_trials=3, weight_method='equal')

    # ä¸€è¡Œä»£ç æ‰¾åˆ°æœ€ä½³å…ƒæ¨¡å‹
    best_metamodel = metamodel_selector.find_best_metamodel(
        data['strategy_data']['returns'], data['strategy_data']['performance']
    )
    print(f"âœ… å…ƒæ¨¡å‹æƒé‡: {list(best_metamodel.get('weights', {}).values())[:3]}...")

    # ä¸€è¡Œä»£ç åˆ›å»ºç³»ç»Ÿè¯„ä¼°å™¨
    system_evaluator = create_system_evaluator(
        primary_metrics=['sharpe_ratio', 'total_return'],
        min_requirements={'sharpe_ratio': 0.5}
    )

    # ä¸€è¡Œä»£ç è¯„ä¼°ç³»ç»Ÿæ€§èƒ½
    portfolio_returns = data['strategy_data']['returns'].mean(axis=1)
    system_performance = system_evaluator.evaluate_complete_system(
        portfolio_returns, data['strategy_data']['returns'],
        data['benchmark_data']['returns']
    )
    print(f"âœ… ç³»ç»ŸSharpe: {system_performance['portfolio_metrics']['sharpe_ratio']:.3f}")

    return {
        'best_models': best_models,
        'best_metamodel': best_metamodel,
        'system_performance': system_performance
    }


def demo_config_driven_usage(config_path: str):
    """æ¼”ç¤ºé…ç½®é©±åŠ¨ç”¨æ³•."""
    print(f"\nğŸš€ æ¼”ç¤ºé…ç½®é©±åŠ¨ç”¨æ³•: {config_path}")
    print("=" * 50)

    # åŠ è½½é…ç½®
    config = load_config(config_path)

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    data = generate_mock_data(config)

    # ä»é…ç½®åˆ›å»ºç³»ç»Ÿ
    system_config = OptimalSystemConfig(
        model_n_trials=config.get('model_selection', {}).get('n_trials', 10),
        metamodel_n_trials=config.get('metamodel_selection', {}).get('n_trials', 10),
        save_results=config.get('output', {}).get('save_results', True),
        output_directory=config.get('output', {}).get('output_directory', './results')
    )

    # ä¸€è¡Œä»£ç åˆ›å»ºåè°ƒå™¨
    orchestrator = OptimalSystemOrchestrator(system_config)

    # ä¸€è¡Œä»£ç è¿è¡Œå®Œæ•´ç³»ç»Ÿ
    model_types = config.get('model_selection', {}).get('model_types', ['xgboost'])
    result = orchestrator.find_and_run_optimal_system(
        model_types, data['train_data'], data['test_data'],
        data['strategy_data'], data['benchmark_data']
    )

    # ä¸€è¡Œä»£ç ç”ŸæˆæŠ¥å‘Š
    report = orchestrator.generate_complete_report(result['system_performance'])

    print(f"âœ… é…ç½®é©±åŠ¨ç³»ç»Ÿå®Œæˆï¼")
    print(f"âœ… {report['summary']['overall_performance']}")
    print(f"âœ… é£é™©ç­‰çº§: {report['summary']['risk_level']}")
    print(f"âœ… éªŒè¯çŠ¶æ€: {report['summary']['validation_status']}")

    return result


def demo_comparison_functionality():
    """æ¼”ç¤ºç³»ç»Ÿå¯¹æ¯”åŠŸèƒ½."""
    print("\nğŸš€ æ¼”ç¤ºç³»ç»Ÿå¯¹æ¯”åŠŸèƒ½")
    print("=" * 50)

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    config = load_config('configs/quick_test_config.yaml')
    data = generate_mock_data(config)

    # åˆ›å»ºå¤šä¸ªé…ç½®
    configs = {
        'conservative': OptimalSystemConfig(
            min_sharpe_ratio=1.0, max_drawdown_threshold=-0.15
        ),
        'aggressive': OptimalSystemConfig(
            min_sharpe_ratio=0.5, max_drawdown_threshold=-0.35
        ),
        'balanced': OptimalSystemConfig(
            min_sharpe_ratio=0.8, max_drawdown_threshold=-0.25
        )
    }

    # ä¸€è¡Œä»£ç å¯¹æ¯”ç³»ç»Ÿé…ç½®
    orchestrator = create_optimal_system_orchestrator(n_trials=2)
    comparison = orchestrator.compare_system_configurations(
        configs, ['xgboost'], data['train_data'], data['test_data']
    )

    print(f"âœ… ç³»ç»Ÿå¯¹æ¯”å®Œæˆï¼")
    print(f"âœ… æœ€ä½³ç³»ç»Ÿ: {comparison['best_system_name']}")
    print(f"âœ… æœ€ä½³Sharpe: {comparison['best_system_metrics']['sharpe_ratio']:.3f}")

    return comparison


def main():
    """ä¸»å‡½æ•°."""
    parser = argparse.ArgumentParser(description='Optimal System Demo')
    parser.add_argument('--config', '-c', type=str,
                       default='configs/optimal_system_config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quick-test', action='store_true',
                       help='è¿è¡Œå¿«é€Ÿæµ‹è¯•')
    parser.add_argument('--custom-config', action='store_true',
                       help='è¿è¡Œè‡ªå®šä¹‰é…ç½®æ¼”ç¤º')
    parser.add_argument('--log-level', type=str, default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       help='æ—¥å¿—çº§åˆ«')

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—
    setup_logging(args.log_level)

    print("ğŸ¯ Optimal System Demo - ä¸€è¡Œä»£ç æœ€ä¼˜ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)

    try:
        # åŸºç¡€ä¸€è¡Œä»£ç æ¼”ç¤º
        demo_basic_one_line_usage()

        # å¿«é€Ÿæœ€ä¼˜ç³»ç»Ÿæ¼”ç¤º
        demo_quick_optimal_system()

        # ç»„ä»¶çº§åˆ«æ¼”ç¤º
        demo_component_level_usage()

        # ç³»ç»Ÿå¯¹æ¯”æ¼”ç¤º
        demo_comparison_functionality()

        # é…ç½®é©±åŠ¨æ¼”ç¤º
        if args.custom_config:
            demo_config_driven_usage(args.config)
        elif args.quick_test:
            demo_config_driven_usage('configs/quick_test_config.yaml')
        else:
            demo_config_driven_usage(args.config)

        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼ä¸€è¡Œä»£ç æœ€ä¼˜ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")

    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()