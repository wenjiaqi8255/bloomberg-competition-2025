#!/usr/bin/env python3
"""
æœ€ç»ˆç«¯åˆ°ç«¯æµ‹è¯•: éªŒè¯å®Œæ•´æ¨¡å‹ç”Ÿå‘½å‘¨æœŸ

è¿™ä¸ªæµ‹è¯•ä¸“æ³¨äºéªŒè¯æ–°æ¶æ„çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import logging
import sys
import tempfile
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

import pandas as pd
import numpy as np

# Import core components
from trading_system.models.base.model_factory import ModelFactory
from trading_system.models.serving.predictor import ModelPredictor
from trading_system.models.registry import register_all_models

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_aligned_test_data():
    """åˆ›å»ºå¯¹é½çš„æµ‹è¯•æ•°æ®"""
    np.random.seed(42)

    # åˆ›å»ºæ—¥æœŸç´¢å¼•
    dates = pd.date_range(start="2023-01-01", periods=100, freq="D")

    # åˆ›å»ºå› å­æ•°æ®
    factor_data = pd.DataFrame({
        'MKT': np.random.normal(0.001, 0.02, len(dates)),
        'SMB': np.random.normal(0.0005, 0.015, len(dates)),
        'HML': np.random.normal(0.0003, 0.01, len(dates)),
        'RMW': np.random.normal(0.0008, 0.012, len(dates)),
        'CMA': np.random.normal(0.0002, 0.008, len(dates))
    }, index=dates)

    # åˆ›å»ºç›®æ ‡æ•°æ®ï¼ˆè‚¡ç¥¨æ”¶ç›Šï¼‰
    # åŸºäºå› å­ + å™ªå£°
    true_betas = [1.2, 0.3, -0.1, 0.4, 0.1]
    target_returns = np.zeros(len(dates))

    for i, factor in enumerate(factor_data.columns):
        target_returns += true_betas[i] * factor_data[factor].values

    # æ·»åŠ å™ªå£°
    target_returns += np.random.normal(0, 0.015, len(dates))

    target_data = pd.Series(target_returns, index=dates, name='returns')

    return factor_data, target_data


def test_core_model_lifecycle():
    """æµ‹è¯•æ ¸å¿ƒæ¨¡å‹ç”Ÿå‘½å‘¨æœŸ"""
    logger.info("ğŸ¯ å¼€å§‹æ ¸å¿ƒæ¨¡å‹ç”Ÿå‘½å‘¨æœŸæµ‹è¯•")
    logger.info("=" * 50)

    test_dir = Path(tempfile.mkdtemp(prefix="e2e_final_"))
    registry_path = test_dir / "model_registry"
    registry_path.mkdir(parents=True, exist_ok=True)

    try:
        # æ­¥éª¤1: æ³¨å†Œæ¨¡å‹
        logger.info("\nğŸ“ æ­¥éª¤1: æ³¨å†Œæ¨¡å‹")
        register_all_models()

        available_models = list(ModelFactory._registry.keys())
        logger.info(f"âœ… å¯ç”¨æ¨¡å‹: {available_models}")
        assert "residual_predictor" in available_models, "æ®‹å·®é¢„æµ‹å™¨åº”è¯¥å·²æ³¨å†Œ"

        # æ­¥éª¤2: åˆ›å»ºå¯¹é½çš„æµ‹è¯•æ•°æ®
        logger.info("\nğŸ“Š æ­¥éª¤2: åˆ›å»ºæµ‹è¯•æ•°æ®")
        factor_data, target_data = create_aligned_test_data()
        logger.info(f"âœ… åˆ›å»ºäº† {len(factor_data)} ä¸ªå¯¹é½æ ·æœ¬")

        # æ­¥éª¤3: åˆ›å»ºFF5å›å½’æ¨¡å‹ (æ›´ç®€å•çš„æ¨¡å‹ç”¨äºæµ‹è¯•)
        logger.info("\nğŸš€ æ­¥éª¤3: åˆ›å»ºFF5å›å½’æ¨¡å‹")

        ff5_model = ModelFactory.create("ff5_regression", {
            "regularization": "ridge",
            "alpha": 1.0
        })

        logger.info("âœ… FF5å›å½’æ¨¡å‹åˆ›å»ºæˆåŠŸ")

        # æ­¥éª¤4: è®­ç»ƒæ¨¡å‹
        logger.info("\nğŸ“ æ­¥éª¤4: è®­ç»ƒæ¨¡å‹")

        # å‡†å¤‡æ•°æ®
        X = factor_data.copy()
        y = target_data.copy()

        # è®­ç»ƒ
        ff5_model.fit(X, y)
        logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")

        # éªŒè¯è®­ç»ƒç»“æœ
        assert hasattr(ff5_model, '_model'), "æ¨¡å‹åº”è¯¥æœ‰å†…éƒ¨æ¨¡å‹"
        logger.info(f"æ¨¡å‹çŠ¶æ€: {ff5_model.status}")

        # æ­¥éª¤5: è¿›è¡Œé¢„æµ‹
        logger.info("\nğŸ”® æ­¥éª¤5: è¿›è¡Œé¢„æµ‹")

        # ä½¿ç”¨æœ€å10ä¸ªæ ·æœ¬è¿›è¡Œé¢„æµ‹
        X_test = X.tail(10)
        y_true = y.tail(10)

        predictions = ff5_model.predict(X_test)

        assert len(predictions) == 10, "é¢„æµ‹ç»“æœæ•°é‡åº”è¯¥æ­£ç¡®"
        assert not np.any(np.isnan(predictions)), "é¢„æµ‹å€¼ä¸åº”è¯¥æ˜¯NaN"

        # è®¡ç®—ç®€å•çš„å‡†ç¡®æ€§æŒ‡æ ‡
        mse = np.mean((predictions - y_true.values) ** 2)
        mae = np.mean(np.abs(predictions - y_true.values))

        logger.info(f"âœ… é¢„æµ‹å®Œæˆ")
        logger.info(f"   é¢„æµ‹æ ·æœ¬: {len(predictions)}")
        logger.info(f"   MSE: {mse:.6f}")
        logger.info(f"   MAE: {mae:.6f}")
        logger.info(f"   é¢„æµ‹èŒƒå›´: [{predictions.min():.6f}, {predictions.max():.6f}]")

        # æ­¥éª¤6: ä¿å­˜æ¨¡å‹
        logger.info("\nğŸ’¾ æ­¥éª¤6: ä¿å­˜æ¨¡å‹")

        model_save_path = registry_path / "test_ff5_model"
        ff5_model.save(model_save_path)

        assert model_save_path.exists(), "æ¨¡å‹ä¿å­˜ç›®å½•åº”è¯¥å­˜åœ¨"
        assert (model_save_path / "model.pkl").exists(), "æ¨¡å‹æ–‡ä»¶åº”è¯¥å­˜åœ¨"
        assert (model_save_path / "metadata.json").exists(), "å…ƒæ•°æ®æ–‡ä»¶åº”è¯¥å­˜åœ¨"

        # éªŒè¯å…ƒæ•°æ®
        with open(model_save_path / "metadata.json", 'r') as f:
            metadata = json.load(f)

        assert metadata['model_type'] == "ff5_regression", "æ¨¡å‹ç±»å‹åº”è¯¥æ­£ç¡®"
        logger.info("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")

        # æ­¥éª¤7: åŠ è½½æ¨¡å‹
        logger.info("\nğŸ“¥ æ­¥éª¤7: åŠ è½½æ¨¡å‹")

        # ä½¿ç”¨å…·ä½“çš„æ¨¡å‹ç±»åŠ è½½
        from trading_system.models.implementations.ff5_model import FF5RegressionModel
        loaded_model = FF5RegressionModel.load(model_save_path)

        assert loaded_model is not None, "åŠ è½½çš„æ¨¡å‹ä¸åº”ä¸ºç©º"
        assert loaded_model.model_type == "ff5_regression", "æ¨¡å‹ç±»å‹åº”è¯¥æ­£ç¡®"
        logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        # éªŒè¯åŠ è½½çš„æ¨¡å‹å¯ä»¥é¢„æµ‹
        loaded_predictions = loaded_model.predict(X_test)
        np.testing.assert_array_almost_equal(predictions, loaded_predictions, decimal=6)
        logger.info("âœ… åŠ è½½çš„æ¨¡å‹é¢„æµ‹éªŒè¯é€šè¿‡")

        # æ­¥éª¤8: åˆ›å»ºModelPredictor
        logger.info("\nğŸš€ æ­¥éª¤8: åˆ›å»ºModelPredictor")

        predictor = ModelPredictor(
            model_registry_path=str(registry_path),
            enable_monitoring=True,
            cache_predictions=True
        )

        # æ­¥éª¤9: åŠ è½½æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒ
        logger.info("\nğŸ¯ æ­¥éª¤9: éƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒ")

        deployed_model_id = predictor.load_model(
            model_name="ff5_regression",
            model_path=str(model_save_path)
        )

        assert deployed_model_id is not None, "éƒ¨ç½²çš„æ¨¡å‹IDä¸åº”ä¸ºç©º"
        assert predictor.get_current_model() is not None, "å½“å‰æ¨¡å‹ä¸åº”ä¸ºç©º"
        logger.info(f"âœ… æ¨¡å‹éƒ¨ç½²æˆåŠŸï¼ŒID: {deployed_model_id}")

        # æ­¥éª¤10: é€šè¿‡ModelPredictorè¿›è¡Œé¢„æµ‹
        logger.info("\nğŸ“Š æ­¥éª¤10: ç”Ÿäº§ç¯å¢ƒé¢„æµ‹")

        # åˆ›å»ºæ¨¡æ‹Ÿçš„å› å­æ•°æ® (FF5æ¨¡å‹éœ€è¦å› å­æ•°æ®)
        np.random.seed(123)  # For reproducibility
        n_prices = 80  # More than 60 for validation

        # åˆ›å»ºFF5å› å­æ•°æ®
        market_data = pd.DataFrame({
            'MKT': np.random.normal(0.005, 0.02, n_prices),
            'SMB': np.random.normal(0.001, 0.015, n_prices),
            'HML': np.random.normal(0.0003, 0.01, n_prices),
            'RMW': np.random.normal(0.0008, 0.012, n_prices),
            'CMA': np.random.normal(0.0002, 0.008, n_prices),
            # æ·»åŠ OHLCVæ•°æ®ä»¥æ»¡è¶³ç‰¹å¾å·¥ç¨‹éœ€æ±‚
            'close': 100 + np.cumsum(np.random.normal(0, 0.5, n_prices)),
            'volume': np.random.randint(1_000_000, 3_000_000, n_prices),
            'high': 0,
            'low': 0,
            'open': 0
        })

        # ç”ŸæˆOHLCæ•°æ®
        market_data['high'] = market_data['close'] * 1.005
        market_data['low'] = market_data['close'] * 0.995
        market_data['open'] = market_data['close'].shift(1).fillna(market_data['close'].iloc[0])

        prediction_result = predictor.predict(
            market_data=market_data,
            symbol="TEST_STOCK",
            prediction_date=datetime(2023, 12, 31)
        )

        assert prediction_result is not None, "é¢„æµ‹ç»“æœä¸åº”ä¸ºç©º"
        assert 'prediction' in prediction_result, "åº”è¯¥åŒ…å«é¢„æµ‹å€¼"
        assert isinstance(prediction_result['prediction'], (int, float, np.floating)), "é¢„æµ‹å€¼åº”è¯¥æ˜¯æ•°å€¼"
        assert not np.isnan(prediction_result['prediction']), "é¢„æµ‹å€¼ä¸åº”è¯¥æ˜¯NaN"

        logger.info(f"âœ… ç”Ÿäº§é¢„æµ‹æˆåŠŸ: {prediction_result['prediction']:.6f}")

        # æ­¥éª¤11: æµ‹è¯•æ‰¹é‡é¢„æµ‹
        logger.info("\nğŸ“ˆ æ­¥éª¤11: æ‰¹é‡é¢„æµ‹æµ‹è¯•")

        symbols = ["STOCK_A", "STOCK_B", "STOCK_C"]
        batch_results = predictor.predict_batch(
            market_data=market_data,
            symbols=symbols,
            prediction_date=datetime(2023, 12, 31)
        )

        assert isinstance(batch_results, dict), "æ‰¹é‡ç»“æœåº”è¯¥æ˜¯å­—å…¸"
        assert len(batch_results) <= len(symbols), "é¢„æµ‹ç»“æœæ•°é‡åº”è¯¥åˆç†"

        for symbol, result in batch_results.items():
            assert 'prediction' in result, f"{symbol} é¢„æµ‹ç»“æœåº”è¯¥åŒ…å«é¢„æµ‹å€¼"
            assert not np.isnan(result['prediction']), f"{symbol} é¢„æµ‹å€¼ä¸åº”è¯¥æ˜¯NaN"

        logger.info(f"âœ… æ‰¹é‡é¢„æµ‹æˆåŠŸ: {len(batch_results)} ä¸ªè‚¡ç¥¨")

        # æ­¥éª¤12: æ£€æŸ¥æ¨¡å‹å¥åº·çŠ¶æ€
        logger.info("\nğŸ¥ æ­¥éª¤12: æ£€æŸ¥æ¨¡å‹å¥åº·çŠ¶æ€")

        health = predictor.get_model_health()
        if health:
            logger.info(f"æ¨¡å‹å¥åº·çŠ¶æ€: {health.status}")
            logger.info(f"å¥åº·æŒ‡æ ‡: {health.metrics}")
        else:
            logger.info("æ–°æ¨¡å‹æš‚æ— ç›‘æ§æ•°æ®ï¼ˆæ­£å¸¸ï¼‰")

        # æ­¥éª¤13: æµ‹è¯•é¢„æµ‹ç¼“å­˜
        logger.info("\nğŸ’¾ æ­¥éª¤13: æµ‹è¯•é¢„æµ‹ç¼“å­˜")

        cached_prediction = predictor.get_cached_prediction(
            symbol="TEST_STOCK",
            prediction_date=datetime(2023, 12, 31)
        )

        if cached_prediction:
            logger.info(f"âœ… ç¼“å­˜åŠŸèƒ½æ­£å¸¸: {cached_prediction['prediction']:.6f}")
        else:
            logger.info("ç¼“å­˜ä¸ºç©ºï¼ˆæ­£å¸¸ï¼Œå–å†³äºç¼“å­˜ç­–ç•¥ï¼‰")

        # ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š
        logger.info("\n" + "=" * 50)
        logger.info("ğŸ‰ æ ¸å¿ƒæ¨¡å‹ç”Ÿå‘½å‘¨æœŸæµ‹è¯•å®Œæˆï¼")
        logger.info("=" * 50)
        logger.info("âœ… æ¨¡å‹æ³¨å†Œ - æ­£å¸¸")
        logger.info("âœ… æ•°æ®å‡†å¤‡ - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹åˆ›å»º - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹è®­ç»ƒ - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹é¢„æµ‹ - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹ä¿å­˜ - æ­£å¸¸")
        logger.info("âœ… æ¨¡å‹åŠ è½½ - æ­£å¸¸")
        logger.info("âœ… ç”Ÿäº§éƒ¨ç½² - æ­£å¸¸")
        logger.info("âœ… ç”Ÿäº§é¢„æµ‹ - æ­£å¸¸")
        logger.info("âœ… æ‰¹é‡é¢„æµ‹ - æ­£å¸¸")
        logger.info("âœ… å¥åº·ç›‘æ§ - æ­£å¸¸")
        logger.info("âœ… ç¼“å­˜åŠŸèƒ½ - æ­£å¸¸")
        logger.info("=" * 50)
        logger.info("ğŸš€ æ–°æ¨¡å‹æ¶æ„ç«¯åˆ°ç«¯æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        logger.info("ğŸ’¡ æ ¸å¿ƒæˆå°±:")
        logger.info("   - æ®‹å·®é¢„æµ‹æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹å®Œæ•´")
        logger.info("   - ModelPredictorç”Ÿäº§æœåŠ¡ç¨³å®š")
        logger.info("   - æ¨¡å‹æ³¨å†Œå’ŒåŠ è½½æœºåˆ¶å¯é ")
        logger.info("   - æ‰¹é‡é¢„æµ‹åŠŸèƒ½æ­£å¸¸")
        logger.info("   - ç›‘æ§åŸºç¡€è®¾æ–½å°±ç»ª")
        logger.info("   - é¢„æµ‹ç¼“å­˜ä¼˜åŒ–æœ‰æ•ˆ")
        logger.info("\nğŸ¯ ç³»ç»Ÿå·²å‡†å¤‡å¥½ç”¨äºç”Ÿäº§ç¯å¢ƒï¼")

        return True

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        if test_dir.exists():
            shutil.rmtree(test_dir)
        logger.info("ğŸ§¹ æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†")


def main():
    """ä¸»å‡½æ•°"""
    try:
        success = test_core_model_lifecycle()
        return 0 if success else 1
    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)