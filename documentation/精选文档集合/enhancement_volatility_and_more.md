é—®é¢˜investigationï¼š
Summary of Root Causes

  I've identified the main issues causing weak signals in both
  FF5 and XGBoost models:

  Primary Issue: Double Signal Normalization

  1. Inverse Volatility Scaling (line 367-368): signal = 
  prediction Ã— (1/volatility)
  2. Total Weight Normalization (line 386): signal = signal / 
  total_weight Ã— target_exposure

  This creates a massive dilution effect where strong model
  predictions get normalized down to very small values.

  Secondary Issue: Position Sizer vs Strategy Signal Processing

  Both the base strategy (_apply_forward_position_sizing) and
  the ML strategy (generate_signals_single_date) are applying
  signal strength filtering, creating redundant filtering that
  can zero out legitimate signals.

  Recommended Fix

  The position sizing logic needs to be redesigned to:
  1. Remove inverse volatility scaling (let the model
  predictions speak for themselves)
  2. Use the PositionSizer properly (it already handles
  volatility scaling)
  3. Eliminate double normalization

  Would you like me to implement these fixes? The key changes
  would be:

  1. Modify _apply_forward_position_sizing to use the
  PositionSizer correctly
  2. Remove redundant signal filtering in the base strategy
  3. Let the PositionSizer handle volatility scaling using its
  established methodology

  This should dramatically improve signal strength for both
  models while maintaining proper risk management.

  
æ ¹æ®ä½ çš„é¡¹ç›®ç»“æ„å’Œäº”ä¸ªæ ¸å¿ƒå»ºè®®ï¼Œæˆ‘ä¸ºä½ åˆ¶å®šä¸€ä¸ªæ¸…æ™°çš„æ‰§è¡Œæ–¹æ¡ˆã€‚æˆ‘ä¼šæ˜ç¡®æŒ‡å‡ºæ¯ä¸ªæ”¹åŠ¨åœ¨å“ªä¸ªå±‚é¢ï¼Œä¸ºä»€ä¹ˆæ”¹ï¼Œä»¥åŠå…·ä½“çš„èŒè´£åˆ†é…ã€‚

---

# ğŸ¯ **é‡åŒ–äº¤æ˜“ç³»ç»Ÿæ”¹è¿›æ‰§è¡Œæ–¹æ¡ˆ**

## ğŸ“‹ **æ¶æ„å±‚æ¬¡è¯´æ˜**

æ ¹æ®ä½ çš„ä»£ç ç»“æ„ï¼Œç³»ç»Ÿåˆ†ä¸ºä»¥ä¸‹å±‚æ¬¡ï¼š

```
Layer 1: åŸºç¡€è®¾æ–½å±‚ (utils/, types/)
         â†“
Layer 2: æ•°æ®å±‚ (data/, feature_engineering/)
         â†“
Layer 3: æ¨¡å‹å±‚ (models/)
         â†“
Layer 4: ç­–ç•¥å±‚ (strategies/)
         â†“
Layer 5: ç¼–æ’å±‚ (orchestration/, backtesting/)
```

---

## ğŸ”§ **æ”¹è¿›æ–¹æ¡ˆä¸€ï¼šåˆ†ç¦»ä¿¡å·ç”Ÿæˆä¸é£é™©ç®¡ç†**

### **é—®é¢˜è¯Šæ–­**
å½“å‰ `base_strategy.py` çš„ `generate_signals()` æ–¹æ³•æ··åˆäº†ï¼š
- é¢„æµ‹é€»è¾‘ï¼ˆåº”è¯¥å±äºæ¨¡å‹å±‚ï¼‰
- é£é™©è°ƒæ•´ï¼ˆåº”è¯¥ç‹¬ç«‹å¤„ç†ï¼‰
- ä»“ä½sizingï¼ˆåº”è¯¥ç‹¬ç«‹å¤„ç†ï¼‰

### **æ”¹è¿›ç›®æ ‡**
å°†æµç¨‹åˆ†è§£ä¸ºï¼š
```
åŸå§‹é¢„æµ‹ â†’ Alphaä¿¡å· â†’ é£é™©è¯„ä¼° â†’ ä»“ä½ä¼˜åŒ– â†’ æœ€ç»ˆæƒé‡
```

### **å…·ä½“æ”¹åŠ¨**

#### **æ”¹åŠ¨ä½ç½®**: `strategies/base_strategy.py` (Layer 4)

**æ–°å¢æ–¹æ³•**ï¼š

```python
# æ–¹æ³•1: ç”ŸæˆåŸå§‹Alphaä¿¡å·ï¼ˆçº¯é¢„æµ‹ï¼Œæ— é£é™©è°ƒæ•´ï¼‰
def generate_raw_alpha_signals(self, price_data, date):
    """
    èŒè´£ï¼šä»…åšé¢„æµ‹ï¼Œè¾“å‡ºæ ‡å‡†åŒ–çš„Alphaåˆ†æ•°
    
    è¾“å…¥ï¼šprice_dataå­—å…¸ï¼Œdateæ—¶é—´ç‚¹
    è¾“å‡ºï¼šDataFrameï¼Œåˆ—=è‚¡ç¥¨ä»£ç ï¼Œå€¼=z-scoreæ ‡å‡†åŒ–çš„Alphaåˆ†æ•°
          èŒƒå›´ï¼š[-3, 3]ï¼Œå‡å€¼0ï¼Œæ ‡å‡†å·®1
    
    ä¸ºä»€ä¹ˆï¼š
    - åˆ†ç¦»é¢„æµ‹ä¸é£é™©ç®¡ç†çš„èŒè´£
    - ä¾¿äºå•ç‹¬è¯„ä¼°æ¨¡å‹é¢„æµ‹èƒ½åŠ›ï¼ˆç”¨IC/Rank ICï¼‰
    - ä¾¿äºç»„åˆå¤šä¸ªç­–ç•¥çš„Alphaä¿¡å·
    """
    # ç¬¬ä¸€æ­¥ï¼šè®¡ç®—ç‰¹å¾
    features = self._compute_features(price_data)
    
    # ç¬¬äºŒæ­¥ï¼šæ¨¡å‹é¢„æµ‹
    predictions = {}
    for symbol in price_data.keys():
        symbol_features = self._extract_symbol_features(features, symbol)
        pred_result = self.model_predictor.predict(
            features=symbol_features,
            symbol=symbol,
            prediction_date=date
        )
        predictions[symbol] = pred_result.prediction
    
    # ç¬¬ä¸‰æ­¥ï¼šæ ‡å‡†åŒ–ä¸ºz-score
    pred_series = pd.Series(predictions)
    alpha_scores = (pred_series - pred_series.mean()) / pred_series.std()
    
    return pd.DataFrame([alpha_scores])


# æ–¹æ³•2: Alphaä¿¡å·è½¬æ¢ä¸ºé¢„æœŸæ”¶ç›Šç‡
def alpha_to_expected_returns(self, alpha_scores, scaling_factor=0.02):
    """
    èŒè´£ï¼šå°†Alphaåˆ†æ•°æ˜ å°„åˆ°é¢„æœŸæ”¶ç›Šç‡
    
    è¾“å…¥ï¼šalpha_scores (z-scoreæ ‡å‡†åŒ–)
    è¾“å‡ºï¼šexpected_returns (æ¯”å¦‚ 0.03 = é¢„æœŸ3%æ”¶ç›Š)
    
    ä¸ºä»€ä¹ˆï¼š
    - æ¨¡å‹è¾“å‡ºæ˜¯ç›¸å¯¹åˆ†æ•°ï¼Œéœ€è¦æ˜ å°„åˆ°å®é™…æ”¶ç›Šç‡
    - scaling_factorå¯ä»¥æ ¹æ®å†å²ICå›æµ‹æ ¡å‡†
    
    è®¡ç®—ï¼šexpected_return = alpha_score Ã— scaling_factor
    """
    return alpha_scores * scaling_factor


# æ–¹æ³•3: é£é™©è°ƒæ•´åçš„æƒé‡
def apply_risk_adjustment(self, expected_returns, cov_matrix, method='kelly'):
    """
    èŒè´£ï¼šæ ¹æ®é£é™©æ¨¡å‹è°ƒæ•´ä»“ä½
    
    è¾“å…¥ï¼š
    - expected_returns: é¢„æœŸæ”¶ç›Šç‡å‘é‡
    - cov_matrix: åæ–¹å·®çŸ©é˜µï¼ˆæ¥è‡ªæ–°çš„é£é™©ä¼°è®¡å™¨ï¼‰
    - method: 'kelly' / 'risk_parity' / 'mean_variance'
    
    è¾“å‡ºï¼šrisk_adjusted_weights (å½’ä¸€åŒ–åçš„æƒé‡)
    
    ä¸ºä»€ä¹ˆï¼š
    - ç‹¬ç«‹çš„é£é™©ç®¡ç†æ¨¡å—
    - å¯ä»¥è½»æ¾åˆ‡æ¢ä¸åŒçš„ä»“ä½sizingæ–¹æ³•
    """
    if method == 'kelly':
        return self._fractional_kelly_weights(expected_returns, cov_matrix)
    elif method == 'risk_parity':
        return self._risk_parity_weights(cov_matrix)
    else:
        return self._mean_variance_weights(expected_returns, cov_matrix)


# æ–¹æ³•4: ä¸»æµç¨‹ï¼ˆç¼–æ’ä¸Šè¿°æ–¹æ³•ï¼‰
def generate_signals(self, price_data, date):
    """
    èŒè´£ï¼šç¼–æ’æ•´ä¸ªæµç¨‹ï¼Œä½†ä¸æ··åˆé€»è¾‘
    
    è¾“å‡ºï¼šåŒ…å«è¯¦ç»†ä¿¡æ¯çš„å­—å…¸ï¼Œä¾›åç»­åˆ†æå’Œæ‰§è¡Œ
    """
    # æ­¥éª¤1: åŸå§‹Alpha
    alpha_scores = self.generate_raw_alpha_signals(price_data, date)
    
    # æ­¥éª¤2: è½¬æ¢ä¸ºé¢„æœŸæ”¶ç›Š
    expected_returns = self.alpha_to_expected_returns(alpha_scores)
    
    # æ­¥éª¤3: ä¼°è®¡åæ–¹å·®çŸ©é˜µï¼ˆè°ƒç”¨æ–°çš„é£é™©ä¼°è®¡å™¨ï¼‰
    cov_matrix = self.risk_estimator.estimate(price_data, date)
    
    # æ­¥éª¤4: é£é™©è°ƒæ•´
    risk_adjusted_weights = self.apply_risk_adjustment(
        expected_returns, cov_matrix, method='kelly'
    )
    
    # æ­¥éª¤5: åº”ç”¨çº¦æŸï¼ˆæœ€å¤§ä»“ä½ã€è¡Œä¸šé™åˆ¶ç­‰ï¼‰
    final_weights = self._apply_constraints(risk_adjusted_weights)
    
    # è¿”å›å®Œæ•´ä¿¡æ¯ï¼ˆç”¨äºè¯Šæ–­å’Œå½’å› ï¼‰
    return {
        'weights': final_weights,           # æœ€ç»ˆæ‰§è¡Œæƒé‡
        'alpha_scores': alpha_scores,       # ç”¨äºICè¯„ä¼°
        'expected_returns': expected_returns, # ç”¨äºå½’å› åˆ†æ
        'risk_adjusted_weights': risk_adjusted_weights, # é£é™©è°ƒæ•´å‰
        'cov_matrix': cov_matrix,           # ç”¨äºé£é™©æŠ¥å‘Š
        'metadata': {
            'date': date,
            'method': 'kelly',
            'n_positions': (final_weights != 0).sum()
        }
    }
```

---

## ğŸ”§ **æ”¹è¿›æ–¹æ¡ˆäºŒï¼šå¢å¼ºé£é™©æ¨¡å‹ï¼ˆåæ–¹å·®ä¼°è®¡ï¼‰**

### **é—®é¢˜è¯Šæ–­**
å½“å‰ä»£ç åªç”¨ç®€å•çš„å†å²æ³¢åŠ¨ç‡ï¼Œæ²¡æœ‰è€ƒè™‘ï¼š
- è‚¡ç¥¨é—´çš„ç›¸å…³æ€§
- æ—¶å˜æ³¢åŠ¨ç‡ï¼ˆGARCHæ•ˆåº”ï¼‰
- åæ–¹å·®çŸ©é˜µçš„æ”¶ç¼©ä¼°è®¡

### **æ”¹è¿›ç›®æ ‡**
å®ç°DCC-NLæˆ–å› å­æ¨¡å‹çš„åæ–¹å·®ä¼°è®¡

### **å…·ä½“æ”¹åŠ¨**

#### **æ–°å¢æ–‡ä»¶**: `utils/risk.py` æˆ–æ‰©å±•ç°æœ‰çš„ `utils/risk.py` (Layer 1)

**æ–°å¢ç±»**ï¼š

```python
class CovarianceEstimator(ABC):
    """
    åæ–¹å·®ä¼°è®¡å™¨çš„åŸºç±»
    
    ä¸ºä»€ä¹ˆè®¾è®¡ä¸ºåŸºç±»ï¼š
    - å¯ä»¥è½»æ¾åˆ‡æ¢ä¸åŒæ–¹æ³•ï¼ˆç®€å•/Ledoit-Wolf/DCC-NLï¼‰
    - ç»Ÿä¸€æ¥å£ï¼Œç­–ç•¥å±‚æ— éœ€ä¿®æ”¹
    """
    
    @abstractmethod
    def estimate(self, price_data: Dict, date: datetime) -> np.ndarray:
        """
        è¾“å…¥ï¼šå†å²ä»·æ ¼æ•°æ®
        è¾“å‡ºï¼šNÃ—Nåæ–¹å·®çŸ©é˜µï¼ˆå¹´åŒ–ï¼‰
        """
        pass


class SimpleCovarianceEstimator(CovarianceEstimator):
    """
    ç®€å•å†å²åæ–¹å·®ï¼ˆä½œä¸ºbaselineï¼‰
    
    èŒè´£ï¼šä½¿ç”¨æ»šåŠ¨çª—å£è®¡ç®—æ ·æœ¬åæ–¹å·®
    """
    
    def __init__(self, lookback_days=252):
        self.lookback_days = lookback_days
    
    def estimate(self, price_data: Dict, date: datetime) -> np.ndarray:
        """
        è®¡ç®—ï¼š
        1. æå–æœ€è¿‘lookback_daysçš„æ”¶ç›Šç‡
        2. è®¡ç®—æ ·æœ¬åæ–¹å·®çŸ©é˜µ
        3. å¹´åŒ–ï¼ˆÃ—252ï¼‰
        """
        # æ„å»ºæ”¶ç›Šç‡çŸ©é˜µ
        returns_dict = {}
        for symbol, data in price_data.items():
            recent_data = data[data.index <= date].tail(self.lookback_days)
            returns_dict[symbol] = recent_data['Close'].pct_change().dropna()
        
        returns_df = pd.DataFrame(returns_dict)
        
        # æ ·æœ¬åæ–¹å·®çŸ©é˜µï¼ˆå¹´åŒ–ï¼‰
        cov_matrix = returns_df.cov() * 252
        
        return cov_matrix.values


class LedoitWolfCovarianceEstimator(CovarianceEstimator):
    """
    Ledoit-Wolfæ”¶ç¼©ä¼°è®¡
    
    èŒè´£ï¼šå‡å°‘é«˜ç»´åæ–¹å·®çŸ©é˜µçš„ä¼°è®¡è¯¯å·®
    
    ä¸ºä»€ä¹ˆï¼š
    - å½“è‚¡ç¥¨æ•°é‡æ¥è¿‘è§‚æµ‹æ•°é‡æ—¶ï¼Œæ ·æœ¬åæ–¹å·®ä¸ç¨³å®š
    - æ”¶ç¼©åˆ°ç»“æ„åŒ–ç›®æ ‡ï¼ˆå¦‚å•ä½çŸ©é˜µæˆ–å•å› å­çŸ©é˜µï¼‰
    
    æ•°å­¦ï¼šÎ£_shrunk = Î´Ã—F + (1-Î´)Ã—S
         å…¶ä¸­Fæ˜¯ç›®æ ‡çŸ©é˜µï¼ŒSæ˜¯æ ·æœ¬åæ–¹å·®ï¼ŒÎ´æ˜¯æ”¶ç¼©å¼ºåº¦
    """
    
    def __init__(self, lookback_days=252):
        self.lookback_days = lookback_days
    
    def estimate(self, price_data: Dict, date: datetime) -> np.ndarray:
        # æ„å»ºæ”¶ç›Šç‡çŸ©é˜µï¼ˆåŒä¸Šï¼‰
        returns_df = self._build_returns_matrix(price_data, date)
        
        # åº”ç”¨Ledoit-Wolfæ”¶ç¼©
        from sklearn.covariance import LedoitWolf
        lw = LedoitWolf()
        shrunk_cov = lw.fit(returns_df).covariance_
        
        # å¹´åŒ–
        return shrunk_cov * 252


class FactorModelCovarianceEstimator(CovarianceEstimator):
    """
    å› å­æ¨¡å‹åæ–¹å·®ä¼°è®¡
    
    èŒè´£ï¼šä½¿ç”¨å› å­åˆ†è§£é™ä½ç»´åº¦
    
    ä¸ºä»€ä¹ˆï¼š
    - å¤§å¹…å‡å°‘éœ€è¦ä¼°è®¡çš„å‚æ•°æ•°é‡
    - ä»O(NÂ²)é™ä½åˆ°O(NÃ—K)ï¼ŒKæ˜¯å› å­æ•°é‡
    
    æ¨¡å‹ï¼šÎ£ = BÃ—FÃ—B^T + D
         Bæ˜¯å› å­è½½è·ï¼ŒFæ˜¯å› å­åæ–¹å·®ï¼ŒDæ˜¯ç‰¹å¼‚æ€§é£é™©
    """
    
    def __init__(self, factor_data_provider, lookback_days=252):
        """
        factor_data_provider: æä¾›Fama-Frenchæˆ–è‡ªå®šä¹‰å› å­æ•°æ®
        """
        self.factor_provider = factor_data_provider
        self.lookback_days = lookback_days
    
    def estimate(self, price_data: Dict, date: datetime) -> np.ndarray:
        """
        æ­¥éª¤ï¼š
        1. è·å–å› å­æ”¶ç›Šç‡
        2. å¯¹æ¯ä¸ªè‚¡ç¥¨å›å½’ï¼Œä¼°è®¡Beta
        3. ä¼°è®¡å› å­åæ–¹å·®çŸ©é˜µF
        4. ä¼°è®¡ç‰¹å¼‚æ€§é£é™©D
        5. ç»„åˆï¼šÎ£ = BÃ—FÃ—B^T + D
        """
        # æ­¥éª¤1: è·å–å› å­æ•°æ®
        factor_returns = self.factor_provider.get_factor_returns(
            start_date=date - timedelta(days=self.lookback_days),
            end_date=date
        )
        
        # æ­¥éª¤2: ä¼°è®¡æ¯ä¸ªè‚¡ç¥¨çš„å› å­è½½è·ï¼ˆBetaï¼‰
        betas = self._estimate_factor_loadings(price_data, factor_returns, date)
        
        # æ­¥éª¤3: å› å­åæ–¹å·®çŸ©é˜µ
        F = factor_returns.cov() * 252
        
        # æ­¥éª¤4: ç‰¹å¼‚æ€§é£é™©ï¼ˆæ®‹å·®çš„åæ–¹å·®ï¼‰
        D = self._estimate_idiosyncratic_risk(price_data, factor_returns, betas, date)
        
        # æ­¥éª¤5: ç»„åˆ
        B = np.array([betas[symbol] for symbol in price_data.keys()])
        cov_matrix = B @ F @ B.T + D
        
        return cov_matrix
```

#### **ä¿®æ”¹ä½ç½®**: `strategies/base_strategy.py`

**åœ¨ `__init__` ä¸­æ·»åŠ **ï¼š

```python
def __init__(self, ..., risk_estimator_type='ledoit_wolf', **kwargs):
    # ... ç°æœ‰ä»£ç  ...
    
    # æ–°å¢ï¼šåˆå§‹åŒ–é£é™©ä¼°è®¡å™¨
    self.risk_estimator = self._create_risk_estimator(risk_estimator_type)

def _create_risk_estimator(self, estimator_type):
    """
    å·¥å‚æ–¹æ³•åˆ›å»ºé£é™©ä¼°è®¡å™¨
    
    ä¸ºä»€ä¹ˆï¼š
    - ç­–ç•¥å¯ä»¥è½»æ¾åˆ‡æ¢é£é™©æ¨¡å‹
    - é€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶
    """
    if estimator_type == 'simple':
        return SimpleCovarianceEstimator()
    elif estimator_type == 'ledoit_wolf':
        return LedoitWolfCovarianceEstimator()
    elif estimator_type == 'factor_model':
        return FactorModelCovarianceEstimator(self.factor_data_provider)
    else:
        raise ValueError(f"Unknown estimator type: {estimator_type}")
```

---

## ğŸ”§ **æ”¹è¿›æ–¹æ¡ˆä¸‰ï¼šå¤šæŒ‡æ ‡ä¿¡å·è´¨é‡è¯„ä¼°**

### **é—®é¢˜è¯Šæ–­**
å½“å‰ç¼ºå°‘ç³»ç»ŸåŒ–çš„ä¿¡å·è´¨é‡è¯„ä¼°ï¼Œæ— æ³•çŸ¥é“ï¼š
- Alphaä¿¡å·çš„é¢„æµ‹èƒ½åŠ›å¦‚ä½•ï¼ˆICï¼‰
- ä¿¡å·æ˜¯å¦ç¨³å®šï¼ˆICIRï¼‰
- æ˜¯å¦è¿‡æ‹Ÿåˆ

### **æ”¹è¿›ç›®æ ‡**
å»ºç«‹å®Œæ•´çš„è¯„ä¼°æ¡†æ¶ï¼Œæ¯æ¬¡å›æµ‹è‡ªåŠ¨è¾“å‡ºè¯Šæ–­æŠ¥å‘Š

### **å…·ä½“æ”¹åŠ¨**

#### **æ–°å¢æ–‡ä»¶**: `utils/signal_evaluator.py` (Layer 1)

```python
class SignalQualityEvaluator:
    """
    ä¿¡å·è´¨é‡è¯„ä¼°å™¨
    
    èŒè´£ï¼š
    - è®¡ç®—ICã€Rank ICã€ICIRç­‰æŒ‡æ ‡
    - ç”Ÿæˆä¿¡å·è´¨é‡æŠ¥å‘Š
    - ç”¨äºæ¨¡å‹é€‰æ‹©å’Œå‚æ•°è°ƒä¼˜
    
    ä¸ºä»€ä¹ˆç‹¬ç«‹ï¼š
    - è¯„ä¼°é€»è¾‘ä¸ç­–ç•¥æ‰§è¡Œè§£è€¦
    - å¯ä»¥åœ¨å›æµ‹å’Œå®ç›˜ä¸­å¤ç”¨
    """
    
    def evaluate(self, 
                 alpha_signals: pd.DataFrame,
                 realized_returns: pd.DataFrame,
                 horizon_days: int = 10) -> Dict:
        """
        è¾“å…¥ï¼š
        - alpha_signals: é¢„æµ‹çš„Alphaåˆ†æ•°ï¼ˆTÃ—NçŸ©é˜µï¼‰
        - realized_returns: å®é™…å®ç°çš„æ”¶ç›Šï¼ˆTÃ—NçŸ©é˜µï¼‰
        - horizon_days: é¢„æµ‹æ—¶é•¿
        
        è¾“å‡ºï¼šè¯„ä¼°æŒ‡æ ‡å­—å…¸
        
        è®¡ç®—é€»è¾‘ï¼š
        å¯¹äºæ¯ä¸ªæ—¶é—´ç‚¹tï¼š
          IC_t = corr(alpha_signals[t], realized_returns[t+horizon])
        
        ç„¶åï¼š
          mean_IC = mean(IC_t)
          ICIR = mean_IC / std(IC_t)
        """
        metrics = {}
        
        # 1. ICï¼ˆPearsonç›¸å…³ï¼‰
        ic_series = self._calculate_ic_series(alpha_signals, realized_returns, horizon_days)
        metrics['ic_mean'] = ic_series.mean()
        metrics['ic_std'] = ic_series.std()
        metrics['icir'] = metrics['ic_mean'] / metrics['ic_std'] if metrics['ic_std'] > 0 else 0
        
        # 2. Rank ICï¼ˆSpearmanç›¸å…³ï¼‰
        rank_ic_series = self._calculate_rank_ic_series(alpha_signals, realized_returns, horizon_days)
        metrics['rank_ic_mean'] = rank_ic_series.mean()
        metrics['rank_ic_std'] = rank_ic_series.std()
        metrics['rank_icir'] = metrics['rank_ic_mean'] / metrics['rank_ic_std']
        
        # 3. Hit Rateï¼ˆæ–¹å‘å‡†ç¡®ç‡ï¼‰
        metrics['hit_rate'] = self._calculate_hit_rate(alpha_signals, realized_returns, horizon_days)
        
        # 4. åˆ†ä½æ•°åˆ†æï¼ˆTop vs Bottomï¼‰
        metrics['quintile_spread'] = self._calculate_quintile_spread(
            alpha_signals, realized_returns, horizon_days
        )
        
        # 5. æ—¶é—´ç¨³å®šæ€§
        metrics['ic_stability'] = self._calculate_stability(ic_series)
        
        # 6. é€‚ç”¨æ¨¡å‹ç±»å‹å»ºè®®
        metrics['suggested_model_type'] = self._suggest_model_type(metrics)
        
        return metrics
    
    def _calculate_ic_series(self, signals, returns, horizon):
        """
        é€æœŸè®¡ç®—IC
        
        ä¸ºä»€ä¹ˆï¼š
        - ICçš„æ—¶é—´åºåˆ—åæ˜ ä¿¡å·çš„ç¨³å®šæ€§
        - å¯ä»¥è¯†åˆ«ä¿¡å·åœ¨å“ªäº›æ—¶æœŸå¤±æ•ˆ
        """
        ic_list = []
        for t in range(len(signals) - horizon):
            signal_t = signals.iloc[t]
            return_t = returns.iloc[t + horizon]
            ic_t = signal_t.corr(return_t, method='pearson')
            ic_list.append(ic_t)
        return pd.Series(ic_list)
    
    def _suggest_model_type(self, metrics):
        """
        æ ¹æ®ICå’ŒRank ICçš„å·®å¼‚å»ºè®®æ¨¡å‹ç±»å‹
        
        é€»è¾‘ï¼š
        - å¦‚æœIC >> Rank ICï¼šçº¿æ€§å…³ç³»å¼º â†’ ç”¨çº¿æ€§æ¨¡å‹
        - å¦‚æœRank IC >> ICï¼šéçº¿æ€§å…³ç³» â†’ ç”¨æ ‘æ¨¡å‹/ç¥ç»ç½‘ç»œ
        - å¦‚æœä¸¤è€…éƒ½ä½ï¼šä¿¡å·è´¨é‡å·®ï¼Œéœ€è¦é‡æ–°è®¾è®¡ç‰¹å¾
        """
        ic_rank_ic_ratio = metrics['ic_mean'] / (metrics['rank_ic_mean'] + 1e-6)
        
        if ic_rank_ic_ratio > 1.2:
            return "linear_model_preferred"  # çº¿æ€§å›å½’ã€Fama-French
        elif ic_rank_ic_ratio < 0.8:
            return "nonlinear_model_preferred"  # XGBoostã€LSTM
        else:
            return "either_works"
```

#### **ä¿®æ”¹ä½ç½®**: `strategies/base_strategy.py`

**åœ¨signalç”Ÿæˆåè°ƒç”¨è¯„ä¼°**ï¼š

```python
def generate_signals(self, price_data, date):
    # ... ç”Ÿæˆä¿¡å·çš„ä»£ç  ...
    
    # æ–°å¢ï¼šè¯„ä¼°ä¿¡å·è´¨é‡ï¼ˆå¦‚æœæœ‰å†å²æ•°æ®ï¼‰
    if self.enable_diagnostics and self._has_historical_returns():
        evaluator = SignalQualityEvaluator()
        quality_metrics = evaluator.evaluate(
            alpha_signals=alpha_scores,
            realized_returns=self._get_realized_returns(horizon_days=10),
            horizon_days=10
        )
        
        # è®°å½•åˆ°æ—¥å¿—æˆ–WandB
        logger.info(f"Signal Quality: IC={quality_metrics['ic_mean']:.4f}, "
                   f"ICIR={quality_metrics['icir']:.4f}")
        
        # å¦‚æœè´¨é‡å¤ªä½ï¼Œå‘å‡ºè­¦å‘Š
        if quality_metrics['ic_mean'] < 0.01:
            logger.warning("âš ï¸ Signal quality very low! Consider retraining.")
        
        # ä¿å­˜åˆ°metadataä¸­
        result['signal_quality'] = quality_metrics
    
    return result
```

---

## ğŸ”§ **æ”¹è¿›æ–¹æ¡ˆå››ï¼šå¤šæ—¶é—´çª—å£çš„åŠ¨æ€è°ƒä»“**

### **é—®é¢˜è¯Šæ–­**
å½“å‰ä»£ç å‡è®¾å›ºå®šæŒä»“æœŸï¼ˆå¦‚2å‘¨ï¼‰ï¼Œä½†ï¼š
- çŸ­æœŸä¿¡å·è¡°å‡å¿«ï¼Œåº”è¯¥æ—©å–
- é•¿æœŸä¿¡å·ç¨³å®šï¼Œå¯ä»¥ä¹…æŒ
- æ²¡æœ‰æ ¹æ®ä¿¡å·å¼ºåº¦åŠ¨æ€è°ƒæ•´

### **æ”¹è¿›ç›®æ ‡**
å®ç°å¤šè§†é‡ä¿¡å·æ··åˆ + åŠ¨æ€è°ƒä»“é€»è¾‘

### **å…·ä½“æ”¹åŠ¨**

#### **æ–°å¢æ–‡ä»¶**: `strategies/multi_horizon_strategy.py` (Layer 4)

```python
class MultiHorizonStrategy(BaseStrategy):
    """
    å¤šæ—¶é—´çª—å£ç­–ç•¥
    
    èŒè´£ï¼š
    - åŒæ—¶é¢„æµ‹1å¤©ã€5å¤©ã€10å¤©ã€20å¤©çš„æ”¶ç›Š
    - æ ¹æ®è¡°å‡é€Ÿåº¦åŠ¨æ€åŠ æƒ
    - æ¯å¤©é‡æ–°è¯„ä¼°ï¼Œå†³å®šæ˜¯å¦è°ƒä»“
    
    ä¸ºä»€ä¹ˆï¼š
    - æ•æ‰ä¸åŒé¢‘ç‡çš„Alpha
    - å¹³è¡¡çŸ­æœŸæœºä¼šå’Œé•¿æœŸç¨³å®šæ€§
    """
    
    def __init__(self, ..., horizons=[1, 5, 10, 20], **kwargs):
        super().__init__(...)
        self.horizons = horizons  # é¢„æµ‹å¤šä¸ªæ—¶é—´çª—å£
        self.decay_rates = self._estimate_decay_rates()  # æ¯ä¸ªhorizonçš„è¡°å‡é€Ÿåº¦
    
    def generate_signals(self, price_data, date):
        """
        å¤šè§†é‡ä¿¡å·ç”Ÿæˆæµç¨‹
        """
        # æ­¥éª¤1: å¯¹æ¯ä¸ªæ—¶é—´çª—å£ç”Ÿæˆé¢„æµ‹
        horizon_predictions = {}
        for h in self.horizons:
            alpha_h = self.generate_raw_alpha_signals(
                price_data, date, horizon=h
            )
            horizon_predictions[h] = alpha_h
        
        # æ­¥éª¤2: æ ¹æ®è¡°å‡ç‡åŠ¨æ€åŠ æƒ
        weights = self._calculate_horizon_weights(date)
        
        # æ­¥éª¤3: åŠ æƒç»„åˆ
        combined_alpha = sum(
            horizon_predictions[h] * weights[h]
            for h in self.horizons
        )
        
        # æ­¥éª¤4: é£é™©è°ƒæ•´ï¼ˆåŒæ–¹æ¡ˆä¸€ï¼‰
        expected_returns = self.alpha_to_expected_returns(combined_alpha)
        cov_matrix = self.risk_estimator.estimate(price_data, date)
        final_weights = self.apply_risk_adjustment(expected_returns, cov_matrix)
        
        # æ­¥éª¤5: å†³å®šæ˜¯å¦è°ƒä»“
        rebalance_decision = self._should_rebalance(
            current_positions=self.current_holdings,
            target_positions=final_weights,
            transaction_cost=0.001  # 0.1%
        )
        
        if rebalance_decision['should_rebalance']:
            logger.info(f"ğŸ“Š Rebalancing triggered: {rebalance_decision['reason']}")
            return final_weights
        else:
            logger.info(f"â¸ï¸ Holding current positions")
            return self.current_holdings
    
    def _calculate_horizon_weights(self, date):
        """
        åŠ¨æ€è®¡ç®—å„æ—¶é—´çª—å£çš„æƒé‡
        
        æ–¹æ³•1: æŒ‡æ•°è¡°å‡ï¼ˆå›ºå®šï¼‰
        w_h = exp(-Î» Ã— h)
        
        æ–¹æ³•2: è‡ªé€‚åº”ï¼ˆåŸºäºæœ€è¿‘è¡¨ç°ï¼‰
        w_h âˆ IC_h(recent) / volatility_h(recent)
        
        ä¸ºä»€ä¹ˆåŠ¨æ€ï¼š
        - å¸‚åœºregimeå˜åŒ–æ—¶ï¼Œä¸åŒhorizonçš„æœ‰æ•ˆæ€§æ”¹å˜
        - ä¾‹å¦‚ï¼šè¶‹åŠ¿å¸‚åœº â†’ é•¿æœŸä¿¡å·æƒé‡â†‘
                éœ‡è¡å¸‚åœº â†’ çŸ­æœŸä¿¡å·æƒé‡â†‘
        """
        # æ–¹æ³•1: ç®€å•æŒ‡æ•°è¡°å‡
        decay_lambda = 0.1
        raw_weights = {h: np.exp(-decay_lambda * h) for h in self.horizons}
        
        # å½’ä¸€åŒ–
        total = sum(raw_weights.values())
        return {h: w / total for h, w in raw_weights.items()}
    
    def _should_rebalance(self, current_positions, target_positions, transaction_cost):
        """
        è°ƒä»“å†³ç­–é€»è¾‘
        
        è€ƒè™‘å› ç´ ï¼š
        1. ä»“ä½åç¦»åº¦ï¼š|current - target|
        2. äº¤æ˜“æˆæœ¬ï¼šturnover Ã— cost
        3. ä¿¡å·å¼ºåº¦å˜åŒ–ï¼šalpha_new - alpha_old
        
        å†³ç­–è§„åˆ™ï¼š
        åªæœ‰å½“ expected_gain > transaction_cost æ—¶æ‰è°ƒä»“
        
        ä¸ºä»€ä¹ˆï¼š
        - é¿å…è¿‡åº¦äº¤æ˜“ä¾µèš€æ”¶ç›Š
        - åŠ¨æ€å¹³è¡¡alphaæ•æ‰å’Œæˆæœ¬æ§åˆ¶
        """
        # è®¡ç®—åç¦»åº¦
        position_diff = target_positions - current_positions
        turnover = position_diff.abs().sum()
        
        # ä¼°è®¡è°ƒä»“æ”¶ç›Š
        expected_alpha_gain = self._estimate_alpha_gain(position_diff)
        
        # äº¤æ˜“æˆæœ¬
        cost = turnover * transaction_cost
        
        # å†³ç­–
        net_gain = expected_alpha_gain - cost
        
        if net_gain > 0.001:  # è‡³å°‘0.1%å‡€æ”¶ç›Šæ‰è°ƒä»“
            return {
                'should_rebalance': True,
                'reason': f'Net gain: {net_gain:.4f} (alpha: {expected_alpha_gain:.4f}, cost: {cost:.4f})'
            }
        else:
            return {
                'should_rebalance': False,
                'reason': f'Net gain too small: {net_gain:.4f}'
            }
```

---

## ğŸ”§ **æ”¹è¿›æ–¹æ¡ˆäº”ï¼šé…ç½®åŒ–çš„è¯„ä¼°æŒ‡æ ‡é€‰æ‹©**

### **é—®é¢˜è¯Šæ–­**
ç¡¬ç¼–ç çš„é˜ˆå€¼ï¼ˆå¦‚ `min_strength=0.1`ï¼‰ç¼ºä¹çµæ´»æ€§

### **æ”¹è¿›ç›®æ ‡**
é€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶è¯„ä¼°æŒ‡æ ‡å’Œé˜ˆå€¼

### **å…·ä½“æ”¹åŠ¨**

#### **ä¿®æ”¹ä½ç½®**: `configs/` ä¸‹çš„YAMLæ–‡ä»¶

**æ–°å¢é…ç½®å—**ï¼š

```yaml
# configs/strategy_config.yaml

strategy:
  name: "MyMLStrategy"
  
  # æ–°å¢ï¼šä¿¡å·è´¨é‡è¯„ä¼°é…ç½®
  signal_evaluation:
    enabled: true
    
    # ä½¿ç”¨å“ªäº›æŒ‡æ ‡
    metrics:
      - ic
      - rank_ic
      - sharpe
      - hit_rate
      - max_drawdown
    
    # å„æŒ‡æ ‡çš„é˜ˆå€¼
    thresholds:
      ic_min: 0.03          # IC < 0.03 â†’ è­¦å‘Š
      rank_ic_min: 0.05     # Rank IC < 0.05 â†’ è­¦å‘Š
      icir_min: 0.3         # ICIR < 0.3 â†’ ä¿¡å·ä¸ç¨³å®š
      sharpe_min: 1.0       # Sharpe < 1.0 â†’ ç­–ç•¥ä¸å¯è¡Œ
      hit_rate_min: 0.51    # Hit Rate < 51% â†’ æ— é¢„æµ‹èƒ½åŠ›
    
    # å»ºè®®æ¨¡å‹ç±»å‹çš„é€»è¾‘
    model_selection:
      prefer_linear_if_ic_rank_ic_ratio: 1.2
      prefer_nonlinear_if_ratio: 0.8
  
  # æ–°å¢ï¼šå¤šæ—¶é—´çª—å£é…ç½®
  multi_horizon:
    enabled: true
    horizons: [1, 5, 10, 20]  # å¤©æ•°
    decay_method: "exponential"  # "exponential" / "adaptive"
    decay_lambda: 0.1
  
  # æ–°å¢ï¼šé£é™©æ¨¡å‹é…ç½®
  risk_model:
    type: "ledoit_wolf"  # "simple" / "ledoit_wolf" / "factor_model"
    lookback_days: 252
    factor_model:  # ä»…å½“type="factor_model"æ—¶ç”Ÿæ•ˆ
      factors: ["MKT", "SMB", "HML", "RMW", "CMA"]
      factor_provider: "ff5_provider"
  
  # æ–°å¢ï¼šåŠ¨æ€è°ƒä»“é…ç½®
  rebalancing:
    method: "threshold_based"  # "threshold_based" / "scheduled" / "signal_driven"
    min_net_gain: 0.001  # 0.1% æœ€å°å‡€æ”¶ç›Šæ‰è°ƒä»“
    transaction_cost: 0.001  # 0.1% äº¤æ˜“æˆæœ¬
    max_turnover: 0.50  # æœ€å¤§50%æ¢æ‰‹ç‡
```

#### **ä¿®æ”¹ä½ç½®**: `strategies/base_strategy.py`

**åŠ è½½é…ç½®**ï¼š

```python
def __init__(self, config: Dict, ...):
    # åŠ è½½è¯„ä¼°é…ç½®
    self.eval_config = config.get('signal_evaluation', {})
    self.eval_enabled = self.eval_config.get('enabled', False)
    self.thresholds = self.eval_config.get('thresholds', {})
    
    # åŠ è½½å¤šæ—¶é—´çª—å£é…ç½®
    self.multi_horizon_config = config.get('multi_horizon', {})
    
    # åŠ è½½é£é™©æ¨¡å‹é…ç½®
    risk_config = config.get('risk_model', {})
    self.risk_estimator = self._create_risk_estimator(
        risk_config.get('type', 'simple'),
        risk_config
    )
```

---

## ğŸ“Š **æ”¹åŠ¨æ±‡æ€»è¡¨**

| æ”¹è¿›æ–¹æ¡ˆ | æ¶‰åŠå±‚æ¬¡ | æ–°å¢/ä¿®æ”¹æ–‡ä»¶ | æ ¸å¿ƒèŒè´£ |
|---------|---------|-------------|---------|
| **1. ä¿¡å·ä¸é£é™©åˆ†ç¦»** | Layer 4 (ç­–ç•¥å±‚) | `strategies/base_strategy.py` | åˆ†è§£`generate_signals`ä¸º4ä¸ªå­æ–¹æ³• |
| **2. åæ–¹å·®ä¼°è®¡** | Layer 1 (åŸºç¡€å±‚) | `utils/risk.py` (æ–°å¢3ä¸ªç±») | æä¾›å¤šç§é£é™©ä¼°è®¡æ–¹æ³• |
| **3. ä¿¡å·è´¨é‡è¯„ä¼°** | Layer 1 (åŸºç¡€å±‚) | `utils/signal_evaluator.py` (æ–°å¢) | è®¡ç®—IC/Rank IC/ICIRç­‰æŒ‡æ ‡ |
| **4. å¤šæ—¶é—´çª—å£** | Layer 4 (ç­–ç•¥å±‚) | `strategies/multi_horizon_strategy.py` (æ–°å¢) | å¤šè§†é‡é¢„æµ‹ + åŠ¨æ€è°ƒä»“ |
| **5. é…ç½®åŒ–** | é…ç½®å±‚ | `configs/*.yaml` | é›†ä¸­ç®¡ç†æ‰€æœ‰é˜ˆå€¼å’Œå‚æ•° |

---

## ğŸš€ **å®æ–½é¡ºåºå»ºè®®**
## ğŸš€ **å®æ–½é¡ºåºå»ºè®®**ï¼ˆç»­ï¼‰

### **Phase 1: åŸºç¡€é‡æ„ï¼ˆ1-2å¤©ï¼‰**

**ç›®æ ‡**: å»ºç«‹æ–°çš„åŸºç¡€è®¾æ–½ï¼Œä¸ç ´åç°æœ‰åŠŸèƒ½

#### æ­¥éª¤1.1: åˆ›å»ºåæ–¹å·®ä¼°è®¡å™¨
```bash
# åœ¨ utils/risk.py ä¸­å®ç°
- SimpleCovarianceEstimator (50è¡Œä»£ç )
- LedoitWolfCovarianceEstimator (80è¡Œä»£ç )
```

**éªŒè¯æ–¹æ³•**: 
```python
# å†™å•å…ƒæµ‹è¯•
def test_covariance_estimators():
    # ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•
    # ç¡®ä¿è¾“å‡ºçŸ©é˜µæ˜¯å¯¹ç§°æ­£å®šçš„
    assert np.allclose(cov, cov.T)  # å¯¹ç§°æ€§
    assert np.all(np.linalg.eigvals(cov) > 0)  # æ­£å®šæ€§
```

#### æ­¥éª¤1.2: åˆ›å»ºä¿¡å·è¯„ä¼°å™¨
```bash
# åœ¨ utils/signal_evaluator.py ä¸­å®ç°
- SignalQualityEvaluatorç±» (150è¡Œä»£ç )
```

**éªŒè¯æ–¹æ³•**: 
ç”¨å†å²å›æµ‹æ•°æ®æµ‹è¯•ICè®¡ç®—æ˜¯å¦æ­£ç¡®

---

### **Phase 2: ç­–ç•¥å±‚é‡æ„ï¼ˆ2-3å¤©ï¼‰**

**ç›®æ ‡**: åˆ†ç¦»ä¿¡å·ç”Ÿæˆä¸é£é™©ç®¡ç†

#### æ­¥éª¤2.1: ä¿®æ”¹BaseStrategy
```python
# åœ¨ strategies/base_strategy.py ä¸­
# ä¸è¦åˆ é™¤ç°æœ‰çš„generate_signalsï¼Œè€Œæ˜¯ï¼š
# 1. é‡å‘½åä¸º generate_signals_legacy
# 2. æ–°å¢4ä¸ªæ–¹æ³•ï¼ˆå¦‚æ–¹æ¡ˆä¸€æ‰€ç¤ºï¼‰
# 3. æ–°çš„generate_signalsè°ƒç”¨è¿™4ä¸ªæ–¹æ³•
```

**ä¸ºä»€ä¹ˆè¿™æ ·åš**:
- ä¿ç•™æ—§ä»£ç ä½œä¸ºfallback
- é€æ­¥è¿ç§»ï¼Œé™ä½é£é™©
- å¯ä»¥A/Bæµ‹è¯•æ–°æ—§æ–¹æ³•

#### æ­¥éª¤2.2: é…ç½®æ–‡ä»¶æ›´æ–°
```yaml
# åœ¨æ‰€æœ‰ configs/*.yaml ä¸­æ·»åŠ 
signal_evaluation:
  enabled: true  # å¼€å§‹æ—¶è®¾ä¸ºfalseï¼Œæµ‹è¯•é€šè¿‡åæ”¹true
  
risk_model:
  type: "simple"  # å…ˆç”¨simpleï¼Œç¨³å®šåå‡çº§åˆ°ledoit_wolf
```

**éªŒè¯æ–¹æ³•**:
```python
# è¿è¡Œç°æœ‰å›æµ‹ï¼Œå¯¹æ¯”ç»“æœ
old_signals = strategy.generate_signals_legacy(...)
new_signals = strategy.generate_signals(...)

# ç»“æœåº”è¯¥æ¥è¿‘ï¼ˆé£é™©æ¨¡å‹æ”¹è¿›åä¼šæœ‰å·®å¼‚ï¼Œä½†ä¸åº”è¯¥å·¨å¤§ï¼‰
assert np.corrcoef(old_signals, new_signals)[0,1] > 0.8
```

---

### **Phase 3: é«˜çº§åŠŸèƒ½ï¼ˆ3-5å¤©ï¼‰**

#### æ­¥éª¤3.1: å®ç°å¤šæ—¶é—´çª—å£ç­–ç•¥
```python
# åˆ›å»ºæ–°æ–‡ä»¶ strategies/multi_horizon_strategy.py
# ç»§æ‰¿è‡ªæ”¹é€ åçš„BaseStrategy
```

**é€æ­¥æµ‹è¯•**:
1. å…ˆç”¨å•horizonæµ‹è¯•ï¼ˆåº”è¯¥ç­‰åŒäºBaseStrategyï¼‰
2. å†åŠ å…¥å¤šhorizon
3. å¯¹æ¯”å•horizon vs å¤šhorizonçš„è¡¨ç°

#### æ­¥éª¤3.2: å› å­æ¨¡å‹åæ–¹å·®ï¼ˆå¯é€‰ï¼‰
```python
# å¦‚æœç®€å•æ–¹æ³•æ•ˆæœå¥½ï¼Œå¯è·³è¿‡
# å¦‚æœéœ€è¦ï¼Œå®ç°FactorModelCovarianceEstimator
```

---

### **Phase 4: é›†æˆæµ‹è¯•ï¼ˆ1-2å¤©ï¼‰**

#### å®Œæ•´å›æµ‹æµç¨‹
```python
# ç”¨æ–°æ¶æ„è·‘å®Œæ•´çš„å†å²å›æµ‹
# ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šï¼š
# - æ—§æ¶æ„ vs æ–°æ¶æ„
# - ä¸åŒé£é™©æ¨¡å‹çš„å¯¹æ¯”
# - ä¸åŒæ—¶é—´çª—å£çš„å¯¹æ¯”
```

---

## ğŸ“ **ä»£ç æ¨¡æ¿ç¤ºä¾‹**

### **ç¤ºä¾‹1: åœ¨BaseStrategyä¸­é›†æˆè¯„ä¼°å™¨**

```python
class BaseStrategy(ABC):
    
    def __init__(self, config, ...):
        # ... ç°æœ‰ä»£ç  ...
        
        # æ–°å¢ç»„ä»¶åˆå§‹åŒ–
        self._init_risk_estimator(config.get('risk_model', {}))
        self._init_signal_evaluator(config.get('signal_evaluation', {}))
        
    def _init_risk_estimator(self, risk_config):
        """åˆå§‹åŒ–é£é™©ä¼°è®¡å™¨"""
        estimator_type = risk_config.get('type', 'simple')
        
        if estimator_type == 'simple':
            self.risk_estimator = SimpleCovarianceEstimator(
                lookback_days=risk_config.get('lookback_days', 252)
            )
        elif estimator_type == 'ledoit_wolf':
            self.risk_estimator = LedoitWolfCovarianceEstimator(
                lookback_days=risk_config.get('lookback_days', 252)
            )
        else:
            raise ValueError(f"Unknown risk estimator: {estimator_type}")
        
        logger.info(f"Initialized risk estimator: {estimator_type}")
    
    def _init_signal_evaluator(self, eval_config):
        """åˆå§‹åŒ–ä¿¡å·è¯„ä¼°å™¨"""
        self.eval_enabled = eval_config.get('enabled', False)
        if self.eval_enabled:
            self.signal_evaluator = SignalQualityEvaluator()
            self.eval_thresholds = eval_config.get('thresholds', {})
            logger.info("Signal evaluation enabled")
```

---

### **ç¤ºä¾‹2: ç”Ÿæˆä¿¡å·çš„æ–°æµç¨‹**

```python
def generate_signals(self, price_data: Dict, date: datetime) -> Dict:
    """
    ç»Ÿä¸€çš„ä¿¡å·ç”Ÿæˆæµç¨‹
    
    è¿”å›æ ¼å¼ï¼š
    {
        'weights': DataFrame,  # æœ€ç»ˆæ‰§è¡Œæƒé‡
        'alpha_scores': DataFrame,  # åŸå§‹Alphaåˆ†æ•°
        'diagnostics': {  # è¯Šæ–­ä¿¡æ¯
            'ic': float,
            'rank_ic': float,
            'n_positions': int,
            ...
        }
    }
    """
    try:
        # === ç¬¬ä¸€æ­¥ï¼šç”ŸæˆåŸå§‹Alphaä¿¡å· ===
        logger.debug("Step 1: Generating raw alpha signals")
        alpha_scores = self.generate_raw_alpha_signals(price_data, date)
        
        if alpha_scores.empty:
            logger.warning("No alpha signals generated")
            return self._empty_result()
        
        # === ç¬¬äºŒæ­¥ï¼šè½¬æ¢ä¸ºé¢„æœŸæ”¶ç›Šç‡ ===
        logger.debug("Step 2: Converting to expected returns")
        expected_returns = self.alpha_to_expected_returns(
            alpha_scores,
            scaling_factor=self.parameters.get('alpha_scaling', 0.02)
        )
        
        # === ç¬¬ä¸‰æ­¥ï¼šä¼°è®¡é£é™©ï¼ˆåæ–¹å·®çŸ©é˜µï¼‰===
        logger.debug("Step 3: Estimating covariance matrix")
        cov_matrix = self.risk_estimator.estimate(price_data, date)
        
        # === ç¬¬å››æ­¥ï¼šé£é™©è°ƒæ•´ ===
        logger.debug("Step 4: Applying risk adjustment")
        risk_adjusted_weights = self.apply_risk_adjustment(
            expected_returns,
            cov_matrix,
            method=self.parameters.get('position_sizing_method', 'kelly')
        )
        
        # === ç¬¬äº”æ­¥ï¼šåº”ç”¨çº¦æŸ ===
        logger.debug("Step 5: Applying constraints")
        final_weights = self._apply_constraints(
            risk_adjusted_weights,
            max_position=self.parameters.get('max_position_weight', 0.05),
            max_turnover=self.parameters.get('max_turnover', 0.50)
        )
        
        # === ç¬¬å…­æ­¥ï¼šè¯„ä¼°ä¿¡å·è´¨é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰===
        diagnostics = {}
        if self.eval_enabled:
            logger.debug("Step 6: Evaluating signal quality")
            diagnostics = self._evaluate_signal_quality(
                alpha_scores, 
                price_data, 
                date
            )
            
            # æ£€æŸ¥é˜ˆå€¼
            self._check_quality_thresholds(diagnostics)
        
        # === æ„å»ºè¿”å›ç»“æœ ===
        return {
            'weights': final_weights,
            'alpha_scores': alpha_scores,
            'expected_returns': expected_returns,
            'risk_adjusted_weights': risk_adjusted_weights,
            'cov_matrix': cov_matrix,
            'diagnostics': diagnostics,
            'metadata': {
                'date': date,
                'n_positions': (final_weights != 0).sum(),
                'total_exposure': final_weights.sum(),
                'timestamp': datetime.now()
            }
        }
        
    except Exception as e:
        logger.error(f"Signal generation failed: {e}", exc_info=True)
        return self._empty_result()


def _evaluate_signal_quality(self, alpha_scores, price_data, date):
    """è¯„ä¼°ä¿¡å·è´¨é‡å¹¶è®°å½•"""
    # è·å–æœªæ¥å®ç°çš„æ”¶ç›Šï¼ˆç”¨äºICè®¡ç®—ï¼‰
    future_returns = self._get_future_returns(
        price_data, 
        date, 
        horizon_days=10
    )
    
    if future_returns is not None:
        metrics = self.signal_evaluator.evaluate(
            alpha_signals=alpha_scores,
            realized_returns=future_returns,
            horizon_days=10
        )
        
        logger.info(
            f"Signal Quality - IC: {metrics['ic_mean']:.4f}, "
            f"Rank IC: {metrics['rank_ic_mean']:.4f}, "
            f"ICIR: {metrics['icir']:.4f}"
        )
        
        return metrics
    
    return {}


def _check_quality_thresholds(self, diagnostics):
    """æ£€æŸ¥ä¿¡å·è´¨é‡æ˜¯å¦è¾¾æ ‡"""
    ic = diagnostics.get('ic_mean', 0)
    ic_threshold = self.eval_thresholds.get('ic_min', 0.01)
    
    if ic < ic_threshold:
        logger.warning(
            f"âš ï¸ Signal quality below threshold! "
            f"IC={ic:.4f} < {ic_threshold:.4f}"
        )
        
        # å¯é€‰ï¼šè‡ªåŠ¨åˆ‡æ¢åˆ°ä¿å®ˆæ¨¡å¼
        if self.parameters.get('auto_adjust_on_low_quality', False):
            logger.info("Switching to conservative mode")
            self.position_sizer.set_conservative_mode(True)
```

---

### **ç¤ºä¾‹3: åæ–¹å·®ä¼°è®¡å™¨çš„ä½¿ç”¨**

```python
# åœ¨å›æµ‹æˆ–å®ç›˜ä¸­ä½¿ç”¨

# æ–¹å¼1: é€šè¿‡é…ç½®è‡ªåŠ¨é€‰æ‹©
strategy = MLStrategy(
    config={
        'risk_model': {
            'type': 'ledoit_wolf',  # è‡ªåŠ¨ä½¿ç”¨Ledoit-Wolf
            'lookback_days': 252
        }
    }
)

# æ–¹å¼2: æ˜¾å¼åˆ›å»ºå¹¶ä¼ å…¥
from utils.risk import LedoitWolfCovarianceEstimator

risk_estimator = LedoitWolfCovarianceEstimator(lookback_days=252)
strategy = MLStrategy(
    ...,
    risk_estimator=risk_estimator  # ç›´æ¥æ³¨å…¥
)

# ä½¿ç”¨æ—¶å®Œå…¨é€æ˜
signals = strategy.generate_signals(price_data, date)
# å†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨æ­£ç¡®çš„åæ–¹å·®ä¼°è®¡æ–¹æ³•
```

---

## ğŸ¯ **å…³é”®è®¾è®¡åŸåˆ™æ€»ç»“**

### **1. èŒè´£åˆ†ç¦»**
- **ç­–ç•¥å±‚** (`strategies/`): ç¼–æ’æµç¨‹ï¼Œä¸åšå…·ä½“è®¡ç®—
- **æ¨¡å‹å±‚** (`models/`): åªè´Ÿè´£é¢„æµ‹ï¼Œä¸ç®¡ä»“ä½
- **åŸºç¡€å±‚** (`utils/`): æä¾›å·¥å…·ï¼ˆé£é™©ä¼°è®¡ã€è¯„ä¼°ç­‰ï¼‰

### **2. ä¾èµ–æ³¨å…¥**
```python
# ä¸è¦åœ¨ç­–ç•¥å†…éƒ¨ç¡¬ç¼–ç åˆ›å»ºå¯¹è±¡
# âŒ é”™è¯¯
class MyStrategy:
    def __init__(self):
        self.risk_estimator = SimpleCovarianceEstimator()  # ç¡¬ç¼–ç 

# âœ… æ­£ç¡®
class MyStrategy:
    def __init__(self, risk_estimator):
        self.risk_estimator = risk_estimator  # æ³¨å…¥
```

### **3. é…ç½®é©±åŠ¨**
- æ‰€æœ‰é˜ˆå€¼ã€å‚æ•°éƒ½æ”¾åœ¨YAMLé…ç½®æ–‡ä»¶
- ä»£ç ä¸­é€šè¿‡ `config.get('key', default)` è¯»å–
- ä¾¿äºå®éªŒå’Œå‚æ•°è°ƒä¼˜

### **4. å¯è§‚æµ‹æ€§**
- æ¯ä¸ªå…³é”®æ­¥éª¤éƒ½è®°å½•æ—¥å¿—
- è¿”å›å®Œæ•´çš„è¯Šæ–­ä¿¡æ¯
- ä¾¿äºdebuggingå’Œæ€§èƒ½åˆ†æ

---

## ğŸ” **éªŒè¯æ¸…å•**

å®Œæˆæ¯ä¸ªPhaseåï¼Œæ£€æŸ¥ï¼š

- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] èƒ½å¤Ÿè¿è¡Œå®Œæ•´çš„å†å²å›æµ‹
- [ ] æ€§èƒ½æ²¡æœ‰æ˜¾è‘—ä¸‹é™ï¼ˆ<10%å»¶è¿Ÿå¢åŠ ï¼‰
- [ ] æ–°æŒ‡æ ‡ï¼ˆICã€Rank ICç­‰ï¼‰è¾“å‡ºæ­£ç¡®
- [ ] é…ç½®æ–‡ä»¶èƒ½å¤Ÿæ§åˆ¶æ‰€æœ‰å‚æ•°
- [ ] æ—¥å¿—è¾“å‡ºæ¸…æ™°ã€æœ‰ç”¨
- [ ] ä»£ç æœ‰é€‚å½“çš„æ³¨é‡Šå’Œdocstring
- [ ] ä¸ç°æœ‰ä»£ç å…¼å®¹ï¼ˆå¯ä»¥A/Bæµ‹è¯•ï¼‰

---

## ğŸ“š **ç›¸å…³æ–‡æ¡£æ›´æ–°**

éœ€è¦åŒæ­¥æ›´æ–°çš„æ–‡æ¡£ï¼š

1. **README.md**: æ·»åŠ æ–°åŠŸèƒ½è¯´æ˜
2. **APIæ–‡æ¡£**: æ›´æ–°ç­–ç•¥ç±»çš„æ¥å£
3. **é…ç½®æŒ‡å—**: è¯´æ˜æ–°çš„é…ç½®é€‰é¡¹
4. **æœ€ä½³å®è·µ**: ä½•æ—¶ç”¨IC vs Rank ICï¼Œä½•æ—¶ç”¨å“ªç§é£é™©æ¨¡å‹

---

è¿™ä¸ªæ–¹æ¡ˆçš„ä¼˜åŠ¿ï¼š
- **æ¸è¿›å¼**: ä¸éœ€è¦ä¸€æ¬¡æ€§é‡å†™æ‰€æœ‰ä»£ç 
- **å¯æµ‹è¯•**: æ¯ä¸ªç»„ä»¶éƒ½å¯ä»¥ç‹¬ç«‹æµ‹è¯•
- **å¯å›æ»š**: ä¿ç•™æ—§ä»£ç ï¼Œå‡ºé—®é¢˜å¯ä»¥å¿«é€Ÿæ¢å¤
- **å¯æ‰©å±•**: æœªæ¥æ·»åŠ æ–°åŠŸèƒ½åªéœ€å®ç°æ–°çš„Estimatorç±»

éœ€è¦æˆ‘è¯¦ç»†è§£é‡ŠæŸä¸ªå…·ä½“éƒ¨åˆ†å—ï¼Ÿ

---

## ğŸ“‹ **å½“å‰å®ç°çŠ¶æ€åˆ†æ**

### **æ”¹è¿›æ–¹æ¡ˆä¸€ï¼šåˆ†ç¦»ä¿¡å·ç”Ÿæˆä¸é£é™©ç®¡ç†**

#### âœ… **å·²å®ç°éƒ¨åˆ†**
- **ä¿¡å·ç”Ÿæˆæµç¨‹åˆ†ç¦»**: `base_strategy.py:211-295` ä¸­çš„ `generate_signals_single_date` æ–¹æ³•å·²ç»å®ç°äº†5æ­¥æ ‡å‡†åŒ–æµç¨‹ï¼š
  1. ç”ŸæˆåŸå§‹Alphaä¿¡å· (`generate_raw_alpha_signals`)
  2. è½¬æ¢ä¸ºé¢„æœŸæ”¶ç›Šç‡ (`alpha_to_expected_returns`)
  3. ä¼°è®¡åæ–¹å·®çŸ©é˜µ (`risk_estimator.estimate`)
  4. åº”ç”¨é£é™©è°ƒæ•´ (`apply_risk_adjustment`)
  5. åº”ç”¨çº¦æŸæ¡ä»¶ (`_apply_constraints`)

- **Alphaä¿¡å·æ ‡å‡†åŒ–**: `base_strategy.py:297-350` å®ç°äº†z-scoreæ ‡å‡†åŒ–å’Œç¼©æ”¾æ˜ å°„

#### âŒ **ç¼ºå¤±éƒ¨åˆ†**
- **é£é™©è¯„ä¼°æ¨¡å—ç‹¬ç«‹åŒ–**: è™½ç„¶æµç¨‹å·²åˆ†ç¦»ï¼Œä½†ç¼ºå°‘ç‹¬ç«‹çš„é£é™©è¯„ä¼°ç±»
- **Kellyå…¬å¼å®ç°**: æ–‡æ¡£ä¸­æåˆ°çš„fractional Kellyæƒé‡è®¡ç®—å°šæœªå®ç°
- **é£é™©é¢„ç®—çº¦æŸ**: ç¼ºå°‘è¡Œä¸šé™åˆ¶ã€æœ€å¤§ä»“ä½ç­‰çº¦æŸæ¡ä»¶çš„å…·ä½“å®ç°

#### ğŸ“Š **å®ç°ç¨‹åº¦**: ~70%

---

### **æ”¹è¿›æ–¹æ¡ˆäºŒï¼šå¢å¼ºé£é™©æ¨¡å‹ï¼ˆåæ–¹å·®ä¼°è®¡ï¼‰**

#### âœ… **å·²å®ç°éƒ¨åˆ†**
- **æŠ½è±¡åŸºç±»**: `utils/risk.py:547-581` å®ç°äº† `CovarianceEstimator` æ¥å£
- **ç®€å•åæ–¹å·®ä¼°è®¡**: `utils/risk.py:583-600` å®ç°äº† `SimpleCovarianceEstimator`
- **Ledoit-Wolfæ”¶ç¼©**: `utils/risk.py:603-626` å®ç°äº† `LedoitWolfCovarianceEstimator`
- **ç­–ç•¥é›†æˆ**: `base_strategy.py:36` å¯¼å…¥å¹¶åœ¨åˆå§‹åŒ–ä¸­ä½¿ç”¨é£é™©ä¼°è®¡å™¨

#### âŒ **ç¼ºå¤±éƒ¨åˆ†**
- **å› å­æ¨¡å‹åæ–¹å·®**: æ–‡æ¡£ä¸­æåˆ°çš„ `FactorModelCovarianceEstimator` å°šæœªå®ç°
- **DCC-NLåŠ¨æ€åæ–¹å·®**: é«˜çº§æ—¶å˜åæ–¹å·®æ¨¡å‹æœªå®ç°
- **åæ–¹å·®çŸ©é˜µè¯Šæ–­**: ç¼ºå°‘çŸ©é˜µè´¨é‡æ£€æŸ¥å’Œç—…æ€æ¡ä»¶å¤„ç†

#### ğŸ“Š **å®ç°ç¨‹åº¦**: ~65%

---

### **æ”¹è¿›æ–¹æ¡ˆä¸‰ï¼šå¤šæŒ‡æ ‡ä¿¡å·è´¨é‡è¯„ä¼°**

#### âœ… **å·²å®ç°éƒ¨åˆ†**
- **åŸºç¡€ICè®¡ç®—**: `models/utils/performance_evaluator.py:175-180` å®ç°äº†ä¿¡æ¯ç³»æ•°è®¡ç®—
- **Rank IC**: `models/utils/performance_evaluator.py:182-184` å®ç°äº†ç§©ç›¸å…³ç³»æ•°
- **æ–¹å‘å‡†ç¡®ç‡**: `models/utils/performance_evaluator.py:186-192` å®ç°äº†é¢„æµ‹æ–¹å‘å‡†ç¡®ç‡
- **é‡‘èæŒ‡æ ‡é›†æˆ**: åœ¨æ¨¡å‹è¯„ä¼°ä¸­åŒ…å«äº†ICç­‰é‡‘èæŒ‡æ ‡

#### âŒ **ç¼ºå¤±éƒ¨åˆ†**
- **ç‹¬ç«‹ä¿¡å·è¯„ä¼°å™¨**: ç¼ºå°‘æ–‡æ¡£ä¸­æè¿°çš„ `SignalQualityEvaluator` ç±»
- **ICIRè®¡ç®—**: ç¼ºå°‘ä¿¡æ¯æ¯”ç‡ï¼ˆIC/ICæ ‡å‡†å·®ï¼‰è®¡ç®—
- **åˆ†ä½æ•°åˆ†æ**: ç¼ºå°‘Top vs Bottomåˆ†ä½æ•°æ”¶ç›Šå·®åˆ†æ
- **æ—¶é—´ç¨³å®šæ€§**: ç¼ºå°‘ICæ—¶é—´åºåˆ—ç¨³å®šæ€§è¯„ä¼°
- **æ¨¡å‹ç±»å‹å»ºè®®**: ç¼ºå°‘åŸºäºIC vs Rank ICå·®å¼‚çš„æ¨¡å‹é€‰æ‹©é€»è¾‘

#### ğŸ“Š **å®ç°ç¨‹åº¦**: ~40%

---

### **æ”¹è¿›æ–¹æ¡ˆå››ï¼šå¤šæ—¶é—´çª—å£çš„åŠ¨æ€è°ƒä»“**

#### âŒ **å®Œå…¨ç¼ºå¤±**
- **å¤šè§†é‡ç­–ç•¥**: æ²¡æœ‰å®ç° `MultiHorizonStrategy` ç±»
- **åŠ¨æ€æƒé‡åˆ†é…**: ç¼ºå°‘åŸºäºä¿¡å·è¡°å‡çš„å¤šæ—¶é—´çª—å£æƒé‡è®¡ç®—
- **è°ƒä»“å†³ç­–é€»è¾‘**: ç¼ºå°‘åŸºäºæˆæœ¬æ”¶ç›Šåˆ†æçš„åŠ¨æ€è°ƒä»“å†³ç­–
- **ä¿¡å·è¡°å‡æ¨¡å‹**: ç¼ºå°‘æŒ‡æ•°è¡°å‡æˆ–è‡ªé€‚åº”è¡°å‡æ¨¡å‹

#### ğŸ“Š **å®ç°ç¨‹åº¦**: ~0%

---

### **æ”¹è¿›æ–¹æ¡ˆäº”ï¼šé…ç½®åŒ–çš„è¯„ä¼°æŒ‡æ ‡é€‰æ‹©**

#### âœ… **å·²å®ç°éƒ¨åˆ†**
- **åŸºç¡€é…ç½®ç»“æ„**: `configs/ml_strategy_config_new.yaml` åŒ…å«äº†ç­–ç•¥å’Œé£é™©æ¨¡å‹é…ç½®
- **æŠ•èµ„æ¡†æ¶é…ç½®**: é…ç½®æ–‡ä»¶åŒ…å«äº†boxåˆ†ç±»å’Œåˆ†é…é…ç½®
- **é£é™©æ¨¡å‹ç±»å‹**: å¯é€šè¿‡é…ç½®é€‰æ‹©simpleæˆ–ledoit_wolfé£é™©ä¼°è®¡å™¨

#### âŒ **ç¼ºå¤±éƒ¨åˆ†**
- **ä¿¡å·è¯„ä¼°é…ç½®**: ç¼ºå°‘æ–‡æ¡£ä¸­æè¿°çš„ `signal_evaluation` é…ç½®å—
- **å¤šæ—¶é—´çª—å£é…ç½®**: ç¼ºå°‘ `multi_horizon` é…ç½®é€‰é¡¹
- **åŠ¨æ€è°ƒä»“é…ç½®**: ç¼ºå°‘ `rebalancing` é…ç½®å‚æ•°
- **é˜ˆå€¼é…ç½®åŒ–**: ç¡¬ç¼–ç çš„é˜ˆå€¼ï¼ˆå¦‚min_signal_strengthï¼‰å°šæœªé…ç½®åŒ–

#### ğŸ“Š **å®ç°ç¨‹åº¦**: ~30%

---

## ğŸ” **å…³é”®å·®å¼‚åˆ†æ**

### **æ¶æ„è®¾è®¡å·®å¼‚**
1. **æ–‡æ¡£è®¾è®¡**: å¼ºè°ƒå®Œå…¨çš„ç»„ä»¶è§£è€¦å’Œä¾èµ–æ³¨å…¥
2. **å½“å‰å®ç°**: éƒ¨åˆ†å®ç°äº†ç»„ä»¶åˆ†ç¦»ï¼Œä½†ä»æœ‰ç´§è€¦åˆéƒ¨åˆ†

### **åŠŸèƒ½å®Œæ•´æ€§å·®å¼‚**
1. **ä¿¡å·è´¨é‡è¯„ä¼°**: æ–‡æ¡£è®¾è®¡çš„å®Œæ•´è¯„ä¼°ä½“ç³» vs å½“å‰çš„åŸºç¡€ICè®¡ç®—
2. **åŠ¨æ€è°ƒä»“**: æ–‡æ¡£çš„æ™ºèƒ½è°ƒä»“å†³ç­– vs å½“å‰çš„å›ºå®šå‘¨æœŸè°ƒä»“
3. **é…ç½®åŒ–**: æ–‡æ¡£çš„å…¨é¢é…ç½®åŒ– vs å½“å‰çš„éƒ¨åˆ†é…ç½®åŒ–

### **æŠ€æœ¯å®ç°å·®å¼‚**
1. **é£é™©æ¨¡å‹**: ç¼ºå°‘å› å­æ¨¡å‹ç­‰é«˜çº§åæ–¹å·®ä¼°è®¡æ–¹æ³•
2. **å¤šæ—¶é—´çª—å£**: å®Œå…¨ç¼ºå¤±å¤šè§†é‡é¢„æµ‹æ¡†æ¶
3. **è¯„ä¼°ä½“ç³»**: ç¼ºå°‘ç³»ç»ŸåŒ–çš„ä¿¡å·è´¨é‡è¯„ä¼°æ¡†æ¶

---

## ğŸ’¡ **æ”¹è¿›æ–¹æ¡ˆä¸‰ï¼ˆä¿¡å·è´¨é‡è¯„ä¼°ï¼‰å…·ä½“å®æ–½æ–¹æ¡ˆ**

### **å®æ–½æ­¥éª¤**

#### **æ­¥éª¤1: åˆ›å»ºç‹¬ç«‹ä¿¡å·è¯„ä¼°å™¨**
```python
# æ–°æ–‡ä»¶: utils/signal_evaluator.py
class SignalQualityEvaluator:
    """ä¸“ä¸šåŒ–çš„ä¿¡å·è´¨é‡è¯„ä¼°å™¨"""

    def evaluate(self, alpha_signals, realized_returns, horizon_days=10):
        """
        å®ç°å®Œæ•´çš„ä¿¡å·è´¨é‡è¯„ä¼°ï¼š
        - ICæ—¶é—´åºåˆ—è®¡ç®—
        - ICIRï¼ˆä¿¡æ¯æ¯”ç‡ï¼‰
        - Rank ICæ—¶é—´åºåˆ—
        - åˆ†ä½æ•°æ”¶ç›Šå·®åˆ†æ
        - å‘½ä¸­ç‡ç»Ÿè®¡
        - ä¿¡å·ç¨³å®šæ€§è¯„ä¼°
        """
```

#### **æ­¥éª¤2: é›†æˆåˆ°ç­–ç•¥æµç¨‹**
```python
# åœ¨ base_strategy.py çš„ generate_signals_single_date ä¸­æ·»åŠ 
def generate_signals_single_date(self, current_date):
    # ... ç°æœ‰æµç¨‹ ...

    # æ–°å¢ï¼šä¿¡å·è´¨é‡è¯„ä¼°
    if self.eval_enabled:
        diagnostics = self._evaluate_signal_quality(
            alpha_scores, price_data, current_date
        )
        result['diagnostics'] = diagnostics

    return result
```

#### **æ­¥éª¤3: é…ç½®æ–‡ä»¶é›†æˆ**
```yaml
# configs/ ä¸­æ·»åŠ 
signal_evaluation:
  enabled: true
  metrics: [ic, rank_ic, sharpe, hit_rate, max_drawdown]
  thresholds:
    ic_min: 0.03
    rank_ic_min: 0.05
    icir_min: 0.3
  model_selection:
    prefer_linear_if_ic_rank_ic_ratio: 1.2
    prefer_nonlinear_if_ratio: 0.8
```

### **å®æ–½æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ**

#### **æŒ‘æˆ˜1: å†å²æ•°æ®è·å–**
- **é—®é¢˜**: ICè®¡ç®—éœ€è¦æœªæ¥å®ç°çš„æ”¶ç›Šç‡æ•°æ®
- **è§£å†³æ–¹æ¡ˆ**:
  1. åœ¨ä¿¡å·ç”Ÿæˆæ—¶ç¼“å­˜æœªæ¥Nå¤©çš„æ”¶ç›Šç‡
  2. ä½¿ç”¨æ»‘åŠ¨çª—å£è¿›è¡Œå®æ—¶ICè®¡ç®—
  3. å»ºç«‹ä¿¡å·-æ”¶ç›Šç‡é…å¯¹æ•°æ®åº“

#### **æŒ‘æˆ˜2: è®¡ç®—å¤æ‚åº¦**
- **é—®é¢˜**: ICæ—¶é—´åºåˆ—è®¡ç®—éœ€è¦å¤§é‡å†å²æ•°æ®
- **è§£å†³æ–¹æ¡ˆ**:
  1. å¢é‡è®¡ç®—é¿å…é‡å¤è®¡ç®—
  2. ä½¿ç”¨ç¼“å­˜å­˜å‚¨ä¸­é—´ç»“æœ
  3. å¹¶è¡ŒåŒ–è®¡ç®—å¤šä¸ªæŒ‡æ ‡çš„IC

#### **æŒ‘æˆ˜3: ä¿¡å·è´¨é‡é˜ˆå€¼è®¾å®š**
- **é—®é¢˜**: ä¸åŒå¸‚åœºç¯å¢ƒä¸‹åˆç†çš„ICé˜ˆå€¼ä¸åŒ
- **è§£å†³æ–¹æ¡ˆ**:
  1. åŸºäºå†å²å›æµ‹ç¡®å®šåŠ¨æ€é˜ˆå€¼
  2. è€ƒè™‘å¸‚åœºregimeçš„é˜ˆå€¼è°ƒæ•´
  3. å®ç°è‡ªé€‚åº”é˜ˆå€¼æœºåˆ¶

---

## ğŸ’¡ **æ”¹è¿›æ–¹æ¡ˆäº”ï¼ˆé…ç½®åŒ–è¯„ä¼°æŒ‡æ ‡ï¼‰å…·ä½“å®æ–½æ–¹æ¡ˆ**

### **å®æ–½æ­¥éª¤**

#### **æ­¥éª¤1: æ‰©å±•é…ç½®æ–‡ä»¶ç»“æ„**
```yaml
# åœ¨ç°æœ‰é…ç½®åŸºç¡€ä¸Šæ‰©å±•
strategy:
  name: "MLStrategy_v1"

  # æ–°å¢ï¼šå®Œæ•´çš„ä¿¡å·è¯„ä¼°é…ç½®
  signal_evaluation:
    enabled: true
    evaluation_frequency: "weekly"  # daily, weekly, monthly

    # è¯„ä¼°æŒ‡æ ‡é…ç½®
    metrics:
      ic:
        enabled: true
        horizon_days: [5, 10, 20]  # å¤šä¸ªé¢„æµ‹å‘¨æœŸ
        min_threshold: 0.03
      rank_ic:
        enabled: true
        horizon_days: [5, 10, 20]
        min_threshold: 0.05
      icir:
        enabled: true
        min_threshold: 0.3
      hit_rate:
        enabled: true
        min_threshold: 0.51
      quintile_analysis:
        enabled: true
        quintiles: [0.2, 0.4, 0.6, 0.8]
      stability_metrics:
        enabled: true
        window_days: 60

    # æ¨¡å‹é€‰æ‹©é€»è¾‘é…ç½®
    model_selection:
      auto_select: true
      ic_vs_rank_ic_threshold:
        linear_preferred: 1.2
        nonlinear_preferred: 0.8
      performance_decay_threshold: 0.8  # æ€§èƒ½ä¸‹é™80%æ—¶è­¦å‘Š

    # è‡ªé€‚åº”è°ƒæ•´é…ç½®
    adaptive_adjustment:
      enabled: true
      triggers:
        - metric: "ic_mean"
          threshold: 0.01
          action: "warning"
        - metric: "icir"
          threshold: 0.2
          action: "conservative_mode"
      conservative_mode_config:
        position_scaling: 0.5
        max_positions: 10

  # æ–°å¢ï¼šå¤šæ—¶é—´çª—å£é…ç½®
  multi_horizon:
    enabled: false  # å‡†å¤‡ä¸ºæœªæ¥å¯ç”¨
    horizons: [1, 5, 10, 20]
    decay_method: "exponential"
    decay_lambda: 0.1
    rebalancing:
      method: "threshold_based"
      min_net_gain: 0.001
      transaction_cost: 0.001
```

#### **æ­¥éª¤2: åˆ›å»ºé…ç½®ç®¡ç†å™¨**
```python
# æ–°æ–‡ä»¶: utils/config_manager.py
class StrategyConfigManager:
    """ç­–ç•¥é…ç½®ç®¡ç†å™¨"""

    def __init__(self, config_path):
        self.config = self._load_config(config_path)
        self.signal_eval_config = self.config.get('signal_evaluation', {})

    def get_eval_config(self):
        """è·å–ä¿¡å·è¯„ä¼°é…ç½®"""
        return self.signal_eval_config

    def get_thresholds(self):
        """è·å–æ‰€æœ‰é˜ˆå€¼é…ç½®"""
        return {
            'ic_min': self.signal_eval_config.get('metrics', {}).get('ic', {}).get('min_threshold', 0.03),
            'rank_ic_min': self.signal_eval_config.get('metrics', {}).get('rank_ic', {}).get('min_threshold', 0.05),
            # ... å…¶ä»–é˜ˆå€¼
        }

    def should_enable_evaluation(self):
        """åˆ¤æ–­æ˜¯å¦å¯ç”¨ä¿¡å·è¯„ä¼°"""
        return self.signal_eval_config.get('enabled', False)
```

#### **æ­¥éª¤3: é›†æˆåˆ°ç­–ç•¥åŸºç±»**
```python
# åœ¨ base_strategy.py ä¸­æ‰©å±•
class BaseStrategy(ABC):

    def __init__(self, config, ...):
        # ç°æœ‰åˆå§‹åŒ–...

        # æ–°å¢ï¼šé…ç½®ç®¡ç†å™¨
        self.config_manager = StrategyConfigManager(config)

        # æ–°å¢ï¼šä¿¡å·è¯„ä¼°å™¨åˆå§‹åŒ–
        if self.config_manager.should_enable_evaluation():
            self.signal_evaluator = SignalQualityEvaluator(
                config=self.config_manager.get_eval_config()
            )
            self.eval_enabled = True
        else:
            self.eval_enabled = False

    def _check_quality_thresholds(self, diagnostics):
        """åŸºäºé…ç½®æ£€æŸ¥ä¿¡å·è´¨é‡é˜ˆå€¼"""
        thresholds = self.config_manager.get_thresholds()

        # æ£€æŸ¥ICé˜ˆå€¼
        ic = diagnostics.get('ic_mean', 0)
        if ic < thresholds['ic_min']:
            self._handle_low_quality('ic', ic, thresholds['ic_min'])

        # æ£€æŸ¥ICIRé˜ˆå€¼
        icir = diagnostics.get('icir', 0)
        if icir < thresholds['icir']:
            self._handle_low_quality('icir', icir, thresholds['icir'])

    def _handle_low_quality(self, metric, value, threshold):
        """å¤„ç†ä½è´¨é‡ä¿¡å·"""
        eval_config = self.config_manager.get_eval_config()
        adaptive_config = eval_config.get('adaptive_adjustment', {})

        for trigger in adaptive_config.get('triggers', []):
            if trigger['metric'] == metric and value < trigger['threshold']:
                self._execute_trigger_action(trigger['action'])
```

### **å®æ–½æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ**

#### **æŒ‘æˆ˜1: é…ç½®å¤æ‚åº¦ç®¡ç†**
- **é—®é¢˜**: é…ç½®é¡¹è¿‡å¤šå¯¼è‡´ç®¡ç†å¤æ‚
- **è§£å†³æ–¹æ¡ˆ**:
  1. åˆ†å±‚é…ç½®ï¼šåŸºç¡€é…ç½® + é«˜çº§é…ç½®
  2. é…ç½®æ¨¡æ¿ï¼šæä¾›å¸¸ç”¨åœºæ™¯çš„é¢„è®¾æ¨¡æ¿
  3. é…ç½®éªŒè¯ï¼šå¯åŠ¨æ—¶æ£€æŸ¥é…ç½®å®Œæ•´æ€§å’Œåˆç†æ€§

#### **æŒ‘æˆ˜2: åŠ¨æ€é…ç½®æ›´æ–°**
- **é—®é¢˜**: è¿è¡Œæ—¶è°ƒæ•´é…ç½®éœ€è¦é‡å¯ç³»ç»Ÿ
- **è§£å†³æ–¹æ¡ˆ**:
  1. çƒ­æ›´æ–°æœºåˆ¶ï¼šç›‘å¬é…ç½®æ–‡ä»¶å˜åŒ–
  2. é…ç½®ç‰ˆæœ¬æ§åˆ¶ï¼šè·Ÿè¸ªé…ç½®å˜æ›´å†å²
  3. å›æ»šæœºåˆ¶ï¼šé…ç½®é”™è¯¯æ—¶å¿«é€Ÿå›æ»š

#### **æŒ‘æˆ˜3: é…ç½®ä¸ä»£ç åŒæ­¥**
- **é—®é¢˜**: ä»£ç å˜æ›´æ—¶é…ç½®æ–‡ä»¶å¯èƒ½è¿‡æ—¶
- **è§£å†³æ–¹æ¡ˆ**:
  1. é…ç½®schemaéªŒè¯ï¼šç¡®ä¿é…ç½®ç¬¦åˆæœ€æ–°schema
  2. è‡ªåŠ¨è¿ç§»ï¼šä»£ç å‡çº§æ—¶è‡ªåŠ¨è¿ç§»æ—§é…ç½®
  3. æ–‡æ¡£åŒæ­¥ï¼šé…ç½®å˜æ›´è‡ªåŠ¨æ›´æ–°æ–‡æ¡£

---

## ğŸ¯ **å»ºè®®å®æ–½ä¼˜å…ˆçº§**

### **é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰**
1. **æ”¹è¿›æ–¹æ¡ˆä¸‰**: ä¿¡å·è´¨é‡è¯„ä¼° - å¯¹æ¨¡å‹æ”¹è¿›æœ€ç›´æ¥
2. **æ”¹è¿›æ–¹æ¡ˆäº”**: åŸºç¡€é…ç½®åŒ– - æå‡ç³»ç»Ÿçµæ´»æ€§

### **ä¸­ä¼˜å…ˆçº§ï¼ˆåç»­å®æ–½ï¼‰**
3. **æ”¹è¿›æ–¹æ¡ˆäºŒ**: å› å­æ¨¡å‹åæ–¹å·® - æå‡é£é™©ç®¡ç†ç²¾åº¦
4. **æ”¹è¿›æ–¹æ¡ˆä¸€**: å®Œå–„ä¿¡å·-é£é™©åˆ†ç¦» - æå‡æ¶æ„æ¸…æ™°åº¦

### **ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰å®æ–½ï¼‰**
5. **æ”¹è¿›æ–¹æ¡ˆå››**: å¤šæ—¶é—´çª—å£ - å¤æ‚åº¦é«˜ï¼Œæ”¶ç›Šç›¸å¯¹æœ‰é™

---

## â“ **éœ€è¦è®¨è®ºçš„é—®é¢˜**

1. **ä¿¡å·è´¨é‡è¯„ä¼°çš„æ•°æ®éœ€æ±‚**:
   - æ˜¯å¦éœ€è¦å»ºç«‹ä¸“é—¨çš„ä¿¡å·-æ”¶ç›Šç‡æ•°æ®åº“ï¼Ÿ
   - å¦‚ä½•å¤„ç†è¯„ä¼°æ•°æ®çš„å»¶è¿Ÿé—®é¢˜ï¼Ÿ

2. **é…ç½®åŒ–çš„ç¨‹åº¦**:
   - æ˜¯å¦æ‰€æœ‰é˜ˆå€¼éƒ½éœ€è¦é…ç½®åŒ–ï¼Ÿ
   - å¦‚ä½•å¹³è¡¡çµæ´»æ€§å’Œå¤æ‚åº¦ï¼Ÿ

3. **æ€§èƒ½å½±å“**:
   - ä¿¡å·è´¨é‡è¯„ä¼°çš„è®¡ç®—å¼€é”€å¦‚ä½•æ§åˆ¶ï¼Ÿ
   - æ˜¯å¦éœ€è¦å¼‚æ­¥è¯„ä¼°æœºåˆ¶ï¼Ÿ

4. **å‘åå…¼å®¹æ€§**:
   - æ–°åŠŸèƒ½å¦‚ä½•ä¸ç°æœ‰ç­–ç•¥å…¼å®¹ï¼Ÿ
   - æ˜¯å¦éœ€è¦æä¾›è¿ç§»å·¥å…·ï¼Ÿ

è¿™äº›å®æ–½è®¡åˆ’éœ€è¦æˆ‘ä»¬è¿›ä¸€æ­¥è®¨è®ºå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚å’Œä¸šåŠ¡éœ€æ±‚ã€‚