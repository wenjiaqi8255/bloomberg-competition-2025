"""
é˜¶æ®µ0ï¼šResidual Momentum å¿«é€ŸéªŒè¯è„šæœ¬

ç›®æ ‡ï¼šéªŒè¯ residual momentum æ˜¯å¦æ¯”å½“å‰ alpha æ–¹æ³•æ›´æœ‰æ•ˆ

æ–¹æ³•ï¼š
1. æ‰‹åŠ¨åŠ è½½factor dataå’Œstock returns
2. å¯¹å‡ åªè‚¡ç¥¨åštime-series regression
3. è®¡ç®—residuals
4. è®¡ç®—residual momentumä¿¡å·
5. å¯¹æ¯”ç”¨alpha vs residual momentumçš„IC
6. è¾“å‡ºå¯¹æ¯”è¡¨æ ¼

ä½¿ç”¨æ–¹æ³•ï¼š
    python validate_residual_momentum.py
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
import logging

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.trading_system.utils.alpha_stats import compute_alpha_tstat
from src.trading_system.data.ff5_provider import FF5DataProvider

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ResidualMomentumValidator:
    """
    éªŒè¯Residual Momentumæ•ˆæœçš„ç‹¬ç«‹è„šæœ¬
    """
    
    def __init__(self, 
                 factor_data_path: str = None,
                 formation_period: int = 252,
                 skip_recent_days: int = 21,
                 forward_lookback_days: int = 21):
        """
        Args:
            factor_data_path: FF5 factor data CSVè·¯å¾„
            formation_period: Residual momentum formation period (days)
            skip_recent_days: è·³è¿‡æœ€è¿‘Nå¤©ï¼ˆé¿å…çŸ­æœŸåè½¬ï¼‰
            forward_lookback_days: è®¡ç®—ICæ—¶ä½¿ç”¨çš„forward returnçª—å£
        """
        self.formation_period = formation_period
        self.skip_recent_days = skip_recent_days
        self.forward_lookback_days = forward_lookback_days
        
        # åŠ è½½factor data
        if factor_data_path is None:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            possible_paths = [
                project_root / "data" / "ff5_factors_processed.csv",
                project_root / "src" / "trading_system" / "data" / "ff5_factors_processed.csv",
            ]
            for path in possible_paths:
                if path.exists():
                    factor_data_path = str(path)
                    break
        
        if factor_data_path and os.path.exists(factor_data_path):
            logger.info(f"Loading factor data from: {factor_data_path}")
            self.factor_data = pd.read_csv(factor_data_path, index_col=0, parse_dates=True)
            logger.info(f"Loaded factor data: {self.factor_data.shape}")
        else:
            # å°è¯•ä½¿ç”¨FF5DataProvider
            logger.info("Trying to load factor data via FF5DataProvider...")
            try:
                # å°è¯•æ‰€æœ‰å¯èƒ½çš„è·¯å¾„
                for path in possible_paths:
                    if path.exists():
                        provider = FF5DataProvider(file_path=str(path))
                        self.factor_data = provider.get_factor_returns()
                        logger.info(f"Loaded factor data via provider: {self.factor_data.shape}")
                        break
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œå°è¯•ä»ç½‘ç»œè·å–
                    logger.warning("No local factor data file found, trying to fetch from network...")
                    provider = FF5DataProvider()
                    self.factor_data = provider.get_factor_returns()
                    logger.info(f"Loaded factor data from network: {self.factor_data.shape}")
            except Exception as e:
                logger.error(f"Failed to load factor data: {e}")
                raise
        
        # éªŒè¯factor data
        required_cols = ['MKT', 'SMB', 'HML', 'RMW', 'CMA', 'RF']
        missing = set(required_cols) - set(self.factor_data.columns)
        if missing:
            raise ValueError(f"Missing factor columns: {missing}")
        
        logger.info(f"Factor data date range: {self.factor_data.index.min()} to {self.factor_data.index.max()}")
    
    def load_stock_returns(self, symbols: List[str], 
                          start_date: datetime, 
                          end_date: datetime) -> Dict[str, pd.Series]:
        """
        åŠ è½½è‚¡ç¥¨æ”¶ç›Šæ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        
        Returns:
            Dict[symbol, returns_series]
        """
        logger.info(f"Loading stock returns for {len(symbols)} symbols...")
        
        try:
            from src.trading_system.data.yfinance_provider import YFinanceProvider
            
            provider = YFinanceProvider()
            price_data = provider.get_historical_data(symbols, start_date, end_date)
            
            returns_dict = {}
            for symbol in symbols:
                if symbol in price_data and 'Close' in price_data[symbol].columns:
                    prices = price_data[symbol]['Close']
                    returns = prices.pct_change().dropna()
                    returns_dict[symbol] = returns
            
            logger.info(f"Loaded returns for {len(returns_dict)} symbols")
            return returns_dict
            
        except Exception as e:
            logger.error(f"Failed to load stock returns: {e}")
            logger.info("Trying alternative method...")
            
            # å¦‚æœYFinanceProviderå¤±è´¥ï¼Œå°è¯•ä»CSVåŠ è½½
            # è¿™é‡Œå¯ä»¥æ‰©å±•æ”¯æŒå…¶ä»–æ•°æ®æº
            raise
    
    def fit_time_series_regression(self, 
                                   returns: pd.Series,
                                   factors: pd.DataFrame,
                                   required_factors: List[str] = None) -> Dict:
        """
        å¯¹å•åªè‚¡ç¥¨è¿›è¡Œtime-series regression
        
        Args:
            returns: è‚¡ç¥¨æ”¶ç›Šæ—¶é—´åºåˆ—ï¼ˆexcess returnsï¼‰
            factors: å› å­æ•°æ®DataFrame
            required_factors: éœ€è¦çš„å› å­åˆ—
        
        Returns:
            Dict with 'alpha', 'betas', 'residuals', 'fitted_values'
        """
        if required_factors is None:
            required_factors = ['MKT', 'SMB', 'HML', 'RMW', 'CMA']
        
        # å¯¹é½æ•°æ®
        common_dates = returns.index.intersection(factors.index)
        if len(common_dates) < 50:
            logger.warning(f"Insufficient common dates: {len(common_dates)}")
            return None
        
        returns_aligned = returns.loc[common_dates]
        factors_aligned = factors.loc[common_dates][required_factors]
        
        # è®¡ç®—excess returnsï¼ˆå¦‚æœreturnsä¸æ˜¯excess returnsï¼‰
        if 'RF' in factors.columns:
            risk_free = factors.loc[common_dates]['RF']
            returns_aligned = returns_aligned - risk_free
        
        # å»é™¤NaN
        valid_mask = ~(returns_aligned.isna() | factors_aligned.isna().any(axis=1))
        returns_clean = returns_aligned[valid_mask]
        factors_clean = factors_aligned[valid_mask]
        
        if len(returns_clean) < 50:
            logger.warning(f"Insufficient clean data: {len(returns_clean)}")
            return None
        
        # å›å½’
        X = factors_clean.values
        y = returns_clean.values
        
        model = LinearRegression()
        model.fit(X, y)
        
        # è®¡ç®—fitted valueså’Œresiduals
        fitted_values = model.predict(X)
        residuals = y - fitted_values
        
        # å­˜å‚¨ä¸ºSeriesï¼ˆä¿ç•™æ—¶é—´ç´¢å¼•ï¼‰
        residuals_series = pd.Series(residuals, index=returns_clean.index)
        fitted_series = pd.Series(fitted_values, index=returns_clean.index)
        
        return {
            'alpha': float(model.intercept_),
            'betas': dict(zip(required_factors, model.coef_)),
            'residuals': residuals_series,
            'fitted_values': fitted_series,
            'r_squared': float(model.score(X, y)),
            'n_obs': len(returns_clean)
        }
    
    def calculate_residual_momentum(self, 
                                   residuals: pd.Series,
                                   current_date: datetime) -> float:
        """
        è®¡ç®—residual momentumä¿¡å·
        
        Args:
            residuals: Residualsæ—¶é—´åºåˆ—
            current_date: å½“å‰æ—¥æœŸï¼ˆåªä½¿ç”¨<=current_dateçš„æ•°æ®ï¼‰
        
        Returns:
            Standardized residual momentum
        """
        # è¿‡æ»¤åˆ°å½“å‰æ—¥æœŸ
        historical_residuals = residuals[residuals.index <= current_date]
        
        if len(historical_residuals) < self.formation_period + self.skip_recent_days:
            return 0.0
        
        # è·³è¿‡æœ€è¿‘çš„æ—¥æœŸ
        lookback_data = historical_residuals.iloc[:-self.skip_recent_days]
        
        # å–formation period
        formation_residuals = lookback_data.iloc[-self.formation_period:]
        
        if len(formation_residuals) == 0:
            return 0.0
        
        # è®¡ç®—momentumï¼ˆsumï¼‰
        momentum = formation_residuals.sum()
        
        # æ ‡å‡†åŒ–ï¼ˆé™¤ä»¥æ ‡å‡†å·®ï¼‰
        volatility = formation_residuals.std()
        if volatility > 0:
            standardized_momentum = momentum / volatility
        else:
            standardized_momentum = 0.0
        
        return standardized_momentum
    
    def calculate_forward_returns(self, 
                                  returns: pd.Series,
                                  date: datetime) -> float:
        """
        è®¡ç®—forward returnï¼ˆç”¨äºICè®¡ç®—ï¼‰
        
        Args:
            returns: è‚¡ç¥¨æ”¶ç›Šæ—¶é—´åºåˆ—
            date: ä¿¡å·æ—¥æœŸ
        
        Returns:
            Forward return (æœªæ¥Nå¤©çš„ç´¯è®¡æ”¶ç›Š)
        """
        # ç¡®ä¿dateæ˜¯datetimeç±»å‹
        if not isinstance(date, pd.Timestamp):
            date = pd.to_datetime(date)
        
        # æ‰¾åˆ°dateä¹‹åçš„æ•°æ®
        future_dates = returns[returns.index > date]
        
        if len(future_dates) < self.forward_lookback_days:
            return np.nan
        
        # å–å‰Nå¤©çš„æ•°æ®
        forward_data = future_dates.iloc[:self.forward_lookback_days]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaN
        if forward_data.isna().any():
            return np.nan
        
        # è®¡ç®—æœªæ¥Nå¤©çš„ç´¯è®¡æ”¶ç›Š
        try:
            forward_returns = (1 + forward_data).prod() - 1
            return float(forward_returns)
        except Exception:
            return np.nan
    
    def calculate_ic(self, 
                     signals: pd.Series,
                     forward_returns: pd.Series) -> Dict[str, float]:
        """
        è®¡ç®—Information Coefficient (IC)
        
        Args:
            signals: ä¿¡å·Seriesï¼ˆindexæ˜¯æ—¥æœŸï¼Œvaluesæ˜¯ä¿¡å·å€¼ï¼‰
            forward_returns: Forward returns Seriesï¼ˆindexæ˜¯æ—¥æœŸï¼Œvaluesæ˜¯forward returnï¼‰
        
        Returns:
            Dict with IC metrics
        """
        # å¯¹é½æ•°æ®
        common_dates = signals.index.intersection(forward_returns.index)
        if len(common_dates) < 10:
            return {
                'mean_ic': 0.0,
                'ic_std': 0.0,
                'ic_sharpe': 0.0,
                'positive_ic_ratio': 0.0,
                'n_obs': len(common_dates)
            }
        
        signals_aligned = signals.loc[common_dates]
        returns_aligned = forward_returns.loc[common_dates]
        
        # å»é™¤NaN
        valid_mask = ~(signals_aligned.isna() | returns_aligned.isna())
        signals_clean = signals_aligned[valid_mask]
        returns_clean = returns_aligned[valid_mask]
        
        if len(signals_clean) < 10:
            return {
                'mean_ic': 0.0,
                'ic_std': 0.0,
                'ic_sharpe': 0.0,
                'positive_ic_ratio': 0.0,
                'n_obs': len(signals_clean)
            }
        
        # è®¡ç®—ICï¼ˆPearson correlationï¼‰
        ic = signals_clean.corr(returns_clean)
        
        # å¦‚æœICæ˜¯NaNï¼Œè¿”å›0
        if pd.isna(ic):
            ic = 0.0
        
        return {
            'mean_ic': float(ic),
            'ic_std': 0.0,  # å•åªè‚¡ç¥¨çš„ICæ²¡æœ‰std
            'ic_sharpe': 0.0,
            'positive_ic_ratio': 1.0 if ic > 0 else 0.0,
            'n_obs': len(signals_clean)
        }
    
    def validate_cross_sectional(self, 
                                 symbols: List[str],
                                 start_date: datetime,
                                 end_date: datetime,
                                 train_start: datetime = None,
                                 train_end: datetime = None) -> pd.DataFrame:
        """
        æ¨ªæˆªé¢éªŒè¯ï¼šå¯¹æ¯”alpha vs residual momentumçš„IC
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: éªŒè¯å¼€å§‹æ—¥æœŸ
            end_date: éªŒè¯ç»“æŸæ—¥æœŸ
            train_start: è®­ç»ƒå¼€å§‹æ—¥æœŸï¼ˆå¦‚æœNoneï¼Œä½¿ç”¨start_dateå‰1å¹´ï¼‰
            train_end: è®­ç»ƒç»“æŸæ—¥æœŸï¼ˆå¦‚æœNoneï¼Œä½¿ç”¨start_dateï¼‰
        
        Returns:
            DataFrame with comparison results
        """
        logger.info("=" * 80)
        logger.info("Starting Cross-Sectional Validation")
        logger.info("=" * 80)
        
        # è®¾ç½®è®­ç»ƒæœŸ
        if train_start is None:
            train_start = start_date - timedelta(days=365)
        if train_end is None:
            train_end = start_date
        
        logger.info(f"Training period: {train_start} to {train_end}")
        logger.info(f"Validation period: {start_date} to {end_date}")
        
        # åŠ è½½è‚¡ç¥¨æ”¶ç›Šæ•°æ®
        all_returns = self.load_stock_returns(symbols, train_start, end_date)
        
        if len(all_returns) == 0:
            raise ValueError("No stock returns loaded")
        
        # å‡†å¤‡å› å­æ•°æ®
        factor_train = self.factor_data[
            (self.factor_data.index >= train_start) & 
            (self.factor_data.index <= train_end)
        ]
        factor_val = self.factor_data[
            (self.factor_data.index >= start_date) & 
            (self.factor_data.index <= end_date)
        ]
        
        # Step 1: è®­ç»ƒæœŸå›å½’ï¼Œè·å–alphaå’Œresiduals
        # æ³¨æ„ï¼šä¸ºäº†è®¡ç®—éªŒè¯æœŸçš„momentumï¼Œæˆ‘ä»¬éœ€è¦åœ¨éªŒè¯æœŸä¹Ÿè®¡ç®—residuals
        # ä½†ä½¿ç”¨è®­ç»ƒæœŸä¼°è®¡çš„betaså’Œalpha
        logger.info("\nStep 1: Fitting time-series regressions...")
        regression_results = {}
        
        # é¦–å…ˆåœ¨è®­ç»ƒæœŸæ‹Ÿåˆæ¨¡å‹
        for symbol in all_returns.keys():
            returns = all_returns[symbol]
            returns_train = returns[
                (returns.index >= train_start) & 
                (returns.index <= train_end)
            ]
            
            if len(returns_train) < 50:
                logger.warning(f"Insufficient training data for {symbol}: {len(returns_train)}")
                continue
            
            result = self.fit_time_series_regression(returns_train, factor_train)
            if result is not None:
                regression_results[symbol] = result
                logger.info(f"  {symbol}: alpha={result['alpha']:.6f}, RÂ²={result['r_squared']:.3f}, n_obs={result['n_obs']}")
        
        logger.info(f"Successfully fitted {len(regression_results)} symbols")
        
        # Step 1.5: æ‰©å±•residualsåˆ°éªŒè¯æœŸï¼ˆä½¿ç”¨è®­ç»ƒæœŸçš„betasè®¡ç®—éªŒè¯æœŸçš„residualsï¼‰
        logger.info("\nStep 1.5: Computing residuals for validation period...")
        factor_val_aligned = factor_val.copy()
        
        for symbol in regression_results.keys():
            returns = all_returns[symbol]
            returns_val = returns[
                (returns.index >= start_date) & 
                (returns.index <= end_date)
            ]
            
            if len(returns_val) == 0:
                continue
            
            # å¯¹é½å› å­æ•°æ®å’Œæ”¶ç›Šæ•°æ®
            common_dates = returns_val.index.intersection(factor_val_aligned.index)
            if len(common_dates) == 0:
                continue
            
            returns_aligned = returns_val.loc[common_dates]
            factors_aligned = factor_val_aligned.loc[common_dates]
            
            # è®¡ç®—excess returns
            if 'RF' in factors_aligned.columns:
                risk_free = factors_aligned['RF']
                returns_excess = returns_aligned - risk_free
            else:
                returns_excess = returns_aligned
            
            # ä½¿ç”¨è®­ç»ƒæœŸçš„betaså’Œalphaè®¡ç®—fitted values
            betas = regression_results[symbol]['betas']
            alpha = regression_results[symbol]['alpha']
            
            # ç¡®ä¿å› å­é¡ºåºä¸betasä¸€è‡´
            factor_cols = ['MKT', 'SMB', 'HML', 'RMW', 'CMA']
            factor_values = factors_aligned[factor_cols].values
            
            # betasæ˜¯å­—å…¸ï¼Œéœ€è¦æŒ‰é¡ºåºæå–
            beta_array = np.array([betas[col] for col in factor_cols])
            
            # è®¡ç®—fitted values: alpha + beta @ factors
            fitted_values = alpha + np.dot(factor_values, beta_array)
            fitted_series = pd.Series(fitted_values, index=common_dates)
            
            # è®¡ç®—residuals
            residuals_val = returns_excess - fitted_series
            
            # åˆå¹¶è®­ç»ƒæœŸå’ŒéªŒè¯æœŸçš„residuals
            residuals_train = regression_results[symbol]['residuals']
            residuals_combined = pd.concat([residuals_train, residuals_val]).sort_index()
            
            # æ›´æ–°regression_resultsä¸­çš„residuals
            regression_results[symbol]['residuals'] = residuals_combined
            
        logger.info("Extended residuals to validation period")
        
        if len(regression_results) == 0:
            raise ValueError("No successful regressions")
        
        # Step 2: åœ¨éªŒè¯æœŸè®¡ç®—ä¿¡å·å’Œforward returns
        logger.info("\nStep 2: Computing signals and forward returns...")
        
        # ç”Ÿæˆrebalance datesï¼ˆæ¯æœˆä¸€æ¬¡ï¼‰
        # ä½¿ç”¨'ME'æ›¿ä»£å·²å¼ƒç”¨çš„'M'
        try:
            rebalance_dates = pd.date_range(start=start_date, end=end_date, freq='ME')
        except:
            # å…¼å®¹æ—§ç‰ˆæœ¬pandas
            rebalance_dates = pd.date_range(start=start_date, end=end_date, freq='M')
        
        logger.info(f"Rebalance dates: {len(rebalance_dates)}")
        if len(rebalance_dates) > 0:
            logger.info(f"  First rebalance: {rebalance_dates[0]}")
            logger.info(f"  Last rebalance: {rebalance_dates[-1]}")
        
        # å­˜å‚¨ä¿¡å·å’Œforward returns
        alpha_signals = {}  # {date: {symbol: signal}}
        expected_return_signals = {}  # {date: {symbol: signal}} - æ–°å¢
        momentum_signals = {}  # {date: {symbol: signal}}
        forward_returns_dict = {}  # {date: {symbol: forward_return}}
        
        forward_returns_stats = {'total': 0, 'valid': 0, 'nan': 0}
        
        for date in rebalance_dates:
            alpha_signals[date] = {}
            expected_return_signals[date] = {}
            momentum_signals[date] = {}
            forward_returns_dict[date] = {}
            
            # è·å–å½“å‰æ—¥æœŸçš„å› å­å€¼ï¼ˆç”¨äºè®¡ç®—expected returnï¼‰
            if date in factor_val.index:
                current_factors = factor_val.loc[date]
            else:
                # å¦‚æœç²¾ç¡®æ—¥æœŸä¸å­˜åœ¨ï¼Œæ‰¾æœ€è¿‘çš„
                available_dates = factor_val.index[factor_val.index <= date]
                if len(available_dates) > 0:
                    current_factors = factor_val.loc[available_dates.max()]
                else:
                    current_factors = None
            
            for symbol in regression_results.keys():
                # Alphaä¿¡å·ï¼ˆé™æ€ï¼‰
                alpha_signals[date][symbol] = regression_results[symbol]['alpha']
                
                # Expected Returnä¿¡å·ï¼ˆalpha + beta Ã— factorsï¼‰
                if current_factors is not None:
                    betas = regression_results[symbol]['betas']
                    alpha = regression_results[symbol]['alpha']
                    
                    # è®¡ç®—expected return: alpha + beta @ factors
                    factor_cols = ['MKT', 'SMB', 'HML', 'RMW', 'CMA']
                    factor_values = np.array([current_factors[col] for col in factor_cols])
                    beta_array = np.array([betas[col] for col in factor_cols])
                    
                    expected_return = alpha + np.dot(beta_array, factor_values)
                    expected_return_signals[date][symbol] = expected_return
                else:
                    expected_return_signals[date][symbol] = np.nan
                
                # Residual momentumä¿¡å·ï¼ˆåŠ¨æ€ï¼‰
                residuals = regression_results[symbol]['residuals']
                momentum_signal = self.calculate_residual_momentum(residuals, date)
                momentum_signals[date][symbol] = momentum_signal
                
                # Forward returns
                returns = all_returns[symbol]
                forward_ret = self.calculate_forward_returns(returns, date)
                forward_returns_dict[date][symbol] = forward_ret
                
                forward_returns_stats['total'] += 1
                if pd.isna(forward_ret):
                    forward_returns_stats['nan'] += 1
                else:
                    forward_returns_stats['valid'] += 1
        
        logger.info(f"Forward returns stats: {forward_returns_stats['valid']}/{forward_returns_stats['total']} valid, {forward_returns_stats['nan']} NaN")
        
        # Step 3: è®¡ç®—æ¨ªæˆªé¢IC
        logger.info("\nStep 3: Calculating cross-sectional IC...")
        
        ic_results = []
        skipped_dates = []
        
        for date in rebalance_dates:
            # Alphaä¿¡å·
            alpha_sig = pd.Series(alpha_signals[date])
            # Expected Returnä¿¡å·
            expected_return_sig = pd.Series(expected_return_signals[date])
            # Momentumä¿¡å·
            momentum_sig = pd.Series(momentum_signals[date])
            # Forward returns
            forward_ret = pd.Series(forward_returns_dict[date])
            
            # å»é™¤NaN
            common_symbols = alpha_sig.index.intersection(
                expected_return_sig.index
            ).intersection(momentum_sig.index).intersection(forward_ret.index)
            
            if len(common_symbols) < 5:
                skipped_dates.append((date, f"insufficient common symbols: {len(common_symbols)}"))
                continue
            
            alpha_sig_clean = alpha_sig.loc[common_symbols]
            expected_return_sig_clean = expected_return_sig.loc[common_symbols]
            momentum_sig_clean = momentum_sig.loc[common_symbols]
            forward_ret_clean = forward_ret.loc[common_symbols].dropna()
            
            if len(forward_ret_clean) < 5:
                skipped_dates.append((date, f"insufficient valid forward returns: {len(forward_ret_clean)}"))
                continue
            
            # ç¡®ä¿ä¿¡å·å’Œforward returnså¯¹é½
            final_symbols = alpha_sig_clean.index.intersection(forward_ret_clean.index)
            if len(final_symbols) < 5:
                skipped_dates.append((date, f"insufficient aligned symbols: {len(final_symbols)}"))
                continue
            
            alpha_sig_final = alpha_sig_clean.loc[final_symbols]
            expected_return_sig_final = expected_return_sig_clean.loc[final_symbols]
            momentum_sig_final = momentum_sig_clean.loc[final_symbols]
            forward_ret_final = forward_ret_clean.loc[final_symbols]
            
            # è®¡ç®—IC
            try:
                # æ£€æŸ¥ä¿¡å·æ˜¯å¦æœ‰è¶³å¤Ÿçš„variation
                alpha_std = alpha_sig_final.std()
                expected_return_std = expected_return_sig_final.std()
                momentum_std = momentum_sig_final.std()
                
                if alpha_std == 0:
                    skipped_dates.append((date, f"alpha signal has zero variance"))
                    continue
                
                if expected_return_std == 0:
                    skipped_dates.append((date, f"expected return signal has zero variance"))
                    continue
                
                if momentum_std == 0:
                    skipped_dates.append((date, f"momentum signal has zero variance"))
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æœ‰NaN
                if (alpha_sig_final.isna().any() or 
                    expected_return_sig_final.isna().any() or 
                    momentum_sig_final.isna().any()):
                    skipped_dates.append((date, f"signals contain NaN"))
                    continue
                
                alpha_ic = alpha_sig_final.corr(forward_ret_final)
                expected_return_ic = expected_return_sig_final.corr(forward_ret_final)
                momentum_ic = momentum_sig_final.corr(forward_ret_final)
                
                if (not pd.isna(alpha_ic) and 
                    not pd.isna(expected_return_ic) and 
                    not pd.isna(momentum_ic)):
                    ic_results.append({
                        'date': date,
                        'alpha_ic': alpha_ic,
                        'expected_return_ic': expected_return_ic,
                        'momentum_ic': momentum_ic,
                        'n_stocks': len(forward_ret_final)
                    })
                    logger.debug(f"  {date}: alpha_ic={alpha_ic:.4f}, expected_return_ic={expected_return_ic:.4f}, momentum_ic={momentum_ic:.4f}, n={len(forward_ret_final)}")
                else:
                    # æ·»åŠ æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                    logger.debug(f"  {date}: alpha_ic={alpha_ic}, expected_return_ic={expected_return_ic}, momentum_ic={momentum_ic}")
                    logger.debug(f"    alpha_sig: mean={alpha_sig_final.mean():.6f}, std={alpha_std:.6f}")
                    logger.debug(f"    expected_return_sig: mean={expected_return_sig_final.mean():.6f}, std={expected_return_std:.6f}")
                    logger.debug(f"    momentum_sig: mean={momentum_sig_final.mean():.6f}, std={momentum_std:.6f}")
                    skipped_dates.append((date, f"IC is NaN: alpha={alpha_ic}, expected_return={expected_return_ic}, momentum={momentum_ic}"))
            except Exception as e:
                skipped_dates.append((date, f"correlation error: {e}"))
                import traceback
                logger.debug(traceback.format_exc())
                continue
        
        if len(ic_results) == 0:
            logger.error(f"No valid IC calculations. Skipped {len(skipped_dates)} dates:")
            for date, reason in skipped_dates[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                logger.error(f"  {date}: {reason}")
            if len(skipped_dates) > 5:
                logger.error(f"  ... and {len(skipped_dates) - 5} more")
            raise ValueError(f"No valid IC calculations. All {len(rebalance_dates)} rebalance dates were skipped.")
        
        logger.info(f"Successfully calculated IC for {len(ic_results)}/{len(rebalance_dates)} dates")
        
        ic_df = pd.DataFrame(ic_results)
        
        # Step 4: æ±‡æ€»ç»Ÿè®¡
        logger.info("\nStep 4: Summary Statistics")
        logger.info("=" * 80)
        
        alpha_ic_mean = ic_df['alpha_ic'].mean()
        alpha_ic_std = ic_df['alpha_ic'].std()
        alpha_ic_sharpe = alpha_ic_mean / alpha_ic_std if alpha_ic_std > 0 else 0.0
        alpha_positive_ratio = (ic_df['alpha_ic'] > 0).mean()
        
        expected_return_ic_mean = ic_df['expected_return_ic'].mean()
        expected_return_ic_std = ic_df['expected_return_ic'].std()
        expected_return_ic_sharpe = expected_return_ic_mean / expected_return_ic_std if expected_return_ic_std > 0 else 0.0
        expected_return_positive_ratio = (ic_df['expected_return_ic'] > 0).mean()
        
        momentum_ic_mean = ic_df['momentum_ic'].mean()
        momentum_ic_std = ic_df['momentum_ic'].std()
        momentum_ic_sharpe = momentum_ic_mean / momentum_ic_std if momentum_ic_std > 0 else 0.0
        momentum_positive_ratio = (ic_df['momentum_ic'] > 0).mean()
        
        # è¾“å‡ºå¯¹æ¯”è¡¨ï¼ˆä¸‰åˆ—å¯¹æ¯”ï¼‰
        comparison = pd.DataFrame({
            'Metric': [
                'Mean IC',
                'IC Std',
                'IC Sharpe',
                'Positive IC Ratio',
                'N Observations'
            ],
            'Alpha (Intercept Only)': [
                f"{alpha_ic_mean:.4f}",
                f"{alpha_ic_std:.4f}",
                f"{alpha_ic_sharpe:.4f}",
                f"{alpha_positive_ratio:.2%}",
                f"{len(ic_df)}"
            ],
            'Expected Return (Alpha + BetaÃ—Factors)': [
                f"{expected_return_ic_mean:.4f}",
                f"{expected_return_ic_std:.4f}",
                f"{expected_return_ic_sharpe:.4f}",
                f"{expected_return_positive_ratio:.2%}",
                f"{len(ic_df)}"
            ],
            'Residual Momentum': [
                f"{momentum_ic_mean:.4f}",
                f"{momentum_ic_std:.4f}",
                f"{momentum_ic_sharpe:.4f}",
                f"{momentum_positive_ratio:.2%}",
                f"{len(ic_df)}"
            ]
        })
        
        print("\n" + "=" * 100)
        print("VALIDATION RESULTS: Alpha vs Expected Return vs Residual Momentum")
        print("=" * 100)
        print(comparison.to_string(index=False))
        print("=" * 100)
        
        # æ·»åŠ è§£é‡Šè¯´æ˜
        print("\nğŸ“Š Signal Explanation:")
        print("  â€¢ Alpha (Intercept Only): Uses only the regression intercept as signal")
        print("    â†’ Ignores factor exposures, focuses on unexplained returns")
        print("  â€¢ Expected Return (Alpha + BetaÃ—Factors): Uses full factor model prediction")
        print("    â†’ Considers both intercept and factor loadings Ã— current factor values")
        print("  â€¢ Residual Momentum: Uses past residuals' momentum as signal")
        print("    â†’ Captures firm-specific momentum after controlling for factors")
        print()
        
        # ä¿å­˜ç»“æœ
        output_dir = project_root / "validation_results"
        output_dir.mkdir(exist_ok=True)
        
        ic_df.to_csv(output_dir / "ic_comparison.csv", index=False)
        comparison.to_csv(output_dir / "summary_comparison.csv", index=False)
        
        logger.info(f"\nResults saved to: {output_dir}")
        
        return comparison


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    # ä½¿ç”¨ä¸€äº›å¸¸è§çš„è‚¡ç¥¨ä»£ç ï¼ˆå¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'JPM', 'V', 'JNJ']
    
    # æ—¥æœŸèŒƒå›´
    # ä½¿ç”¨æœ€è¿‘3å¹´æ•°æ®ï¼šè®­ç»ƒ2å¹´ï¼ŒéªŒè¯1å¹´
    # æ³¨æ„ï¼šéœ€è¦ç•™å‡ºè¶³å¤Ÿçš„æ—¶é—´ç”¨äºforward returnsè®¡ç®—
    end_date = datetime.now() - timedelta(days=60)  # ä½¿ç”¨60å¤©å‰ä½œä¸ºç»“æŸæ—¥æœŸï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
    validation_start = end_date - timedelta(days=365)
    validation_end = end_date - timedelta(days=30)  # ç•™å‡º30å¤©ç”¨äºforward returns
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = ResidualMomentumValidator(
        formation_period=252,  # 12ä¸ªæœˆ
        skip_recent_days=21,   # è·³è¿‡æœ€è¿‘1ä¸ªæœˆ
        forward_lookback_days=21  # 21å¤©forward return
    )
    
    # è¿è¡ŒéªŒè¯
    try:
        results = validator.validate_cross_sectional(
            symbols=symbols,
            start_date=validation_start,
            end_date=validation_end
        )
        
        print("\nâœ… Validation completed successfully!")
        print("\nğŸ“ˆ Recommendation:")
        
        # è·å–ä¸‰ä¸ªä¿¡å·çš„IC
        alpha_ic = float(results[results['Metric'] == 'Mean IC']['Alpha (Intercept Only)'].values[0])
        expected_return_ic = float(results[results['Metric'] == 'Mean IC']['Expected Return (Alpha + BetaÃ—Factors)'].values[0])
        momentum_ic = float(results[results['Metric'] == 'Mean IC']['Residual Momentum'].values[0])
        
        # æ‰¾å‡ºæœ€ä½³ä¿¡å·
        best_signal = max([
            ('Alpha', alpha_ic),
            ('Expected Return', expected_return_ic),
            ('Residual Momentum', momentum_ic)
        ], key=lambda x: x[1])
        
        print(f"  â†’ Best performing signal: {best_signal[0]} (IC = {best_signal[1]:.4f})")
        print()
        
        # è¯¦ç»†å¯¹æ¯”
        if momentum_ic > max(alpha_ic, expected_return_ic) + 0.01:
            print("  â†’ Residual Momentum shows significant improvement over both Alpha and Expected Return.")
            print("    Proceed to Stage 1 implementation.")
        elif expected_return_ic > alpha_ic + 0.01:
            print("  â†’ Expected Return (factor-aware) outperforms Alpha (intercept-only).")
            print("    This suggests factor exposures matter for prediction.")
        elif momentum_ic > max(alpha_ic, expected_return_ic):
            print("  â†’ Residual Momentum shows marginal improvement. Consider proceeding to Stage 1.")
        else:
            print("  â†’ Current Alpha or Expected Return method performs best.")
            print("    Residual Momentum may need parameter tuning or different universe.")
        
    except Exception as e:
        logger.error(f"Validation failed: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    main()

