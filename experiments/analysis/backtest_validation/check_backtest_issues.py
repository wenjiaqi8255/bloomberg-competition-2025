#!/usr/bin/env python3
"""
æ£€æŸ¥å›æµ‹è´Ÿæ”¶ç›Šé—®é¢˜çš„è¯Šæ–­è„šæœ¬

æ‰§è¡Œä¸‰é¡¹æ£€æŸ¥ï¼š
1. æ£€æŸ¥è®­ç»ƒæ¨¡å‹çš„å®é™…Alphaåˆ†å¸ƒ
2. æ£€æŸ¥æç«¯æ”¶ç›Šæ—¥çš„æŒä»“å’Œä»·æ ¼æ•°æ®
3. æ£€æŸ¥è®­ç»ƒæœŸä¸å›æµ‹æœŸè‚¡ç¥¨åˆ—è¡¨çš„é‡å åº¦
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json
import pickle
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

from trading_system.models.serving.predictor import ModelPredictor
from trading_system.models.model_persistence import ModelRegistry
from trading_system.models.implementations.ff5_model import FF5RegressionModel


def check_1_alpha_distribution(model_id: str):
    """æ£€æŸ¥1: è®­ç»ƒæ¨¡å‹çš„å®é™…Alphaåˆ†å¸ƒ"""
    print("=" * 80)
    print("æ£€æŸ¥1: è®­ç»ƒæ¨¡å‹çš„å®é™…Alphaåˆ†å¸ƒ")
    print("=" * 80)
    
    try:
        # åŠ è½½æ¨¡å‹
        model_registry_path = project_root / "models"
        predictor = ModelPredictor(
            model_id=model_id,
            model_registry_path=str(model_registry_path)
        )
        model = predictor.get_current_model()
        
        if not model:
            print(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹: {model_id}")
            return None
        
        if not hasattr(model, 'get_symbol_alphas'):
            print(f"âŒ æ¨¡å‹ä¸æ”¯æŒ get_symbol_alphas æ–¹æ³•")
            return None
        
        # è·å–æ‰€æœ‰Alphaå€¼
        alphas = model.get_symbol_alphas()
        
        if not alphas:
            print("âŒ æ¨¡å‹ä¸­æ²¡æœ‰Alphaå€¼")
            return None
        
        alpha_values = list(alphas.values())
        alpha_array = np.array(alpha_values)
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š Alphaç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»è‚¡ç¥¨æ•°é‡: {len(alphas)}")
        print(f"   Alphaæœ€å°å€¼: {np.min(alpha_array):.6f}")
        print(f"   Alphaæœ€å¤§å€¼: {np.max(alpha_array):.6f}")
        print(f"   Alphaå¹³å‡å€¼: {np.mean(alpha_array):.6f}")
        print(f"   Alphaä¸­ä½æ•°: {np.median(alpha_array):.6f}")
        print(f"   Alphaæ ‡å‡†å·®: {np.std(alpha_array):.6f}")
        
        # æ­£è´ŸAlphaç»Ÿè®¡
        positive_alphas = [a for a in alpha_values if a > 0]
        negative_alphas = [a for a in alpha_values if a < 0]
        zero_alphas = [a for a in alpha_values if a == 0]
        
        print(f"\nğŸ“ˆ Alphaç¬¦å·åˆ†å¸ƒ:")
        print(f"   æ­£Alphaè‚¡ç¥¨: {len(positive_alphas)} ({len(positive_alphas)/len(alphas)*100:.1f}%)")
        print(f"   è´ŸAlphaè‚¡ç¥¨: {len(negative_alphas)} ({len(negative_alphas)/len(alphas)*100:.1f}%)")
        print(f"   é›¶Alphaè‚¡ç¥¨: {len(zero_alphas)} ({len(zero_alphas)/len(alphas)*100:.1f}%)")
        
        if positive_alphas:
            print(f"\n   æ­£Alphaç»Ÿè®¡:")
            print(f"     æœ€å°å€¼: {min(positive_alphas):.6f}")
            print(f"     æœ€å¤§å€¼: {max(positive_alphas):.6f}")
            print(f"     å¹³å‡å€¼: {np.mean(positive_alphas):.6f}")
        
        if negative_alphas:
            print(f"\n   è´ŸAlphaç»Ÿè®¡:")
            print(f"     æœ€å°å€¼: {min(negative_alphas):.6f}")
            print(f"     æœ€å¤§å€¼: {max(negative_alphas):.6f}")
            print(f"     å¹³å‡å€¼: {np.mean(negative_alphas):.6f}")
        
        # Top/Bottom Alphaè‚¡ç¥¨
        sorted_alphas = sorted(alphas.items(), key=lambda x: x[1], reverse=True)
        print(f"\nğŸ† Top 10 æ­£Alphaè‚¡ç¥¨:")
        for i, (symbol, alpha) in enumerate(sorted_alphas[:10], 1):
            print(f"   {i:2d}. {symbol:15s}: {alpha:8.6f}")
        
        print(f"\nğŸ“‰ Bottom 10 è´ŸAlphaè‚¡ç¥¨:")
        for i, (symbol, alpha) in enumerate(sorted_alphas[-10:], 1):
            print(f"   {i:2d}. {symbol:15s}: {alpha:8.6f}")
        
        # æ£€æŸ¥æ¨¡å‹å…ƒæ•°æ®
        if hasattr(model, 'metadata'):
            print(f"\nğŸ“‹ æ¨¡å‹è®­ç»ƒä¿¡æ¯:")
            print(f"   è®­ç»ƒæ ·æœ¬æ•°: {model.metadata.training_samples if hasattr(model.metadata, 'training_samples') else 'N/A'}")
            print(f"   è®­ç»ƒå¼€å§‹æ—¥æœŸ: {model.metadata.start_date if hasattr(model.metadata, 'start_date') else 'N/A'}")
            print(f"   è®­ç»ƒç»“æŸæ—¥æœŸ: {model.metadata.end_date if hasattr(model.metadata, 'end_date') else 'N/A'}")
        
        return alphas
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥Alphaåˆ†å¸ƒæ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


def check_2_extreme_return_days(returns_path: str, results_dir: str):
    """æ£€æŸ¥2: æç«¯æ”¶ç›Šæ—¥çš„æŒä»“å’Œä»·æ ¼æ•°æ®"""
    print("\n" + "=" * 80)
    print("æ£€æŸ¥2: æç«¯æ”¶ç›Šæ—¥çš„æŒä»“å’Œä»·æ ¼æ•°æ®")
    print("=" * 80)
    
    try:
        # è¯»å–ç­–ç•¥æ”¶ç›Š
        returns_df = pd.read_csv(returns_path, index_col=0, parse_dates=True)
        returns_df.columns = ['daily_return']
        returns = returns_df['daily_return']
        
        # æ‰¾å‡ºæç«¯æ”¶ç›Šæ—¥
        extreme_days = []
        threshold = 0.05  # 5%é˜ˆå€¼
        
        for date, ret in returns.items():
            if abs(ret) > threshold:
                extreme_days.append((date, ret))
        
        extreme_days.sort(key=lambda x: abs(x[1]), reverse=True)
        
        print(f"\nğŸ“Š æç«¯æ”¶ç›Šæ—¥åˆ†æ (é˜ˆå€¼: Â±{threshold*100:.0f}%):")
        print(f"   æ‰¾åˆ° {len(extreme_days)} ä¸ªæç«¯æ”¶ç›Šæ—¥")
        
        print(f"\nğŸ”¥ Top 10 æç«¯æ”¶ç›Šæ—¥:")
        for i, (date, ret) in enumerate(extreme_days[:10], 1):
            print(f"   {i:2d}. {date.strftime('%Y-%m-%d')}: {ret*100:7.2f}%")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰portfolio weightsæ•°æ®
        results_path = Path(results_dir)
        portfolio_weights_path = results_path / "portfolio_weights.csv"
        
        if portfolio_weights_path.exists():
            print(f"\nğŸ“ˆ æ£€æŸ¥æç«¯æ”¶ç›Šæ—¥çš„æŒä»“æƒé‡...")
            weights_df = pd.read_csv(portfolio_weights_path, index_col=0, parse_dates=True)
            
            for date, ret in extreme_days[:5]:  # åªæ£€æŸ¥å‰5ä¸ª
                if date in weights_df.index:
                    weights = weights_df.loc[date]
                    non_zero_weights = weights[weights != 0].sort_values(ascending=False)
                    
                    print(f"\n   ğŸ“… {date.strftime('%Y-%m-%d')} (æ”¶ç›Š: {ret*100:.2f}%):")
                    print(f"      æ€»æŒä»“æ•°: {len(non_zero_weights)}")
                    print(f"      æƒé‡æ€»å’Œ: {weights.sum():.4f}")
                    
                    if len(non_zero_weights) > 0:
                        print(f"      Top 5 æŒä»“:")
                        for symbol, weight in list(non_zero_weights.head().items()):
                            print(f"        {symbol:15s}: {weight*100:6.2f}%")
        else:
            print(f"\nâš ï¸  æœªæ‰¾åˆ° portfolio_weights.csv æ–‡ä»¶")
            print(f"   è·¯å¾„: {portfolio_weights_path}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰backtestç»“æœ
        backtest_results_path = results_path / "backtest_results.json"
        if backtest_results_path.exists():
            print(f"\nğŸ“‹ æ£€æŸ¥å›æµ‹ç»“æœ...")
            with open(backtest_results_path, 'r') as f:
                backtest_results = json.load(f)
            
            if 'trades' in backtest_results:
                trades = backtest_results['trades']
                print(f"   æ€»äº¤æ˜“æ•°: {len(trades)}")
                
                # æŸ¥æ‰¾æç«¯æ”¶ç›Šæ—¥çš„äº¤æ˜“
                for date, ret in extreme_days[:3]:
                    date_str = date.strftime('%Y-%m-%d')
                    day_trades = [t for t in trades if t.get('date', '').startswith(date_str)]
                    if day_trades:
                        print(f"\n   {date_str} çš„äº¤æ˜“:")
                        for trade in day_trades[:5]:
                            print(f"      {trade.get('symbol', 'N/A'):15s} {trade.get('direction', 'N/A'):5s} {trade.get('quantity', 0):8.0f} @ ${trade.get('price', 0):.2f}")
        
        return extreme_days
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æç«¯æ”¶ç›Šæ—¥æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


def check_3_universe_overlap(config_path: str, model_id: str):
    """æ£€æŸ¥3: è®­ç»ƒæœŸä¸å›æµ‹æœŸè‚¡ç¥¨åˆ—è¡¨çš„é‡å åº¦"""
    print("\n" + "=" * 80)
    print("æ£€æŸ¥3: è®­ç»ƒæœŸä¸å›æµ‹æœŸè‚¡ç¥¨åˆ—è¡¨çš„é‡å åº¦")
    print("=" * 80)
    
    try:
        import yaml
        
        # è¯»å–é…ç½®
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # è·å–è®­ç»ƒæœŸé…ç½®
        training_setup = config.get('training_setup', {})
        training_params = training_setup.get('parameters', {})
        train_start = training_params.get('start_date', 'N/A')
        train_end = training_params.get('end_date', 'N/A')
        
        # è·å–å›æµ‹æœŸé…ç½®
        backtest_config = config.get('backtest', {})
        backtest_start = backtest_config.get('start_date', 'N/A')
        backtest_end = backtest_config.get('end_date', 'N/A')
        
        print(f"\nğŸ“… æ—¶é—´èŒƒå›´:")
        print(f"   è®­ç»ƒæœŸ: {train_start} åˆ° {train_end}")
        print(f"   å›æµ‹æœŸ: {backtest_start} åˆ° {backtest_end}")
        
        # åŠ è½½æ¨¡å‹ï¼Œè·å–è®­ç»ƒæœŸçš„è‚¡ç¥¨åˆ—è¡¨
        model_registry_path = project_root / "models"
        predictor = ModelPredictor(
            model_id=model_id,
            model_registry_path=str(model_registry_path)
        )
        model = predictor.get_current_model()
        
        if not model or not hasattr(model, 'get_symbol_alphas'):
            print("âŒ æ— æ³•åŠ è½½æ¨¡å‹æˆ–è·å–è‚¡ç¥¨åˆ—è¡¨")
            return None
        
        training_symbols = set(model.get_symbol_alphas().keys())
        print(f"\nğŸ“Š è®­ç»ƒæœŸè‚¡ç¥¨æ•°é‡: {len(training_symbols)}")
        
        # è·å–å›æµ‹æœŸçš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆä»é…ç½®ä¸­ï¼‰
        universe_config = training_params.get('universe', {})
        if universe_config.get('source') == 'csv':
            csv_path = universe_config.get('csv_path', '')
            if csv_path:
                csv_path = project_root / csv_path.replace('./', '')
                if csv_path.exists():
                    universe_df = pd.read_csv(csv_path)
                    if 'symbol' in universe_df.columns:
                        backtest_symbols = set(universe_df['symbol'].unique())
                    elif 'Symbol' in universe_df.columns:
                        backtest_symbols = set(universe_df['Symbol'].unique())
                    else:
                        # å°è¯•ç¬¬ä¸€åˆ—
                        backtest_symbols = set(universe_df.iloc[:, 0].unique())
                    
                    print(f"ğŸ“Š å›æµ‹æœŸè‚¡ç¥¨æ•°é‡: {len(backtest_symbols)}")
                    
                    # è®¡ç®—é‡å 
                    overlap = training_symbols.intersection(backtest_symbols)
                    only_training = training_symbols - backtest_symbols
                    only_backtest = backtest_symbols - training_symbols
                    
                    print(f"\nğŸ“ˆ é‡å åˆ†æ:")
                    print(f"   é‡å è‚¡ç¥¨æ•°: {len(overlap)} ({len(overlap)/len(training_symbols)*100:.1f}% of è®­ç»ƒæœŸ)")
                    print(f"   ä»…åœ¨è®­ç»ƒæœŸ: {len(only_training)}")
                    print(f"   ä»…åœ¨å›æµ‹æœŸ: {len(only_backtest)}")
                    
                    if len(overlap) < len(training_symbols) * 0.5:
                        print(f"\nâš ï¸  è­¦å‘Š: é‡å åº¦ä½äº50%ï¼Œè¿™å¯èƒ½å¯¼è‡´ä¿¡å·è´¨é‡é—®é¢˜ï¼")
                    
                    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
                    if only_training:
                        print(f"\n   ä»…åœ¨è®­ç»ƒæœŸçš„ç¤ºä¾‹è‚¡ç¥¨ (å‰10ä¸ª):")
                        for symbol in list(only_training)[:10]:
                            print(f"      {symbol}")
                    
                    if only_backtest:
                        print(f"\n   ä»…åœ¨å›æµ‹æœŸçš„ç¤ºä¾‹è‚¡ç¥¨ (å‰10ä¸ª):")
                        for symbol in list(only_backtest)[:10]:
                            print(f"      {symbol}")
                    
                    return {
                        'training_symbols': training_symbols,
                        'backtest_symbols': backtest_symbols,
                        'overlap': overlap,
                        'overlap_ratio': len(overlap) / len(training_symbols) if training_symbols else 0
                    }
                else:
                    print(f"âš ï¸  CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            else:
                print("âš ï¸  é…ç½®ä¸­æœªæŒ‡å®šCSVè·¯å¾„")
        else:
            print("âš ï¸  æ— æ³•ä»é…ç½®ä¸­ç¡®å®šå›æµ‹æœŸè‚¡ç¥¨åˆ—è¡¨")
        
        return None
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è‚¡ç¥¨é‡å åº¦æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ä¸»å‡½æ•°"""
    model_id = "ff5_regression_20251107_012512"
    config_path = project_root / "configs" / "active" / "single_experiment" / "ff5_box_based_experiment.yaml"
    returns_path = project_root / "results" / "ff5_regression_20251107_012512" / "strategy_returns.csv"
    results_dir = project_root / "results" / "ff5_regression_20251107_012512"
    
    print("ğŸ” FF5å›æµ‹è´Ÿæ”¶ç›Šé—®é¢˜è¯Šæ–­")
    print("=" * 80)
    print(f"æ¨¡å‹ID: {model_id}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    print(f"æ”¶ç›Šæ–‡ä»¶: {returns_path}")
    print("=" * 80)
    
    # æ£€æŸ¥1: Alphaåˆ†å¸ƒ
    alphas = check_1_alpha_distribution(model_id)
    
    # æ£€æŸ¥2: æç«¯æ”¶ç›Šæ—¥
    if returns_path.exists():
        extreme_days = check_2_extreme_return_days(str(returns_path), str(results_dir))
    else:
        print(f"\nâš ï¸  æ”¶ç›Šæ–‡ä»¶ä¸å­˜åœ¨: {returns_path}")
    
    # æ£€æŸ¥3: è‚¡ç¥¨é‡å åº¦
    if config_path.exists():
        overlap_info = check_3_universe_overlap(str(config_path), model_id)
    else:
        print(f"\nâš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“‹ æ£€æŸ¥æ€»ç»“")
    print("=" * 80)
    
    if alphas:
        alpha_values = list(alphas.values())
        positive_ratio = sum(1 for a in alpha_values if a > 0) / len(alpha_values)
        print(f"1. Alphaåˆ†å¸ƒ: {len(alphas)}åªè‚¡ç¥¨, {positive_ratio*100:.1f}%ä¸ºæ­£Alpha")
        
        if positive_ratio < 0.3:
            print("   âš ï¸  è­¦å‘Š: æ­£Alphaè‚¡ç¥¨æ¯”ä¾‹è¿‡ä½ï¼Œå¯èƒ½å¯¼è‡´å¯ç”¨ä¿¡å·ä¸è¶³")
        if positive_ratio > 0.7:
            print("   âš ï¸  è­¦å‘Š: æ­£Alphaè‚¡ç¥¨æ¯”ä¾‹è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®é—®é¢˜")
    
    if overlap_info:
        overlap_ratio = overlap_info.get('overlap_ratio', 0)
        print(f"2. è‚¡ç¥¨é‡å åº¦: {overlap_ratio*100:.1f}%")
        
        if overlap_ratio < 0.5:
            print("   âš ï¸  è­¦å‘Š: è®­ç»ƒæœŸå’Œå›æµ‹æœŸè‚¡ç¥¨é‡å åº¦ä½ï¼Œæ¨¡å‹å¯èƒ½æ— æ³•æœ‰æ•ˆé¢„æµ‹")
    
    print("\nâœ… æ£€æŸ¥å®Œæˆ")


if __name__ == "__main__":
    main()


